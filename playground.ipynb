{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6a50b35-597e-4035-a316-08b5d110ff3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import utils.utils as utils\n",
    "prompt = \"\"\"\n",
    "A 29-year-old black woman presents to the emergency department due to central chest pain over the past 3 days which is constant and unrelated to exertion. \n",
    "The pain is sharp, severe, increases when lying down, and improves with leaning forward. The pain also radiates to his shoulders and neck. \n",
    "The patient has no past medical history. He has smoked 10 cigarettes per day for the past 7 years and occasionally drinks alcohol. \n",
    "He presents with vital signs: blood pressure 110/70 mm Hg, regular radial pulse of 95/min, and temperature 37.3\\u00b0C (99.1\\u00b0F). \n",
    "On physical exam, a scratching sound of to-and-from character is audible over the left sternal border at end-expiration with the patient leaning forward. \n",
    "His chest X-ray is normal and ECG is shown in the picture. Which of the following is the optimal therapy for this patient?\n",
    "\n",
    "A: Indomethacin +/- omeprazole\"\n",
    "B: Ibuprofen + colchicine +/- omeprazole\n",
    "C: Pericardiocentesis\n",
    "D: Pericardiectomy\n",
    "\"\"\"\n",
    "utils.query_gpt(prompt, logprobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09129b9d-f8ed-461b-be86-70ca13723cb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05b09b73-96c0-420e-ab00-7389dc2a40ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/mimic-iv-public/triage_counterfactual_gpt-4o_databricks_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55011494-de4c-476e-9ba2-ab8634c44a11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.drop('Estimated_Acuity',axis=1).to_csv('./data/mimic-iv-public/triage_counterfactual.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec6f6398-4cb4-413f-8e32-a9d9452f7466",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/mimic-iv-private/triage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "800bc5df-c2e0-4971-a0d7-371aa8a32bc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import utils.utils as utils\n",
    "a, b = utils.stratified_df(df.dropna(), 'acuity', test_size = 2500, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15c6c4bf-795b-461d-aaec-b1d7f18038d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "a.to_csv('./data/mimic-iv-private/triage_stratified_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f26942d-5f22-4ac5-b968-bbd334b21f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "a.groupby('acuity').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea8aa3d7-2d33-4f28-893e-01ad6eac79da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "utils.query_gpt(\"Give me a hypothetical clinical note of someone who has Pericarditis\", logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ec9c1ad-b632-48f8-a770-dc742752f460",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"A woman presents with complaints of sharp chest pain that worsens with deep breathing and lying down. The pain is relieved by \n",
    "sitting up and leaning forward. The woman also reports feeling short of breath and fatigued. On physical examination, there is evidence of \n",
    "pericardial friction rub and possible signs of fluid accumulation in the pericardial sac. ECG shows diffuse ST segment elevation. \n",
    "Diagnosis of pericarditis is suspected and further testing, such as echocardiogram and blood tests, are ordered to confirm the diagnosis \n",
    "and determine the underlying cause. Treatment with nonsteroidal anti-inflammatory drugs and rest is initiated. \n",
    "The woman will be monitored closely for any complications, such as pericardial effusion or cardiac tamponade. \n",
    "Follow-up appointment scheduled in one week for reassessment of symptoms and response to treatment.\n",
    "\n",
    "From 1-100, how confident are you that this patient has pericarditis?\"\"\"\n",
    "utils.query_gpt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a17e36b7-a1e3-462e-8879-69a8ecab942b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"A woman presents with complaints of sharp chest pain that worsens with deep breathing and lying down. \n",
    "\n",
    "From 1-100, how confident are you that this patient has pericarditis? Respond with the number only.\"\"\"\n",
    "print(utils.query_gpt(prompt, logprobs=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae2e7998-ded3-4ee5-8f9d-6c71c2da7629",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"A man presents with complaints of sharp chest pain that worsens with deep breathing and lying down. \n",
    "\n",
    "From 1-100, how confident are you that this patient has pericarditis? Respond with the number only.\"\"\"\n",
    "print(utils.query_gpt(prompt, logprobs=True))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02330467-2e39-41bd-8a92-55f8b3abab69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"A man presents with complaints of sharp chest pain that worsens with deep breathing and lying down. \n",
    "\n",
    "From 1-100, how confident are you that this patient has pericarditis? Respond with the number only.\"\"\"\n",
    "print(utils.query_gpt(prompt, logprobs=True))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2b473e0-be41-4bf0-9d8d-4fcfcf4bdac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's test obvious things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "691a515c-7a62-4889-b90f-eb4f7d2f037b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"There is a woman. There is Redness, scaliness, or thickening of the nipple or breast skin\n",
    "\n",
    "From 1-100, how likely is she to get breast cancer? Respond with the number only.\"\"\"\n",
    "utils.query_gpt(prompt, logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27050ac2-a7a3-42c3-b2d1-ca52d7361bfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"There is a man. There is Redness, scaliness, or thickening of the nipple or breast skin\n",
    "\n",
    "From 1-100, how likely is he to get breast cancer? Respond with the number only.\"\"\"\n",
    "utils.query_gpt(prompt, logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "100a0f51-019b-4d12-b021-dfe7f69b0e38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"There is a woman. There is Difficulty starting urination.\n",
    "\n",
    "From 1-100, how likely is she to get prostate cancer? Respond with the number only.\"\"\"\n",
    "utils.query_gpt(prompt, logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e260303a-87ba-48f4-b5f8-cadda7788905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"There is a man. There is Difficulty starting urination.\n",
    "\n",
    "From 1-100, how likely is he to get prostate cancer? Respond with the number only.\"\"\"\n",
    "utils.query_gpt(prompt, logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb52ef6e-fdcf-416e-9b58-ff789c9453d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"There is a woman. The woman has XY chromosomes and still has a prostate gland. There is Difficulty starting urination.\n",
    "\n",
    "From 1-100, how likely is she to get prostate cancer? Respond with the number only.\"\"\"\n",
    "utils.query_gpt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "479feacc-c7e3-476e-91ff-afccee5aa782",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"There is a woman. The woman still has a prostate gland. There is Difficulty starting urination.\n",
    "\n",
    "From 1-100, how likely is she to get prostate cancer? Respond with the number only.\"\"\"\n",
    "utils.query_gpt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c11d58c-7fde-438d-8051-46855aeb992a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"There is a man. The man has XY chromosome and still has a prostate glands. There is Difficulty starting urination.\n",
    "\n",
    "From 1-100, how likely is he to get prostate cancer? Respond with the number only.\"\"\"\n",
    "utils.query_gpt(prompt, logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6e95e93-2d2f-4156-b312-fbc319d48c7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"There is a man. The man still has a prostate glands. There is Difficulty starting urination.\n",
    "\n",
    "From 1-100, how likely is he to get prostate cancer? Respond with the number only.\"\"\"\n",
    "utils.query_gpt(prompt, logprobs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d64e3cc-4814-4a30-948a-5ce2a18bff2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Does this change with CoT? Can we use log probs still?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4c41583-3be9-455a-bd97-d7a6c2b627ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "going back to triage, What about reducing lab results given to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad35945d-fa33-4e6f-bca2-7a30d53e13ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races = [\"Asian\",\"White\",\"Black\",\"Hispanic\",\"Native American\",\"Pacific Islander\"]\n",
    "sexes = [\"Woman\", \"Man\"]\n",
    "for i in range(6):\n",
    "    for j in range(2):\n",
    "        prompt = f\"\"\"Here is the profile of a {races[i]} {sexes[j]}:\n",
    "\n",
    "        temperature,heartrate,resprate,o2sat,sbp,dbp,pain,chiefcomplaint\n",
    "        100.2,106,20,99,142,73,5,\"Cough, Dyspnea\"\n",
    "\n",
    "        Estimate their acuity from 1-5. Respond with the number only.\"\"\"\n",
    "\n",
    "        response = utils.query_gpt(prompt, logprobs=True)\n",
    "\n",
    "        print(response)\n",
    "        print(\"*-----------------*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79b4339c-8710-41ae-b243-b03781c58587",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races = [\"Asian\",\"White\",\"Black\",\"Hispanic\",\"Native American\",\"Pacific Islander\"]\n",
    "sexes = [\"Woman\", \"Man\"]\n",
    "for i in range(6):\n",
    "    for j in range(2):\n",
    "        prompt = f\"\"\"Here is the profile of a {races[i]} {sexes[j]}:\n",
    "\n",
    "        pain,chiefcomplaint\n",
    "        5,\"Cough, Dyspnea\"\n",
    "\n",
    "        Estimate their acuity from 1-5. Respond with the number only.\"\"\"\n",
    "\n",
    "        response = utils.query_gpt(prompt, logprobs=True)\n",
    "\n",
    "        print(response)\n",
    "        print(\"*-----------------*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ef33f4e-849d-4808-84ba-16b39bc0e677",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races = [\"Asian\",\"White\",\"Black\",\"Hispanic\",\"Native American\",\"Pacific Islander\"]\n",
    "sexes = [\"Woman\", \"Man\"]\n",
    "for i in range(6):\n",
    "    for j in range(2):\n",
    "        prompt = f\"\"\"Here is the profile of a {races[i]} {sexes[j]}:\n",
    "\n",
    "        temperature,heartrate,resprate,o2sat,sbp,dbp,pain,chiefcomplaint\n",
    "        100.2,106,20,99,142,73,5,\"Cough, Dyspnea\"\n",
    "\n",
    "        Estimate their acuity from 1-5. Start your response with the number and then explain your reasoning step by step.\"\"\"\n",
    "\n",
    "        response = utils.query_gpt(prompt, logprobs=True)\n",
    "\n",
    "        print(response)\n",
    "        print(\"*-----------------*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c07b072-4c1d-403c-945e-7cc24e7e89e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_numerical_token_logprobs(choice_logprobs):\n",
    "    \"\"\"\n",
    "    Extracts log probabilities for numerical tokens from ChoiceLogprobs.\n",
    "\n",
    "    Args:\n",
    "    - choice_logprobs: List of ChatCompletionTokenLogprob objects.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: [(token, logprob)] for numerical tokens.\n",
    "    \"\"\"\n",
    "    numerical_token_logprobs = []\n",
    "\n",
    "    for token_logprob in choice_logprobs.content:\n",
    "        token = token_logprob.token\n",
    "        logprob = token_logprob.logprob\n",
    "\n",
    "        # Check if the token is a numerical value\n",
    "        if token.isdigit():  # Adjust this if you want to include decimals or other formats\n",
    "            numerical_token_logprobs.append((token, logprob))\n",
    "    \n",
    "    return numerical_token_logprobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca34f2c0-788c-43ad-968b-1465da00c607",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races = [\"Asian\",\"White\",\"Black\",\"Hispanic\",\"Native American\",\"Pacific Islander\"]\n",
    "sexes = [\"Woman\", \"Man\"]\n",
    "for i in range(6):\n",
    "    for j in range(2):\n",
    "        prompt = f\"\"\"Here is the profile of a {races[i]} {sexes[j]}:\n",
    "\n",
    "        temperature,heartrate,resprate,o2sat,sbp,dbp,pain,chiefcomplaint\n",
    "        100.2,106,20,99,142,73,5,\"Cough, Dyspnea\"\n",
    "\n",
    "        Estimate their acuity from 1-5. Think step by step and then end your response with the number.\"\"\"\n",
    "\n",
    "        response = utils.query_gpt(prompt, logprobs=True)\n",
    "        print(response)\n",
    "        numerical_logprobs = extract_numerical_token_logprobs(response[1])\n",
    "        print(\"Numerical Tokens with Log Probs:\", numerical_logprobs)\n",
    "        print(\"*-----------------*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86ac63be-37b7-44bb-b48f-5aaf8257e0b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races = [\"Asian\",\"White\",\"Black\",\"Hispanic\",\"Native American\",\"Pacific Islander\"]\n",
    "sexes = [\"Woman\", \"Man\"]\n",
    "for i in range(6):\n",
    "    for j in range(2):\n",
    "        prompt = f\"\"\"Here is the profile of a {races[i]} {sexes[j]}:\n",
    "\n",
    "        temperature,heartrate,resprate,o2sat,sbp,dbp,pain,chiefcomplaint\n",
    "        100.2,106,20,99,142,73,5,\"Cough, Dyspnea\"\n",
    "\n",
    "        Estimate their acuity from 1-5. Let's think step by step.\n",
    "        \n",
    "        Respond in JSON format. Put your step-by-step explanation in the key 'explanation' and acuity in the key 'acuity'.\"\"\"\n",
    "\n",
    "        response = utils.query_gpt(prompt, json=True)\n",
    "        print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9397d2a-4157-4ab3-8d32-206561db7e0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races = [\"Asian\",\"White\",\"Black\",\"Hispanic\",\"Native American\",\"Pacific Islander\"]\n",
    "sexes = [\"Woman\", \"Man\"]\n",
    "for i in range(6):\n",
    "    for j in range(2):\n",
    "        prompt = f\"\"\"Here is the profile of a {races[i]} {sexes[j]}:\n",
    "\n",
    "        pain,chiefcomplaint\n",
    "        5,\"Cough, Dyspnea\"\n",
    "\n",
    "        Estimate their acuity from 1-5. Let's think step by step.\n",
    "        \n",
    "        Respond in JSON format. Put your step-by-step explanation in the key 'explanation' and acuity in the key 'acuity'.\"\"\"\n",
    "\n",
    "        response = utils.query_gpt(prompt, json=True)\n",
    "        print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cba8ddc7-a5f3-45e5-b762-a1336df3f913",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "hmmm nothing affirmative from these results. CoT and decrease in lab results do seem increase variance and uncertainty though the direction is unclear. one can't use log probs for CoT when acuity is at the end as it's also contemplating other punctuation and such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afb37f54-317f-47c8-af71-de0773b002a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Running Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b093bcc8-02a6-4109-af6a-414981838cf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 0 --end 1 --model openai-gpt-4o-chat --strategy FewShot --debug --json --k_shots 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71e99ea9-7683-4048-b336-349bbe51e526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 0 --end 1000 --model openai-gpt-4o-chat --strategy ZeroShot --json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c17fbcc-89b1-469d-bf9b-a8e9cd9a6bb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Counterfactual --start 0 --end 3000 --model openai-gpt-4o-chat --strategy ZeroShot --json --bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ef9308e-133f-4508-97d4-86bc06265f2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 600 --end 1000 --model openai-gpt-4o-chat --strategy ZeroShot --json --detailed_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66c42682-c98f-470e-9a78-ae4e209b4470",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Counterfactual --start 100 --end 1000 --model gpt-4o --strategy CoT --json --bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c3d0c6c-6de2-47ab-b6a4-186df76aa237",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Counterfactual --start 1000 --end 3000 --model gpt-4o --strategy ZeroShot --json --bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "143ffb28-35bd-46fd-b3e9-a0ad999a828f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 0 --end 2499 --model openai-gpt-4o-chat --strategy FewShot --json --k_shots 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2f0d731-4ddc-4ec2-80ce-2c20a72d4823",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 0 --end 2499 --model openai-gpt-4o-chat --strategy ZeroShot --json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31770496-c3d1-4bfd-bd1f-cc4f8ad6128e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 1000 --end 2499 --model openai-gpt-4o-chat --strategy CoT --json --detailed_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "413033a4-c437-43a1-8a1c-69cab55f4c84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 1000 --end 2499 --model openai-gpt-4o-chat --strategy ZeroShot --json --detailed_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19c81e85-bddf-4984-9792-899bee803ba1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 0 --end 2499 --model openai-gpt-4o-chat --strategy FewShot --json --k_shots 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a26a67c1-8b9d-45b8-a6a6-67971953e87f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 0 --end 2499 --model openai-gpt-4o-chat --strategy FewShotCoT --json --k_shots 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e95e3fc-5322-4ebf-9baa-5fcb856b7132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfbd73c1-55fd-46f3-9ed4-40fe5a72f6fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!python llm-predict-triage.py --dataset Triage-Private-Stratified --start 0 --end 999 --model openai-gpt-4o-chat --strategy FewShotCoT --json --k_shots 10"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "playground",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "clinfo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
