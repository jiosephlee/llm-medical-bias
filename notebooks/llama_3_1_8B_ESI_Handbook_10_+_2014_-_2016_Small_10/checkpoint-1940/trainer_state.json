{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.99614890885751,
  "eval_steps": 500,
  "global_step": 1940,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12836970474967907,
      "grad_norm": 0.09567686915397644,
      "learning_rate": 0.00019793281653746771,
      "loss": 0.5127,
      "step": 25
    },
    {
      "epoch": 0.25673940949935814,
      "grad_norm": 0.12293652445077896,
      "learning_rate": 0.00019534883720930232,
      "loss": 0.2819,
      "step": 50
    },
    {
      "epoch": 0.3851091142490372,
      "grad_norm": 0.07603971660137177,
      "learning_rate": 0.00019276485788113695,
      "loss": 0.2702,
      "step": 75
    },
    {
      "epoch": 0.5134788189987163,
      "grad_norm": 0.08151312172412872,
      "learning_rate": 0.00019018087855297158,
      "loss": 0.267,
      "step": 100
    },
    {
      "epoch": 0.6418485237483954,
      "grad_norm": 0.07038101553916931,
      "learning_rate": 0.00018759689922480621,
      "loss": 0.2626,
      "step": 125
    },
    {
      "epoch": 0.7702182284980744,
      "grad_norm": 0.07484094798564911,
      "learning_rate": 0.00018501291989664085,
      "loss": 0.2619,
      "step": 150
    },
    {
      "epoch": 0.8985879332477535,
      "grad_norm": 0.13663429021835327,
      "learning_rate": 0.00018242894056847545,
      "loss": 0.2593,
      "step": 175
    },
    {
      "epoch": 1.030808729139923,
      "grad_norm": 0.07297651469707489,
      "learning_rate": 0.0001798449612403101,
      "loss": 0.2707,
      "step": 200
    },
    {
      "epoch": 1.159178433889602,
      "grad_norm": 0.0645160898566246,
      "learning_rate": 0.0001772609819121447,
      "loss": 0.2536,
      "step": 225
    },
    {
      "epoch": 1.287548138639281,
      "grad_norm": 0.06847016513347626,
      "learning_rate": 0.00017467700258397934,
      "loss": 0.2529,
      "step": 250
    },
    {
      "epoch": 1.4159178433889603,
      "grad_norm": 0.05804917961359024,
      "learning_rate": 0.00017209302325581395,
      "loss": 0.2546,
      "step": 275
    },
    {
      "epoch": 1.5442875481386393,
      "grad_norm": 0.07812435925006866,
      "learning_rate": 0.00016950904392764858,
      "loss": 0.2509,
      "step": 300
    },
    {
      "epoch": 1.6726572528883183,
      "grad_norm": 0.06748609989881516,
      "learning_rate": 0.0001669250645994832,
      "loss": 0.2525,
      "step": 325
    },
    {
      "epoch": 1.8010269576379976,
      "grad_norm": 0.059498131275177,
      "learning_rate": 0.00016434108527131784,
      "loss": 0.2521,
      "step": 350
    },
    {
      "epoch": 1.9293966623876764,
      "grad_norm": 0.059055037796497345,
      "learning_rate": 0.00016175710594315245,
      "loss": 0.2524,
      "step": 375
    },
    {
      "epoch": 2.061617458279846,
      "grad_norm": 0.055032696574926376,
      "learning_rate": 0.00015917312661498708,
      "loss": 0.2595,
      "step": 400
    },
    {
      "epoch": 2.189987163029525,
      "grad_norm": 0.057603880763053894,
      "learning_rate": 0.0001565891472868217,
      "loss": 0.2466,
      "step": 425
    },
    {
      "epoch": 2.318356867779204,
      "grad_norm": 0.05668407678604126,
      "learning_rate": 0.00015400516795865634,
      "loss": 0.2481,
      "step": 450
    },
    {
      "epoch": 2.4467265725288834,
      "grad_norm": 0.06926674395799637,
      "learning_rate": 0.00015142118863049097,
      "loss": 0.2481,
      "step": 475
    },
    {
      "epoch": 2.575096277278562,
      "grad_norm": 0.058365557342767715,
      "learning_rate": 0.00014883720930232558,
      "loss": 0.2468,
      "step": 500
    },
    {
      "epoch": 2.7034659820282414,
      "grad_norm": 0.062177713960409164,
      "learning_rate": 0.0001462532299741602,
      "loss": 0.2473,
      "step": 525
    },
    {
      "epoch": 2.8318356867779206,
      "grad_norm": 0.049445223063230515,
      "learning_rate": 0.00014366925064599484,
      "loss": 0.2464,
      "step": 550
    },
    {
      "epoch": 2.9602053915275994,
      "grad_norm": 0.05920587480068207,
      "learning_rate": 0.00014108527131782947,
      "loss": 0.2474,
      "step": 575
    },
    {
      "epoch": 3.092426187419769,
      "grad_norm": 0.05740649253129959,
      "learning_rate": 0.00013850129198966408,
      "loss": 0.2538,
      "step": 600
    },
    {
      "epoch": 3.220795892169448,
      "grad_norm": 0.06382472068071365,
      "learning_rate": 0.0001359173126614987,
      "loss": 0.2434,
      "step": 625
    },
    {
      "epoch": 3.349165596919127,
      "grad_norm": 0.06392116099596024,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.2418,
      "step": 650
    },
    {
      "epoch": 3.477535301668806,
      "grad_norm": 0.0671311542391777,
      "learning_rate": 0.00013074935400516797,
      "loss": 0.2421,
      "step": 675
    },
    {
      "epoch": 3.605905006418485,
      "grad_norm": 0.06474833935499191,
      "learning_rate": 0.00012816537467700258,
      "loss": 0.2442,
      "step": 700
    },
    {
      "epoch": 3.7342747111681645,
      "grad_norm": 0.05924418941140175,
      "learning_rate": 0.0001255813953488372,
      "loss": 0.2422,
      "step": 725
    },
    {
      "epoch": 3.8626444159178432,
      "grad_norm": 0.05656075105071068,
      "learning_rate": 0.00012299741602067184,
      "loss": 0.2438,
      "step": 750
    },
    {
      "epoch": 3.9910141206675225,
      "grad_norm": 0.056377679109573364,
      "learning_rate": 0.00012041343669250647,
      "loss": 0.2437,
      "step": 775
    },
    {
      "epoch": 4.123234916559692,
      "grad_norm": 0.06688524782657623,
      "learning_rate": 0.0001178294573643411,
      "loss": 0.2463,
      "step": 800
    },
    {
      "epoch": 4.251604621309371,
      "grad_norm": 0.06372793018817902,
      "learning_rate": 0.00011524547803617572,
      "loss": 0.2387,
      "step": 825
    },
    {
      "epoch": 4.37997432605905,
      "grad_norm": 0.06891080737113953,
      "learning_rate": 0.00011266149870801035,
      "loss": 0.239,
      "step": 850
    },
    {
      "epoch": 4.508344030808729,
      "grad_norm": 0.061148036271333694,
      "learning_rate": 0.00011007751937984496,
      "loss": 0.2398,
      "step": 875
    },
    {
      "epoch": 4.636713735558408,
      "grad_norm": 0.07186292111873627,
      "learning_rate": 0.0001074935400516796,
      "loss": 0.2387,
      "step": 900
    },
    {
      "epoch": 4.7650834403080875,
      "grad_norm": 0.059658486396074295,
      "learning_rate": 0.0001049095607235142,
      "loss": 0.2388,
      "step": 925
    },
    {
      "epoch": 4.893453145057767,
      "grad_norm": 0.05982057750225067,
      "learning_rate": 0.00010232558139534885,
      "loss": 0.2405,
      "step": 950
    },
    {
      "epoch": 5.025673940949936,
      "grad_norm": 0.05801989883184433,
      "learning_rate": 9.974160206718347e-05,
      "loss": 0.2477,
      "step": 975
    },
    {
      "epoch": 5.154043645699615,
      "grad_norm": 0.07308829575777054,
      "learning_rate": 9.71576227390181e-05,
      "loss": 0.2311,
      "step": 1000
    },
    {
      "epoch": 5.282413350449294,
      "grad_norm": 0.08007809519767761,
      "learning_rate": 9.457364341085272e-05,
      "loss": 0.2338,
      "step": 1025
    },
    {
      "epoch": 5.410783055198973,
      "grad_norm": 0.09320799261331558,
      "learning_rate": 9.198966408268735e-05,
      "loss": 0.2329,
      "step": 1050
    },
    {
      "epoch": 5.539152759948652,
      "grad_norm": 0.06773591041564941,
      "learning_rate": 8.940568475452197e-05,
      "loss": 0.2346,
      "step": 1075
    },
    {
      "epoch": 5.667522464698331,
      "grad_norm": 0.05887242779135704,
      "learning_rate": 8.68217054263566e-05,
      "loss": 0.2333,
      "step": 1100
    },
    {
      "epoch": 5.7958921694480106,
      "grad_norm": 0.06106017157435417,
      "learning_rate": 8.423772609819122e-05,
      "loss": 0.2345,
      "step": 1125
    },
    {
      "epoch": 5.92426187419769,
      "grad_norm": 0.07588807493448257,
      "learning_rate": 8.165374677002583e-05,
      "loss": 0.2394,
      "step": 1150
    },
    {
      "epoch": 6.056482670089859,
      "grad_norm": 0.09165430068969727,
      "learning_rate": 7.906976744186047e-05,
      "loss": 0.2412,
      "step": 1175
    },
    {
      "epoch": 6.184852374839538,
      "grad_norm": 0.07612154632806778,
      "learning_rate": 7.648578811369508e-05,
      "loss": 0.2259,
      "step": 1200
    },
    {
      "epoch": 6.313222079589217,
      "grad_norm": 0.07799313962459564,
      "learning_rate": 7.390180878552973e-05,
      "loss": 0.2257,
      "step": 1225
    },
    {
      "epoch": 6.441591784338896,
      "grad_norm": 0.07890590280294418,
      "learning_rate": 7.131782945736435e-05,
      "loss": 0.227,
      "step": 1250
    },
    {
      "epoch": 6.569961489088575,
      "grad_norm": 0.08669491857290268,
      "learning_rate": 6.873385012919898e-05,
      "loss": 0.227,
      "step": 1275
    },
    {
      "epoch": 6.698331193838254,
      "grad_norm": 0.07477864623069763,
      "learning_rate": 6.61498708010336e-05,
      "loss": 0.2249,
      "step": 1300
    },
    {
      "epoch": 6.826700898587934,
      "grad_norm": 0.0712989866733551,
      "learning_rate": 6.356589147286823e-05,
      "loss": 0.2263,
      "step": 1325
    },
    {
      "epoch": 6.955070603337612,
      "grad_norm": 0.07472631335258484,
      "learning_rate": 6.0981912144702846e-05,
      "loss": 0.2274,
      "step": 1350
    },
    {
      "epoch": 7.087291399229782,
      "grad_norm": 0.0876847505569458,
      "learning_rate": 5.839793281653747e-05,
      "loss": 0.2288,
      "step": 1375
    },
    {
      "epoch": 7.2156611039794605,
      "grad_norm": 0.08628857880830765,
      "learning_rate": 5.5813953488372095e-05,
      "loss": 0.2145,
      "step": 1400
    },
    {
      "epoch": 7.34403080872914,
      "grad_norm": 0.1025351956486702,
      "learning_rate": 5.322997416020672e-05,
      "loss": 0.2156,
      "step": 1425
    },
    {
      "epoch": 7.472400513478819,
      "grad_norm": 0.10675032436847687,
      "learning_rate": 5.0645994832041345e-05,
      "loss": 0.2175,
      "step": 1450
    },
    {
      "epoch": 7.600770218228498,
      "grad_norm": 0.10792997479438782,
      "learning_rate": 4.8062015503875976e-05,
      "loss": 0.216,
      "step": 1475
    },
    {
      "epoch": 7.729139922978177,
      "grad_norm": 0.09015180915594101,
      "learning_rate": 4.54780361757106e-05,
      "loss": 0.2156,
      "step": 1500
    },
    {
      "epoch": 7.857509627727856,
      "grad_norm": 0.10158094018697739,
      "learning_rate": 4.289405684754522e-05,
      "loss": 0.2161,
      "step": 1525
    },
    {
      "epoch": 7.985879332477535,
      "grad_norm": 0.0914439931511879,
      "learning_rate": 4.0310077519379843e-05,
      "loss": 0.2162,
      "step": 1550
    },
    {
      "epoch": 8.118100128369704,
      "grad_norm": 0.12103923410177231,
      "learning_rate": 3.772609819121447e-05,
      "loss": 0.2109,
      "step": 1575
    },
    {
      "epoch": 8.246469833119384,
      "grad_norm": 0.14839240908622742,
      "learning_rate": 3.514211886304909e-05,
      "loss": 0.1998,
      "step": 1600
    },
    {
      "epoch": 8.374839537869063,
      "grad_norm": 0.1436200588941574,
      "learning_rate": 3.2558139534883724e-05,
      "loss": 0.2017,
      "step": 1625
    },
    {
      "epoch": 8.503209242618741,
      "grad_norm": 0.11642938107252121,
      "learning_rate": 2.997416020671835e-05,
      "loss": 0.2012,
      "step": 1650
    },
    {
      "epoch": 8.631578947368421,
      "grad_norm": 0.12469343096017838,
      "learning_rate": 2.7390180878552974e-05,
      "loss": 0.2012,
      "step": 1675
    },
    {
      "epoch": 8.7599486521181,
      "grad_norm": 0.1411246359348297,
      "learning_rate": 2.48062015503876e-05,
      "loss": 0.2012,
      "step": 1700
    },
    {
      "epoch": 8.88831835686778,
      "grad_norm": 0.13770952820777893,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.2016,
      "step": 1725
    },
    {
      "epoch": 9.020539152759948,
      "grad_norm": 0.12454213201999664,
      "learning_rate": 1.9638242894056848e-05,
      "loss": 0.2082,
      "step": 1750
    },
    {
      "epoch": 9.148908857509628,
      "grad_norm": 0.2053847461938858,
      "learning_rate": 1.7054263565891473e-05,
      "loss": 0.1812,
      "step": 1775
    },
    {
      "epoch": 9.277278562259307,
      "grad_norm": 0.16551446914672852,
      "learning_rate": 1.4470284237726097e-05,
      "loss": 0.1812,
      "step": 1800
    },
    {
      "epoch": 9.405648267008987,
      "grad_norm": 0.15309405326843262,
      "learning_rate": 1.1886304909560724e-05,
      "loss": 0.1815,
      "step": 1825
    },
    {
      "epoch": 9.534017971758665,
      "grad_norm": 0.1817992627620697,
      "learning_rate": 9.302325581395349e-06,
      "loss": 0.1828,
      "step": 1850
    },
    {
      "epoch": 9.662387676508343,
      "grad_norm": 0.152463898062706,
      "learning_rate": 6.718346253229975e-06,
      "loss": 0.183,
      "step": 1875
    },
    {
      "epoch": 9.790757381258024,
      "grad_norm": 0.16211074590682983,
      "learning_rate": 4.1343669250646e-06,
      "loss": 0.1826,
      "step": 1900
    },
    {
      "epoch": 9.919127086007702,
      "grad_norm": 0.15943105518817902,
      "learning_rate": 1.550387596899225e-06,
      "loss": 0.1804,
      "step": 1925
    }
  ],
  "logging_steps": 25,
  "max_steps": 1940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.253086621170401e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
