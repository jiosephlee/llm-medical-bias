{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.154043645699615,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12836970474967907,
      "grad_norm": 0.09567686915397644,
      "learning_rate": 0.00019793281653746771,
      "loss": 0.5127,
      "step": 25
    },
    {
      "epoch": 0.25673940949935814,
      "grad_norm": 0.12293652445077896,
      "learning_rate": 0.00019534883720930232,
      "loss": 0.2819,
      "step": 50
    },
    {
      "epoch": 0.3851091142490372,
      "grad_norm": 0.07603971660137177,
      "learning_rate": 0.00019276485788113695,
      "loss": 0.2702,
      "step": 75
    },
    {
      "epoch": 0.5134788189987163,
      "grad_norm": 0.08151312172412872,
      "learning_rate": 0.00019018087855297158,
      "loss": 0.267,
      "step": 100
    },
    {
      "epoch": 0.6418485237483954,
      "grad_norm": 0.07038101553916931,
      "learning_rate": 0.00018759689922480621,
      "loss": 0.2626,
      "step": 125
    },
    {
      "epoch": 0.7702182284980744,
      "grad_norm": 0.07484094798564911,
      "learning_rate": 0.00018501291989664085,
      "loss": 0.2619,
      "step": 150
    },
    {
      "epoch": 0.8985879332477535,
      "grad_norm": 0.13663429021835327,
      "learning_rate": 0.00018242894056847545,
      "loss": 0.2593,
      "step": 175
    },
    {
      "epoch": 1.030808729139923,
      "grad_norm": 0.07297651469707489,
      "learning_rate": 0.0001798449612403101,
      "loss": 0.2707,
      "step": 200
    },
    {
      "epoch": 1.159178433889602,
      "grad_norm": 0.0645160898566246,
      "learning_rate": 0.0001772609819121447,
      "loss": 0.2536,
      "step": 225
    },
    {
      "epoch": 1.287548138639281,
      "grad_norm": 0.06847016513347626,
      "learning_rate": 0.00017467700258397934,
      "loss": 0.2529,
      "step": 250
    },
    {
      "epoch": 1.4159178433889603,
      "grad_norm": 0.05804917961359024,
      "learning_rate": 0.00017209302325581395,
      "loss": 0.2546,
      "step": 275
    },
    {
      "epoch": 1.5442875481386393,
      "grad_norm": 0.07812435925006866,
      "learning_rate": 0.00016950904392764858,
      "loss": 0.2509,
      "step": 300
    },
    {
      "epoch": 1.6726572528883183,
      "grad_norm": 0.06748609989881516,
      "learning_rate": 0.0001669250645994832,
      "loss": 0.2525,
      "step": 325
    },
    {
      "epoch": 1.8010269576379976,
      "grad_norm": 0.059498131275177,
      "learning_rate": 0.00016434108527131784,
      "loss": 0.2521,
      "step": 350
    },
    {
      "epoch": 1.9293966623876764,
      "grad_norm": 0.059055037796497345,
      "learning_rate": 0.00016175710594315245,
      "loss": 0.2524,
      "step": 375
    },
    {
      "epoch": 2.061617458279846,
      "grad_norm": 0.055032696574926376,
      "learning_rate": 0.00015917312661498708,
      "loss": 0.2595,
      "step": 400
    },
    {
      "epoch": 2.189987163029525,
      "grad_norm": 0.057603880763053894,
      "learning_rate": 0.0001565891472868217,
      "loss": 0.2466,
      "step": 425
    },
    {
      "epoch": 2.318356867779204,
      "grad_norm": 0.05668407678604126,
      "learning_rate": 0.00015400516795865634,
      "loss": 0.2481,
      "step": 450
    },
    {
      "epoch": 2.4467265725288834,
      "grad_norm": 0.06926674395799637,
      "learning_rate": 0.00015142118863049097,
      "loss": 0.2481,
      "step": 475
    },
    {
      "epoch": 2.575096277278562,
      "grad_norm": 0.058365557342767715,
      "learning_rate": 0.00014883720930232558,
      "loss": 0.2468,
      "step": 500
    },
    {
      "epoch": 2.7034659820282414,
      "grad_norm": 0.062177713960409164,
      "learning_rate": 0.0001462532299741602,
      "loss": 0.2473,
      "step": 525
    },
    {
      "epoch": 2.8318356867779206,
      "grad_norm": 0.049445223063230515,
      "learning_rate": 0.00014366925064599484,
      "loss": 0.2464,
      "step": 550
    },
    {
      "epoch": 2.9602053915275994,
      "grad_norm": 0.05920587480068207,
      "learning_rate": 0.00014108527131782947,
      "loss": 0.2474,
      "step": 575
    },
    {
      "epoch": 3.092426187419769,
      "grad_norm": 0.05740649253129959,
      "learning_rate": 0.00013850129198966408,
      "loss": 0.2538,
      "step": 600
    },
    {
      "epoch": 3.220795892169448,
      "grad_norm": 0.06382472068071365,
      "learning_rate": 0.0001359173126614987,
      "loss": 0.2434,
      "step": 625
    },
    {
      "epoch": 3.349165596919127,
      "grad_norm": 0.06392116099596024,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.2418,
      "step": 650
    },
    {
      "epoch": 3.477535301668806,
      "grad_norm": 0.0671311542391777,
      "learning_rate": 0.00013074935400516797,
      "loss": 0.2421,
      "step": 675
    },
    {
      "epoch": 3.605905006418485,
      "grad_norm": 0.06474833935499191,
      "learning_rate": 0.00012816537467700258,
      "loss": 0.2442,
      "step": 700
    },
    {
      "epoch": 3.7342747111681645,
      "grad_norm": 0.05924418941140175,
      "learning_rate": 0.0001255813953488372,
      "loss": 0.2422,
      "step": 725
    },
    {
      "epoch": 3.8626444159178432,
      "grad_norm": 0.05656075105071068,
      "learning_rate": 0.00012299741602067184,
      "loss": 0.2438,
      "step": 750
    },
    {
      "epoch": 3.9910141206675225,
      "grad_norm": 0.056377679109573364,
      "learning_rate": 0.00012041343669250647,
      "loss": 0.2437,
      "step": 775
    },
    {
      "epoch": 4.123234916559692,
      "grad_norm": 0.06688524782657623,
      "learning_rate": 0.0001178294573643411,
      "loss": 0.2463,
      "step": 800
    },
    {
      "epoch": 4.251604621309371,
      "grad_norm": 0.06372793018817902,
      "learning_rate": 0.00011524547803617572,
      "loss": 0.2387,
      "step": 825
    },
    {
      "epoch": 4.37997432605905,
      "grad_norm": 0.06891080737113953,
      "learning_rate": 0.00011266149870801035,
      "loss": 0.239,
      "step": 850
    },
    {
      "epoch": 4.508344030808729,
      "grad_norm": 0.061148036271333694,
      "learning_rate": 0.00011007751937984496,
      "loss": 0.2398,
      "step": 875
    },
    {
      "epoch": 4.636713735558408,
      "grad_norm": 0.07186292111873627,
      "learning_rate": 0.0001074935400516796,
      "loss": 0.2387,
      "step": 900
    },
    {
      "epoch": 4.7650834403080875,
      "grad_norm": 0.059658486396074295,
      "learning_rate": 0.0001049095607235142,
      "loss": 0.2388,
      "step": 925
    },
    {
      "epoch": 4.893453145057767,
      "grad_norm": 0.05982057750225067,
      "learning_rate": 0.00010232558139534885,
      "loss": 0.2405,
      "step": 950
    },
    {
      "epoch": 5.025673940949936,
      "grad_norm": 0.05801989883184433,
      "learning_rate": 9.974160206718347e-05,
      "loss": 0.2477,
      "step": 975
    },
    {
      "epoch": 5.154043645699615,
      "grad_norm": 0.07308829575777054,
      "learning_rate": 9.71576227390181e-05,
      "loss": 0.2311,
      "step": 1000
    }
  ],
  "logging_steps": 25,
  "max_steps": 1940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.7393773914750976e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
