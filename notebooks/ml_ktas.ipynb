{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the train and test data\n",
    "train_df = pd.read_csv(\"../data/kaggle/train_numeric.csv\")\n",
    "test_df  = pd.read_csv(\"../data/kaggle/test_numeric.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 688 entries, 0 to 687\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Group                     688 non-null    int64  \n",
      " 1   Sex                       688 non-null    int64  \n",
      " 2   Age                       688 non-null    int64  \n",
      " 3   Patients number per hour  688 non-null    int64  \n",
      " 4   Arrival mode              688 non-null    int64  \n",
      " 5   Injury                    688 non-null    int64  \n",
      " 6   Chief_complain            688 non-null    object \n",
      " 7   Mental                    688 non-null    int64  \n",
      " 8   Pain                      688 non-null    int64  \n",
      " 9   NRS_pain                  370 non-null    float64\n",
      " 10  SBP                       670 non-null    float64\n",
      " 11  DBP                       670 non-null    float64\n",
      " 12  HR                        672 non-null    float64\n",
      " 13  RR                        675 non-null    float64\n",
      " 14  BT                        674 non-null    float64\n",
      " 15  KTAS_RN                   688 non-null    int64  \n",
      " 16  Diagnosis in ED           688 non-null    object \n",
      " 17  KTAS_expert               688 non-null    int64  \n",
      " 18  Length of stay_min        688 non-null    int64  \n",
      "dtypes: float64(6), int64(11), object(2)\n",
      "memory usage: 102.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['Chief_complain','Diagnosis in ED','KTAS_RN'])\n",
    "test_df = test_df.drop(columns=['Chief_complain','Diagnosis in ED','KTAS_RN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of vital signs columns\n",
    "vital_signs_cols = ['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain']\n",
    "\n",
    "# Ensure vital signs are numeric and handle missing values\n",
    "data[vital_signs_cols] = data[vital_signs_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Normalize vital signs using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "vital_signs_normalized = scaler.fit_transform(data[vital_signs_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124160/1146406248.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_124160/1146406248.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill all NAs with the mean\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"number\"]).columns\n",
    "for col in numeric_cols:\n",
    "    train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
    "    test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression Predictions ===\n",
      "\n",
      "Accuracy: 0.4835924006908463\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.42      0.53        12\n",
      "           2       0.37      0.17      0.23       148\n",
      "           3       0.47      0.71      0.57       217\n",
      "           4       0.56      0.52      0.54       183\n",
      "           5       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.48       579\n",
      "   macro avg       0.42      0.36      0.37       579\n",
      "weighted avg       0.46      0.48      0.45       579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Optionally, drop rows with missing target values (if any)\n",
    "train_df = train_df.dropna(subset=[\"KTAS_expert\",])\n",
    "test_df  = test_df.dropna(subset=[\"KTAS_expert\", ])\n",
    "\n",
    "# Define the target column and feature set.\n",
    "# Here we assume that all columns except 'KTAS_expert' are features.\n",
    "target_col = \"KTAS_expert\"\n",
    "features = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# (Optional) Convert all features to numeric in case they are not.\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_test  = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# (Optional) Fill any remaining missing values with the median of each column.\n",
    "X_train.fillna(X_train.median(), inplace=True)\n",
    "X_test.fillna(X_test.median(), inplace=True)\n",
    "\n",
    "# Build and train the Logistic Regression model.\n",
    "# For multiclass problems, LogisticRegression can use multinomial mode.\n",
    "logreg = LogisticRegression(max_iter=1000, multi_class='auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set.\n",
    "preds_lr = logreg.predict(X_test)\n",
    "\n",
    "# Print the results.\n",
    "print(\"=== Logistic Regression Predictions ===\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, preds_lr))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Predictions ===\n",
      "\n",
      "Accuracy: 0.2970639032815199\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.04      0.17      0.07        12\n",
      "           2       0.27      0.28      0.28       148\n",
      "           3       0.34      0.59      0.43       217\n",
      "           4       0.25      0.01      0.01       183\n",
      "           5       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.30       579\n",
      "   macro avg       0.15      0.17      0.13       579\n",
      "weighted avg       0.28      0.30      0.24       579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:52:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Build and train the XGBoost model.\n",
    "# Setting 'use_label_encoder' to False to avoid warnings and specifying an evaluation metric.\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set.\n",
    "preds_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Print the results.\n",
    "print(\"=== XGBoost Predictions ===\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, preds_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioBERT + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/kaggle/train_numeric.csv\")\n",
    "test_df  = pd.read_csv(\"../data/kaggle/test_numeric.csv\")\n",
    "train_df = train_df.drop(columns=['Chief_complain','Diagnosis in ED'])\n",
    "test_df = test_df.drop(columns=['Chief_complain','Diagnosis in ED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the pre-trained SentenceTransformer model for clinical text\n",
    "# This model is fine-tuned for biomedical and clinical text embeddings\n",
    "# model_name = 'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb'\n",
    "# model = SentenceTransformer(model_name)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
