{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the train and test data\n",
    "train_df = pd.read_csv(\"../data/kaggle/train_numeric.csv\")\n",
    "test_df  = pd.read_csv(\"../data/kaggle/test_numeric.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 688 entries, 0 to 687\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Group                     688 non-null    int64  \n",
      " 1   Sex                       688 non-null    int64  \n",
      " 2   Age                       688 non-null    int64  \n",
      " 3   Patients number per hour  688 non-null    int64  \n",
      " 4   Arrival mode              688 non-null    int64  \n",
      " 5   Injury                    688 non-null    int64  \n",
      " 6   Chief_complain            688 non-null    object \n",
      " 7   Mental                    688 non-null    int64  \n",
      " 8   Pain                      688 non-null    int64  \n",
      " 9   NRS_pain                  370 non-null    float64\n",
      " 10  SBP                       670 non-null    float64\n",
      " 11  DBP                       670 non-null    float64\n",
      " 12  HR                        672 non-null    float64\n",
      " 13  RR                        675 non-null    float64\n",
      " 14  BT                        674 non-null    float64\n",
      " 15  KTAS_RN                   688 non-null    int64  \n",
      " 16  Diagnosis in ED           688 non-null    object \n",
      " 17  KTAS_expert               688 non-null    int64  \n",
      " 18  Length of stay_min        688 non-null    int64  \n",
      "dtypes: float64(6), int64(11), object(2)\n",
      "memory usage: 102.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# List of vital signs column\n",
    "vital_signs_cols = ['NRS_pain', 'SBP', 'DBP', 'HR', 'RR', 'BT']\n",
    "\n",
    "# Normalize vital signs using Min-Max scaling for train data\n",
    "scaler = MinMaxScaler()\n",
    "train_df[vital_signs_cols] = scaler.fit_transform(train_df[vital_signs_cols])\n",
    "\n",
    "# Use same scaler for test data to maintain consistency\n",
    "test_df[vital_signs_cols] = scaler.transform(test_df[vital_signs_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['Length of stay_min','Group','Chief_complain','Diagnosis in ED','KTAS_RN'])\n",
    "test_df = test_df.drop(columns=['Length of stay_min','Group','Chief_complain','Diagnosis in ED','KTAS_RN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create encoder for categorical variables\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Fit encoder on train data for specified columns\n",
    "train_categories = train_df[['Sex', 'Arrival mode', 'Mental']]\n",
    "test_categories = test_df[['Sex', 'Arrival mode', 'Mental']]\n",
    "\n",
    "encoder.fit(train_categories)\n",
    "\n",
    "# Transform both train and test data\n",
    "train_encoded = encoder.transform(train_categories)\n",
    "test_encoded = encoder.transform(test_categories)\n",
    "\n",
    "# Get encoded column names\n",
    "encoded_columns = encoder.get_feature_names_out(['Sex', 'Arrival mode', 'Mental'])\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_encoded_df = pd.DataFrame(train_encoded, columns=encoded_columns, index=train_df.index)\n",
    "test_encoded_df = pd.DataFrame(test_encoded, columns=encoded_columns, index=test_df.index)\n",
    "\n",
    "# Drop original columns and join encoded columns\n",
    "train_df = train_df.drop(columns=['Sex', 'Arrival mode', 'Mental']).join(train_encoded_df)\n",
    "test_df = test_df.drop(columns=['Sex', 'Arrival mode', 'Mental']).join(test_encoded_df)\n",
    "\n",
    "# Scale Age separately since it's numeric\n",
    "age_scaler = MinMaxScaler()\n",
    "train_df['Age'] = age_scaler.fit_transform(train_df[['Age']])\n",
    "test_df['Age'] = age_scaler.transform(test_df[['Age']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 688 entries, 0 to 687\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       688 non-null    float64\n",
      " 1   Patients number per hour  688 non-null    int64  \n",
      " 2   Injury                    688 non-null    int64  \n",
      " 3   Pain                      688 non-null    int64  \n",
      " 4   NRS_pain                  688 non-null    float64\n",
      " 5   SBP                       688 non-null    float64\n",
      " 6   DBP                       688 non-null    float64\n",
      " 7   HR                        688 non-null    float64\n",
      " 8   RR                        688 non-null    float64\n",
      " 9   BT                        688 non-null    float64\n",
      " 10  KTAS_expert               688 non-null    int64  \n",
      " 11  Sex_1                     688 non-null    float64\n",
      " 12  Sex_2                     688 non-null    float64\n",
      " 13  Arrival mode_1            688 non-null    float64\n",
      " 14  Arrival mode_2            688 non-null    float64\n",
      " 15  Arrival mode_3            688 non-null    float64\n",
      " 16  Arrival mode_4            688 non-null    float64\n",
      " 17  Arrival mode_5            688 non-null    float64\n",
      " 18  Arrival mode_6            688 non-null    float64\n",
      " 19  Arrival mode_7            688 non-null    float64\n",
      " 20  Mental_1                  688 non-null    float64\n",
      " 21  Mental_2                  688 non-null    float64\n",
      " 22  Mental_3                  688 non-null    float64\n",
      " 23  Mental_4                  688 non-null    float64\n",
      "dtypes: float64(20), int64(4)\n",
      "memory usage: 129.1 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "# Drop specified columns from both train and test dataframes\n",
    "train_df = train_df.drop(columns=['Patients number per hour', 'Injury', 'Pain'])\n",
    "test_df = test_df.drop(columns=['Patients number per hour', 'Injury', 'Pain'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_c/yxhjygdn79j4bxrfk18sjync0000gn/T/ipykernel_66372/1146406248.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
      "/var/folders/_c/yxhjygdn79j4bxrfk18sjync0000gn/T/ipykernel_66372/1146406248.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill all NAs with the mean\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"number\"]).columns\n",
    "for col in numeric_cols:\n",
    "    train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
    "    test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics: {'overall': {'accuracy': 0.47150259067357514, 'precision': 0.500462952576997, 'recall': 0.47150259067357514, 'f1_score': 0.4182469761820638, 'adjusted_accuracy': 0.9050086355785838, 'adjusted_precision': 0.923734415106249, 'adjusted_recall': 0.9050086355785838, 'adjusted_f1': 0.9010054221304983, 'mae': 0.6234887737478411, 'mse': 0.8134715025906736, 'quadratic_kappa': np.float64(0.36918621461764967)}, 'by_class': {'1': {'precision': 1.0, 'recall': 0.5, 'f1-score': 0.6666666666666666, 'support': 12.0}, '2': {'precision': 0.631578947368421, 'recall': 0.08108108108108109, 'f1-score': 0.1437125748502994, 'support': 148.0}, '3': {'precision': 0.46360153256704983, 'recall': 0.5576036866359447, 'f1-score': 0.5062761506276151, 'support': 217.0}, '4': {'precision': 0.45733788395904434, 'recall': 0.73224043715847, 'f1-score': 0.5630252100840336, 'support': 183.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, 'accuracy': 0.47150259067357514, 'macro avg': {'precision': 0.5105036727789031, 'recall': 0.3741850409750992, 'f1-score': 0.37593612044572294, 'support': 579.0}, 'weighted avg': {'precision': 0.500462952576997, 'recall': 0.47150259067357514, 'f1-score': 0.4182469761820638, 'support': 579.0}}}\n",
      "Evaluation complete. Metrics and plots saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Optionally, drop rows with missing target values (if any)\n",
    "train_df = train_df.dropna(subset=[\"KTAS_expert\",])\n",
    "test_df  = test_df.dropna(subset=[\"KTAS_expert\", ])\n",
    "\n",
    "# Define the target column and feature set.\n",
    "# Here we assume that all columns except 'KTAS_expert' are features.\n",
    "target_col = \"KTAS_expert\"\n",
    "features = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# Build and train the Logistic Regression model.\n",
    "# For multiclass problems, LogisticRegression can use multinomial mode.\n",
    "logreg = LogisticRegression(max_iter=1000, multi_class='auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set.\n",
    "preds_lr = logreg.predict(X_test)\n",
    "\n",
    "# Print the results.\n",
    "metrics = utils.evaluate_predictions(preds_lr, y_test, ordinal=True, by_class=True)\n",
    "print(\"Overall Metrics:\", metrics)\n",
    "output_filepath = \"../results/Triage-KTAS/Triage-KTAS_LogReg\"\n",
    "utils.save_metrics(metrics, output_filepath)\n",
    "print(\"Evaluation complete. Metrics and plots saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "import utils.utils as utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:10:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics: {'overall': {'accuracy': 0.34196891191709844, 'precision': 0.3882290643130567, 'recall': 0.34196891191709844, 'f1_score': 0.2907779324106367, 'adjusted_accuracy': 0.772020725388601, 'adjusted_precision': 0.82223869589665, 'adjusted_recall': 0.772020725388601, 'adjusted_f1': 0.7412777747224233, 'mae': 0.9119170984455959, 'mse': 1.4749568221070812, 'quadratic_kappa': np.float64(0.05918862044165041)}, 'by_class': {'0': {'precision': 1.0, 'recall': 0.16666666666666666, 'f1-score': 0.2857142857142857, 'support': 12.0}, '1': {'precision': 0.4, 'recall': 0.06756756756756757, 'f1-score': 0.11560693641618497, 'support': 148.0}, '2': {'precision': 0.4298245614035088, 'recall': 0.22580645161290322, 'f1-score': 0.29607250755287007, 'support': 217.0}, '3': {'precision': 0.3238095238095238, 'recall': 0.7431693989071039, 'f1-score': 0.45107794361525705, 'support': 183.0}, '4': {'precision': 0.05555555555555555, 'recall': 0.05263157894736842, 'f1-score': 0.05405405405405406, 'support': 19.0}, 'accuracy': 0.34196891191709844, 'macro avg': {'precision': 0.4418379281537176, 'recall': 0.2511683327403219, 'f1-score': 0.2405051454705304, 'support': 579.0}, 'weighted avg': {'precision': 0.3882290643130567, 'recall': 0.34196891191709844, 'f1-score': 0.2907779324106367, 'support': 579.0}}}\n",
      "Evaluation complete. Metrics and plots saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Build and train the XGBoost model.\n",
    "# Setting 'use_label_encoder' to False to avoid warnings and specifying an evaluation metric.\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set.\n",
    "preds_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Print the results.\n",
    "metrics = utils.evaluate_predictions(preds_xgb, y_test, ordinal=True, by_class=True)\n",
    "print(\"Overall Metrics:\", metrics)\n",
    "output_filepath = \"../results/Triage-KTAS/Triage-KTAS_XGB\"\n",
    "utils.save_metrics(metrics, output_filepath)\n",
    "print(\"Evaluation complete. Metrics and plots saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioBERT + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test data\n",
    "train_df = pd.read_csv(\"../data/kaggle/train_numeric.csv\")\n",
    "test_df  = pd.read_csv(\"../data/kaggle/test_numeric.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/kaggle/train_numeric.csv\")\n",
    "test_df  = pd.read_csv(\"../data/kaggle/test_numeric.csv\")\n",
    "train_df = train_df.drop(columns=['Length of stay_min','Group','KTAS_RN'])\n",
    "test_df = test_df.drop(columns=['Length of stay_min','Group','KTAS_RN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the pre-trained SentenceTransformer model for clinical text\n",
    "# This model is fine-tuned for biomedical and clinical text embeddings\n",
    "model_name = 'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing symptom embeddings in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 22/22 [00:03<00:00,  5.69it/s]\n",
      "Batches: 100%|██████████| 19/19 [00:00<00:00, 25.50it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 22.67it/s]\n",
      "Batches: 100%|██████████| 19/19 [00:01<00:00, 15.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process chief complaints in batches of 10,000\n",
    "print(\"Computing symptom embeddings in batches...\")\n",
    "# Create embeddings for the chiefcomplaint column for train and test datasets\n",
    "train_texts = train_df['Chief_complain'].tolist()\n",
    "test_texts = test_df['Chief_complain'].tolist()\n",
    "\n",
    "# Use the model to encode the texts; show_progress_bar=True gives you a progress update\n",
    "train_chief_embeddings = model.encode(train_texts, show_progress_bar=True)\n",
    "test_chief_embeddings = model.encode(test_texts, show_progress_bar=True)\n",
    "\n",
    "# Save chief complaint embeddings\n",
    "np.save('../data/kaggle/KTAS_train_chiefcomplaint_embeddings.npy', train_chief_embeddings)\n",
    "np.save('../data/kaggle/KTAS_test_chiefcomplaint_embeddings.npy', test_chief_embeddings)\n",
    "\n",
    "# Create embeddings for diagnosis column\n",
    "train_texts = train_df['Diagnosis in ED'].tolist()\n",
    "test_texts = test_df['Diagnosis in ED'].tolist()\n",
    "\n",
    "# Use the model to encode the texts; show_progress_bar=True gives you a progress update\n",
    "train_diagnosis_embeddings = model.encode(train_texts, show_progress_bar=True)\n",
    "test_diagnosis_embeddings = model.encode(test_texts, show_progress_bar=True)\n",
    "\n",
    "# Save diagnosis embeddings\n",
    "np.save('../data/kaggle/KTAS_train_diagnosis_embeddings.npy', train_diagnosis_embeddings)\n",
    "np.save('../data/kaggle/KTAS_test_diagnosis_embeddings.npy', test_diagnosis_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing PCA on train chief complaint embeddings...\n",
      "Performing PCA on test chief complaint embeddings...\n",
      "Performing PCA on train diagnosis embeddings...\n",
      "Performing PCA on test diagnosis embeddings...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ----- For Chief Complaint Embeddings -----\n",
    "\n",
    "# Perform PCA on train chief complaint embeddings\n",
    "print(\"Performing PCA on train chief complaint embeddings...\")\n",
    "pca_chief = PCA(n_components=25)\n",
    "train_embeddings = pca_chief.fit_transform(train_chief_embeddings)\n",
    "\n",
    "# Transform test chief complaint embeddings using same PCA\n",
    "print(\"Performing PCA on test chief complaint embeddings...\")\n",
    "test_embeddings = pca_chief.transform(test_chief_embeddings)\n",
    "\n",
    "# ----- For Diagnosis Embeddings -----\n",
    "\n",
    "# Perform PCA on train diagnosis embeddings\n",
    "print(\"Performing PCA on train diagnosis embeddings...\")\n",
    "pca_diag = PCA(n_components=25)\n",
    "train_embeddings_two = pca_diag.fit_transform(train_diagnosis_embeddings)\n",
    "\n",
    "# Transform test diagnosis embeddings using same PCA\n",
    "print(\"Performing PCA on test diagnosis embeddings...\")\n",
    "test_embeddings_two = pca_diag.transform(test_diagnosis_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_c/yxhjygdn79j4bxrfk18sjync0000gn/T/ipykernel_66372/1146406248.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
      "/var/folders/_c/yxhjygdn79j4bxrfk18sjync0000gn/T/ipykernel_66372/1146406248.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill all NAs with the mean\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"number\"]).columns\n",
    "for col in numeric_cols:\n",
    "    train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
    "    test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['Chief_complain','Diagnosis in ED'])\n",
    "test_df = test_df.drop(columns=['Chief_complain','Diagnosis in ED'])\n",
    "\n",
    "# Define the target column and feature set.\n",
    "# Here we assume that all columns except 'KTAS_expert' are features.\n",
    "target_col = \"KTAS_expert\"\n",
    "features = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target_col].values\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target_col].values\n",
    "\n",
    "# # (Optional) Convert all features to numeric in case they are not.\n",
    "# X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "# X_test  = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# # (Optional) Fill any remaining missing values with the median of each column.\n",
    "# X_train.fillna(X_train.median(), inplace=True)\n",
    "# X_test.fillna(X_test.median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine vitals data with both chief complaint and diagnosis embeddings\n",
    "X_train = np.hstack([X_train.values, train_embeddings, train_embeddings_two])  # Combine vitals, complaint embeddings, and diagnosis embeddings\n",
    "X_test = np.hstack([X_test.values, test_embeddings, test_embeddings_two])  # Combine test vitals and both types of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics: {'overall': {'accuracy': 0.3298791018998273, 'precision': 0.31228373178195923, 'recall': 0.3298791018998273, 'f1_score': 0.2605722812103006, 'adjusted_accuracy': 0.8635578583765112, 'adjusted_precision': 0.8832116659259983, 'adjusted_recall': 0.8635578583765112, 'adjusted_f1': 0.8531444782160913, 'mae': 0.8238341968911918, 'mse': 1.1692573402417963, 'quadratic_kappa': np.float64(0.07352555360430724)}, 'by_class': {'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12.0}, '2': {'precision': 0.2719298245614035, 'recall': 0.20945945945945946, 'f1-score': 0.2366412213740458, 'support': 148.0}, '3': {'precision': 0.36666666666666664, 'recall': 0.7096774193548387, 'f1-score': 0.4835164835164835, 'support': 217.0}, '4': {'precision': 0.3333333333333333, 'recall': 0.03278688524590164, 'f1-score': 0.05970149253731343, 'support': 183.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, 'accuracy': 0.3298791018998273, 'macro avg': {'precision': 0.16198830409356724, 'recall': 0.15865396067669998, 'f1-score': 0.12997653290464045, 'support': 579.0}, 'weighted avg': {'precision': 0.31228373178195923, 'recall': 0.3298791018998273, 'f1-score': 0.2605722812103006, 'support': 579.0}}}\n",
      "Evaluation complete. Metrics and plots saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/envs/llm-medical-bias/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import utils.utils as utils \n",
    "\n",
    "metrics_results = []\n",
    "\n",
    "# Train an MLP classifier\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(500, 500),  # Small network\n",
    "    random_state=42,\n",
    "    early_stopping=True\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Print the results.\n",
    "metrics = utils.evaluate_predictions(preds_xgb, y_test, ordinal=True, by_class=True)\n",
    "print(\"Overall Metrics:\", metrics)\n",
    "output_filepath = \"../results/Triage-KTAS/Triage-KTAS_BioBERT\"\n",
    "utils.save_metrics(metrics, output_filepath)\n",
    "print(\"Evaluation complete. Metrics and plots saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-medical-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
