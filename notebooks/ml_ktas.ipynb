{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the train and test data\n",
    "train_df = pd.read_csv(\"../data/kaggle/train_numeric.csv\")\n",
    "test_df  = pd.read_csv(\"../data/kaggle/test_numeric.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 688 entries, 0 to 687\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Group                     688 non-null    int64  \n",
      " 1   Sex                       688 non-null    int64  \n",
      " 2   Age                       688 non-null    int64  \n",
      " 3   Patients number per hour  688 non-null    int64  \n",
      " 4   Arrival mode              688 non-null    int64  \n",
      " 5   Injury                    688 non-null    int64  \n",
      " 6   Chief_complain            688 non-null    object \n",
      " 7   Mental                    688 non-null    int64  \n",
      " 8   Pain                      688 non-null    int64  \n",
      " 9   NRS_pain                  370 non-null    float64\n",
      " 10  SBP                       670 non-null    float64\n",
      " 11  DBP                       670 non-null    float64\n",
      " 12  HR                        672 non-null    float64\n",
      " 13  RR                        675 non-null    float64\n",
      " 14  BT                        674 non-null    float64\n",
      " 15  KTAS_RN                   688 non-null    int64  \n",
      " 16  Diagnosis in ED           688 non-null    object \n",
      " 17  KTAS_expert               688 non-null    int64  \n",
      " 18  Length of stay_min        688 non-null    int64  \n",
      "dtypes: float64(6), int64(11), object(2)\n",
      "memory usage: 102.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['Length of stay_min','Group','Chief_complain','Diagnosis in ED','KTAS_RN'])\n",
    "test_df = test_df.drop(columns=['Length of stay_min','Group','Chief_complain','Diagnosis in ED','KTAS_RN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 688 entries, 0 to 687\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Sex                       688 non-null    int64  \n",
      " 1   Age                       688 non-null    int64  \n",
      " 2   Patients number per hour  688 non-null    int64  \n",
      " 3   Arrival mode              688 non-null    int64  \n",
      " 4   Injury                    688 non-null    int64  \n",
      " 5   Mental                    688 non-null    int64  \n",
      " 6   Pain                      688 non-null    int64  \n",
      " 7   NRS_pain                  370 non-null    float64\n",
      " 8   SBP                       670 non-null    float64\n",
      " 9   DBP                       670 non-null    float64\n",
      " 10  HR                        672 non-null    float64\n",
      " 11  RR                        675 non-null    float64\n",
      " 12  BT                        674 non-null    float64\n",
      " 13  KTAS_expert               688 non-null    int64  \n",
      "dtypes: float64(6), int64(8)\n",
      "memory usage: 75.4 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of vital signs columns\n",
    "vital_signs_cols = ['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain']\n",
    "\n",
    "# Ensure vital signs are numeric and handle missing values\n",
    "data[vital_signs_cols] = data[vital_signs_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Normalize vital signs using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "vital_signs_normalized = scaler.fit_transform(data[vital_signs_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_132386/1146406248.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_132386/1146406248.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill all NAs with the mean\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"number\"]).columns\n",
    "for col in numeric_cols:\n",
    "    train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
    "    test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression Predictions ===\n",
      "\n",
      "Accuracy: 0.5146804835924007\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.67      0.70        12\n",
      "           2       0.59      0.09      0.15       148\n",
      "           3       0.55      0.66      0.60       217\n",
      "           4       0.49      0.73      0.59       183\n",
      "           5       0.06      0.05      0.05        19\n",
      "\n",
      "    accuracy                           0.51       579\n",
      "   macro avg       0.48      0.44      0.42       579\n",
      "weighted avg       0.53      0.51      0.47       579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Optionally, drop rows with missing target values (if any)\n",
    "train_df = train_df.dropna(subset=[\"KTAS_expert\",])\n",
    "test_df  = test_df.dropna(subset=[\"KTAS_expert\", ])\n",
    "\n",
    "# Define the target column and feature set.\n",
    "# Here we assume that all columns except 'KTAS_expert' are features.\n",
    "target_col = \"KTAS_expert\"\n",
    "features = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# Build and train the Logistic Regression model.\n",
    "# For multiclass problems, LogisticRegression can use multinomial mode.\n",
    "logreg = LogisticRegression(max_iter=1000, multi_class='auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set.\n",
    "preds_lr = logreg.predict(X_test)\n",
    "\n",
    "# Print the results.\n",
    "print(\"=== Logistic Regression Predictions ===\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, preds_lr))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Predictions ===\n",
      "\n",
      "Accuracy: 0.30569948186528495\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.03      0.08      0.04        12\n",
      "           2       0.26      0.20      0.22       148\n",
      "           3       0.34      0.64      0.44       217\n",
      "           4       0.53      0.04      0.08       183\n",
      "           5       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.31       579\n",
      "   macro avg       0.19      0.16      0.13       579\n",
      "weighted avg       0.36      0.31      0.25       579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:26:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/josephL/miniconda3/envs/llm-bias/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Build and train the XGBoost model.\n",
    "# Setting 'use_label_encoder' to False to avoid warnings and specifying an evaluation metric.\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set.\n",
    "preds_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Print the results.\n",
    "print(\"=== XGBoost Predictions ===\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, preds_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioBERT + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/kaggle/train_numeric.csv\")\n",
    "test_df  = pd.read_csv(\"../data/kaggle/test_numeric.csv\")\n",
    "train_df = train_df.drop(columns=['Group','KTAS_RN'])\n",
    "test_df = test_df.drop(columns=['Group','KTAS_RN'])\n",
    "\n",
    "# Optionally, drop rows with missing target values (if any)\n",
    "train_df = train_df.dropna(subset=[\"Diagnosis in ED\",\"Chief_complain\"])\n",
    "test_df  = test_df.dropna(subset=[\"Diagnosis in ED\",\"Chief_complain\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the pre-trained SentenceTransformer model for clinical text\n",
    "# This model is fine-tuned for biomedical and clinical text embeddings\n",
    "model_name = 'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing symptom embeddings in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 136.95it/s]\n",
      "Batches: 100%|██████████| 19/19 [00:00<00:00, 154.58it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 150.44it/s]\n",
      "Batches: 100%|██████████| 19/19 [00:00<00:00, 127.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process chief complaints in batches of 10,000\n",
    "print(\"Computing symptom embeddings in batches...\")\n",
    "# Create embeddings for the chiefcomplaint column for train and test datasets\n",
    "train_texts = train_df['Chief_complain'].tolist()\n",
    "test_texts = test_df['Chief_complain'].tolist()\n",
    "\n",
    "# Use the model to encode the texts; show_progress_bar=True gives you a progress update\n",
    "train_embeddings = model.encode(train_texts, show_progress_bar=True)\n",
    "test_embeddings = model.encode(test_texts, show_progress_bar=True)\n",
    "\n",
    "train_texts = train_df['Diagnosis in ED'].tolist()\n",
    "test_texts = test_df['Diagnosis in ED'].tolist()\n",
    "\n",
    "# Use the model to encode the texts; show_progress_bar=True gives you a progress update\n",
    "train_embeddings_two = model.encode(train_texts, show_progress_bar=True)\n",
    "test_embeddings_two = model.encode(test_texts, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577, 768)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings as .npy files using NumPy\n",
    "np.save('../data/kaggle/KTAS_train_chiefcomplaint_embeddings.npy', train_embeddings)\n",
    "np.save('../data/kaggle/KTAS_test_chiefcomplaint_embeddings.npy', test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing PCA on train symptom embeddings...\n",
      "Performing PCA on test symptom embeddings...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ----- For the Training Set -----\n",
    "\n",
    "# Convert train symptom embeddings to a numpy array\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "\n",
    "# Perform PCA on train symptom embeddings to reduce dimensionality to 10\n",
    "print(\"Performing PCA on train symptom embeddings...\")\n",
    "pca = PCA(n_components=25)\n",
    "train_embeddings = pca.fit_transform(train_embeddings)\n",
    "\n",
    "# Save the reduced and comprehensive train embeddings to disk\n",
    "# np.save('../data/mimic-iv-private/train_symptom_embeddings_reduced.npy', train_symptom_embeddings_reduced)\n",
    "\n",
    "\n",
    "# ----- For the Test Set -----\n",
    "\n",
    "# Convert test symptom embeddings to a numpy array\n",
    "test_embeddings = np.array(test_embeddings)\n",
    "\n",
    "# Use the same PCA transformation fitted on the training set to transform the test symptom embeddings\n",
    "print(\"Performing PCA on test symptom embeddings...\")\n",
    "test_embeddings = pca.transform(test_embeddings)\n",
    "\n",
    "# Save the reduced and comprehensive test embeddings to disk\n",
    "# np.save('../data/mimic-iv-private/test_symptom_embeddings_reduced.npy', test_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_132386/1146406248.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_132386/1146406248.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill all NAs with the mean\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"number\"]).columns\n",
    "for col in numeric_cols:\n",
    "    train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
    "    test_df[col].fillna(test_df[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['Chief_complain','Diagnosis in ED'])\n",
    "test_df = test_df.drop(columns=['Chief_complain','Diagnosis in ED'])\n",
    "\n",
    "# Define the target column and feature set.\n",
    "# Here we assume that all columns except 'KTAS_expert' are features.\n",
    "target_col = \"KTAS_expert\"\n",
    "features = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target_col].values\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target_col].values\n",
    "\n",
    "# # (Optional) Convert all features to numeric in case they are not.\n",
    "# X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "# X_test  = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# # (Optional) Fill any remaining missing values with the median of each column.\n",
    "# X_train.fillna(X_train.median(), inplace=True)\n",
    "# X_test.fillna(X_test.median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack([X_train.values, train_embeddings, train_embeddings_two])  # Combine vitals and embeddings\n",
    "X_test = np.hstack([X_test.values, test_embeddings, test_embeddings_two])  # Replace with inference embeddings if different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overall': {'accuracy': 0.44540727902946275, 'precision': 0.5118035166261915, 'recall': 0.44540727902946275, 'f1_score': 0.38962643268049574, 'adjusted_accuracy': 0.949740034662045, 'adjusted_precision': 0.949071457079619, 'adjusted_recall': 0.949740034662045, 'adjusted_f1': 0.9459780814305845, 'mae': 0.610051993067591, 'mse': 0.7348353552859619, 'quadratic_kappa': np.float64(0.3550863318834848)}, 'by_class': {'1': {'precision': 0.375, 'recall': 0.25, 'f1-score': 0.3, 'support': 12.0}, '2': {'precision': 0.4909090909090909, 'recall': 0.1836734693877551, 'f1-score': 0.26732673267326734, 'support': 147.0}, '3': {'precision': 0.42247191011235957, 'recall': 0.8663594470046083, 'f1-score': 0.56797583081571, 'support': 217.0}, '4': {'precision': 0.6730769230769231, 'recall': 0.19230769230769232, 'f1-score': 0.29914529914529914, 'support': 182.0}, '5': {'precision': 0.23529411764705882, 'recall': 0.21052631578947367, 'f1-score': 0.2222222222222222, 'support': 19.0}, 'accuracy': 0.44540727902946275, 'macro avg': {'precision': 0.4393504083490865, 'recall': 0.3405733848979059, 'f1-score': 0.33133401697129977, 'support': 577.0}, 'weighted avg': {'precision': 0.5118035166261915, 'recall': 0.44540727902946275, 'f1-score': 0.38962643268049574, 'support': 577.0}}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import utils.utils as utils \n",
    "\n",
    "metrics_results = []\n",
    "\n",
    "# Train an MLP classifier\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(1000, 1000),  # Small network\n",
    "    random_state=42,\n",
    "    early_stopping=True\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "evaluation_metrics = utils.evaluate_predictions(y_pred,y_test,ordinal=True, by_class=True)\n",
    "\n",
    "# Store results\n",
    "metrics_results.append(evaluation_metrics)\n",
    "\n",
    "# Display results\n",
    "print(metrics_results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
