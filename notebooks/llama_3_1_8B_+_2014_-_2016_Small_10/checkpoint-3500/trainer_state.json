{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 18.041078305519896,
  "eval_steps": 500,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5134788189987163,
      "grad_norm": 0.08045893907546997,
      "learning_rate": 0.000196078431372549,
      "loss": 0.3382,
      "step": 100
    },
    {
      "epoch": 1.030808729139923,
      "grad_norm": 0.0754295215010643,
      "learning_rate": 0.00019195046439628483,
      "loss": 0.2624,
      "step": 200
    },
    {
      "epoch": 1.5442875481386393,
      "grad_norm": 0.0721912831068039,
      "learning_rate": 0.00018782249742002065,
      "loss": 0.2528,
      "step": 300
    },
    {
      "epoch": 2.061617458279846,
      "grad_norm": 0.054588332772254944,
      "learning_rate": 0.00018369453044375647,
      "loss": 0.2542,
      "step": 400
    },
    {
      "epoch": 2.575096277278562,
      "grad_norm": 0.051989100873470306,
      "learning_rate": 0.00017956656346749226,
      "loss": 0.2475,
      "step": 500
    },
    {
      "epoch": 3.092426187419769,
      "grad_norm": 0.05474644526839256,
      "learning_rate": 0.00017543859649122806,
      "loss": 0.2491,
      "step": 600
    },
    {
      "epoch": 3.605905006418485,
      "grad_norm": 0.05949830263853073,
      "learning_rate": 0.00017131062951496388,
      "loss": 0.2433,
      "step": 700
    },
    {
      "epoch": 4.123234916559692,
      "grad_norm": 0.06071716547012329,
      "learning_rate": 0.0001671826625386997,
      "loss": 0.2445,
      "step": 800
    },
    {
      "epoch": 4.636713735558408,
      "grad_norm": 0.07795464247465134,
      "learning_rate": 0.00016305469556243552,
      "loss": 0.2399,
      "step": 900
    },
    {
      "epoch": 5.154043645699615,
      "grad_norm": 0.0612124428153038,
      "learning_rate": 0.00015892672858617134,
      "loss": 0.2406,
      "step": 1000
    },
    {
      "epoch": 5.667522464698331,
      "grad_norm": 0.05601273477077484,
      "learning_rate": 0.00015479876160990713,
      "loss": 0.2363,
      "step": 1100
    },
    {
      "epoch": 6.184852374839538,
      "grad_norm": 0.06232175603508949,
      "learning_rate": 0.00015067079463364292,
      "loss": 0.2362,
      "step": 1200
    },
    {
      "epoch": 6.698331193838254,
      "grad_norm": 0.06519893556833267,
      "learning_rate": 0.00014654282765737874,
      "loss": 0.2301,
      "step": 1300
    },
    {
      "epoch": 7.2156611039794605,
      "grad_norm": 0.08512939512729645,
      "learning_rate": 0.00014241486068111456,
      "loss": 0.2275,
      "step": 1400
    },
    {
      "epoch": 7.729139922978177,
      "grad_norm": 0.07844804227352142,
      "learning_rate": 0.00013828689370485038,
      "loss": 0.2206,
      "step": 1500
    },
    {
      "epoch": 8.246469833119384,
      "grad_norm": 0.14022032916545868,
      "learning_rate": 0.00013415892672858618,
      "loss": 0.2158,
      "step": 1600
    },
    {
      "epoch": 8.7599486521181,
      "grad_norm": 0.1036112830042839,
      "learning_rate": 0.00013003095975232197,
      "loss": 0.2093,
      "step": 1700
    },
    {
      "epoch": 9.277278562259307,
      "grad_norm": 0.14289629459381104,
      "learning_rate": 0.0001259029927760578,
      "loss": 0.199,
      "step": 1800
    },
    {
      "epoch": 9.790757381258024,
      "grad_norm": 0.1234673485159874,
      "learning_rate": 0.00012177502579979361,
      "loss": 0.1906,
      "step": 1900
    },
    {
      "epoch": 10.30808729139923,
      "grad_norm": 0.15692469477653503,
      "learning_rate": 0.00011764705882352942,
      "loss": 0.1739,
      "step": 2000
    },
    {
      "epoch": 10.821566110397946,
      "grad_norm": 0.16650722920894623,
      "learning_rate": 0.00011351909184726523,
      "loss": 0.1638,
      "step": 2100
    },
    {
      "epoch": 11.338896020539153,
      "grad_norm": 0.20578889548778534,
      "learning_rate": 0.00010939112487100103,
      "loss": 0.1429,
      "step": 2200
    },
    {
      "epoch": 11.85237483953787,
      "grad_norm": 0.1717291921377182,
      "learning_rate": 0.00010526315789473685,
      "loss": 0.1333,
      "step": 2300
    },
    {
      "epoch": 12.369704749679077,
      "grad_norm": 0.200678750872612,
      "learning_rate": 0.00010113519091847265,
      "loss": 0.111,
      "step": 2400
    },
    {
      "epoch": 12.883183568677792,
      "grad_norm": 0.2036794126033783,
      "learning_rate": 9.700722394220847e-05,
      "loss": 0.1042,
      "step": 2500
    },
    {
      "epoch": 13.400513478818999,
      "grad_norm": 0.22953398525714874,
      "learning_rate": 9.287925696594427e-05,
      "loss": 0.0812,
      "step": 2600
    },
    {
      "epoch": 13.913992297817716,
      "grad_norm": 0.20256440341472626,
      "learning_rate": 8.875128998968009e-05,
      "loss": 0.0765,
      "step": 2700
    },
    {
      "epoch": 14.431322207958921,
      "grad_norm": 0.17151519656181335,
      "learning_rate": 8.462332301341591e-05,
      "loss": 0.0542,
      "step": 2800
    },
    {
      "epoch": 14.944801026957638,
      "grad_norm": 0.17493347823619843,
      "learning_rate": 8.04953560371517e-05,
      "loss": 0.0528,
      "step": 2900
    },
    {
      "epoch": 15.462130937098845,
      "grad_norm": 0.1835145354270935,
      "learning_rate": 7.636738906088752e-05,
      "loss": 0.0346,
      "step": 3000
    },
    {
      "epoch": 15.975609756097562,
      "grad_norm": 0.201103076338768,
      "learning_rate": 7.223942208462333e-05,
      "loss": 0.0332,
      "step": 3100
    },
    {
      "epoch": 16.49293966623877,
      "grad_norm": 0.1340571641921997,
      "learning_rate": 6.811145510835913e-05,
      "loss": 0.0198,
      "step": 3200
    },
    {
      "epoch": 17.010269576379976,
      "grad_norm": 0.08986303955316544,
      "learning_rate": 6.398348813209495e-05,
      "loss": 0.0205,
      "step": 3300
    },
    {
      "epoch": 17.52374839537869,
      "grad_norm": 0.14034512639045715,
      "learning_rate": 5.985552115583075e-05,
      "loss": 0.0133,
      "step": 3400
    },
    {
      "epoch": 18.041078305519896,
      "grad_norm": 0.12117109447717667,
      "learning_rate": 5.5727554179566566e-05,
      "loss": 0.0146,
      "step": 3500
    }
  ],
  "logging_steps": 100,
  "max_steps": 4850,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3088753383228047e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
