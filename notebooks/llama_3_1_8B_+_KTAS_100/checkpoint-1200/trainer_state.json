{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 92.3265306122449,
  "eval_steps": 500,
  "global_step": 1200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.9795918367346939,
      "grad_norm": 0.11823751032352448,
      "learning_rate": 0.00019665271966527197,
      "loss": 0.5777,
      "step": 25
    },
    {
      "epoch": 3.8979591836734695,
      "grad_norm": 0.11023004353046417,
      "learning_rate": 0.00019246861924686193,
      "loss": 0.2757,
      "step": 50
    },
    {
      "epoch": 5.816326530612245,
      "grad_norm": 0.1010163351893425,
      "learning_rate": 0.0001882845188284519,
      "loss": 0.2397,
      "step": 75
    },
    {
      "epoch": 7.73469387755102,
      "grad_norm": 0.0946161076426506,
      "learning_rate": 0.00018410041841004183,
      "loss": 0.2171,
      "step": 100
    },
    {
      "epoch": 9.653061224489797,
      "grad_norm": 0.14608903229236603,
      "learning_rate": 0.0001799163179916318,
      "loss": 0.1925,
      "step": 125
    },
    {
      "epoch": 11.571428571428571,
      "grad_norm": 0.20993846654891968,
      "learning_rate": 0.00017573221757322176,
      "loss": 0.1499,
      "step": 150
    },
    {
      "epoch": 13.489795918367347,
      "grad_norm": 0.24003660678863525,
      "learning_rate": 0.00017154811715481172,
      "loss": 0.0976,
      "step": 175
    },
    {
      "epoch": 15.408163265306122,
      "grad_norm": 0.2541518211364746,
      "learning_rate": 0.00016736401673640169,
      "loss": 0.056,
      "step": 200
    },
    {
      "epoch": 17.3265306122449,
      "grad_norm": 0.21392937004566193,
      "learning_rate": 0.00016317991631799162,
      "loss": 0.0315,
      "step": 225
    },
    {
      "epoch": 19.244897959183675,
      "grad_norm": 0.1528143286705017,
      "learning_rate": 0.00015899581589958158,
      "loss": 0.0156,
      "step": 250
    },
    {
      "epoch": 21.163265306122447,
      "grad_norm": 0.08341889828443527,
      "learning_rate": 0.00015481171548117155,
      "loss": 0.0126,
      "step": 275
    },
    {
      "epoch": 23.081632653061224,
      "grad_norm": 0.10520336031913757,
      "learning_rate": 0.0001506276150627615,
      "loss": 0.0111,
      "step": 300
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.2321915477514267,
      "learning_rate": 0.00014644351464435147,
      "loss": 0.0104,
      "step": 325
    },
    {
      "epoch": 26.979591836734695,
      "grad_norm": 0.037246543914079666,
      "learning_rate": 0.0001422594142259414,
      "loss": 0.006,
      "step": 350
    },
    {
      "epoch": 28.897959183673468,
      "grad_norm": 0.03676136955618858,
      "learning_rate": 0.00013807531380753137,
      "loss": 0.0043,
      "step": 375
    },
    {
      "epoch": 30.816326530612244,
      "grad_norm": 0.02423718199133873,
      "learning_rate": 0.00013389121338912134,
      "loss": 0.0038,
      "step": 400
    },
    {
      "epoch": 32.734693877551024,
      "grad_norm": 0.02125604823231697,
      "learning_rate": 0.0001297071129707113,
      "loss": 0.0037,
      "step": 425
    },
    {
      "epoch": 34.6530612244898,
      "grad_norm": 0.028115997090935707,
      "learning_rate": 0.00012552301255230126,
      "loss": 0.0038,
      "step": 450
    },
    {
      "epoch": 36.57142857142857,
      "grad_norm": 0.03510080650448799,
      "learning_rate": 0.00012133891213389121,
      "loss": 0.0038,
      "step": 475
    },
    {
      "epoch": 38.48979591836735,
      "grad_norm": 0.023324279114603996,
      "learning_rate": 0.00011715481171548118,
      "loss": 0.0033,
      "step": 500
    },
    {
      "epoch": 40.40816326530612,
      "grad_norm": 0.09673000127077103,
      "learning_rate": 0.00011297071129707113,
      "loss": 0.0058,
      "step": 525
    },
    {
      "epoch": 42.326530612244895,
      "grad_norm": 0.025975054129958153,
      "learning_rate": 0.00010878661087866109,
      "loss": 0.0051,
      "step": 550
    },
    {
      "epoch": 44.244897959183675,
      "grad_norm": 0.027954701334238052,
      "learning_rate": 0.00010460251046025104,
      "loss": 0.0035,
      "step": 575
    },
    {
      "epoch": 46.16326530612245,
      "grad_norm": 0.08514522016048431,
      "learning_rate": 0.000100418410041841,
      "loss": 0.0043,
      "step": 600
    },
    {
      "epoch": 48.08163265306123,
      "grad_norm": 0.02142772078514099,
      "learning_rate": 9.623430962343097e-05,
      "loss": 0.0055,
      "step": 625
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.07613861560821533,
      "learning_rate": 9.205020920502092e-05,
      "loss": 0.0034,
      "step": 650
    },
    {
      "epoch": 51.97959183673469,
      "grad_norm": 0.020725930109620094,
      "learning_rate": 8.786610878661088e-05,
      "loss": 0.0031,
      "step": 675
    },
    {
      "epoch": 53.89795918367347,
      "grad_norm": 0.01598329469561577,
      "learning_rate": 8.368200836820084e-05,
      "loss": 0.0029,
      "step": 700
    },
    {
      "epoch": 55.816326530612244,
      "grad_norm": 0.03045370616018772,
      "learning_rate": 7.949790794979079e-05,
      "loss": 0.0031,
      "step": 725
    },
    {
      "epoch": 57.734693877551024,
      "grad_norm": 0.018099665641784668,
      "learning_rate": 7.531380753138076e-05,
      "loss": 0.0029,
      "step": 750
    },
    {
      "epoch": 59.6530612244898,
      "grad_norm": 0.026634996756911278,
      "learning_rate": 7.11297071129707e-05,
      "loss": 0.0028,
      "step": 775
    },
    {
      "epoch": 61.57142857142857,
      "grad_norm": 0.01720707304775715,
      "learning_rate": 6.694560669456067e-05,
      "loss": 0.0028,
      "step": 800
    },
    {
      "epoch": 63.48979591836735,
      "grad_norm": 0.016253503039479256,
      "learning_rate": 6.276150627615063e-05,
      "loss": 0.0029,
      "step": 825
    },
    {
      "epoch": 65.40816326530613,
      "grad_norm": 0.02658146247267723,
      "learning_rate": 5.857740585774059e-05,
      "loss": 0.0027,
      "step": 850
    },
    {
      "epoch": 67.3265306122449,
      "grad_norm": 0.01832556165754795,
      "learning_rate": 5.4393305439330545e-05,
      "loss": 0.0028,
      "step": 875
    },
    {
      "epoch": 69.24489795918367,
      "grad_norm": 0.016608083620667458,
      "learning_rate": 5.02092050209205e-05,
      "loss": 0.0027,
      "step": 900
    },
    {
      "epoch": 71.16326530612245,
      "grad_norm": 0.014286108314990997,
      "learning_rate": 4.602510460251046e-05,
      "loss": 0.0026,
      "step": 925
    },
    {
      "epoch": 73.08163265306122,
      "grad_norm": 0.01334026176482439,
      "learning_rate": 4.184100418410042e-05,
      "loss": 0.0027,
      "step": 950
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.07596337795257568,
      "learning_rate": 3.765690376569038e-05,
      "loss": 0.0029,
      "step": 975
    },
    {
      "epoch": 76.9795918367347,
      "grad_norm": 0.026785407215356827,
      "learning_rate": 3.3472803347280334e-05,
      "loss": 0.0027,
      "step": 1000
    },
    {
      "epoch": 78.89795918367346,
      "grad_norm": 0.013358856551349163,
      "learning_rate": 2.9288702928870294e-05,
      "loss": 0.0027,
      "step": 1025
    },
    {
      "epoch": 80.81632653061224,
      "grad_norm": 0.016292404383420944,
      "learning_rate": 2.510460251046025e-05,
      "loss": 0.0026,
      "step": 1050
    },
    {
      "epoch": 82.73469387755102,
      "grad_norm": 0.020148908719420433,
      "learning_rate": 2.092050209205021e-05,
      "loss": 0.0025,
      "step": 1075
    },
    {
      "epoch": 84.65306122448979,
      "grad_norm": 0.00933380238711834,
      "learning_rate": 1.6736401673640167e-05,
      "loss": 0.0025,
      "step": 1100
    },
    {
      "epoch": 86.57142857142857,
      "grad_norm": 0.018937664106488228,
      "learning_rate": 1.2552301255230125e-05,
      "loss": 0.0026,
      "step": 1125
    },
    {
      "epoch": 88.48979591836735,
      "grad_norm": 0.014817959628999233,
      "learning_rate": 8.368200836820084e-06,
      "loss": 0.0024,
      "step": 1150
    },
    {
      "epoch": 90.40816326530613,
      "grad_norm": 0.01491799671202898,
      "learning_rate": 4.184100418410042e-06,
      "loss": 0.0025,
      "step": 1175
    },
    {
      "epoch": 92.3265306122449,
      "grad_norm": 0.017207643017172813,
      "learning_rate": 0.0,
      "loss": 0.0025,
      "step": 1200
    }
  ],
  "logging_steps": 25,
  "max_steps": 1200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.175793505991393e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
