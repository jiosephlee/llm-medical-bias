{
  "os": "Linux-5.15.0-139-generic-x86_64-with-glibc2.35",
  "python": "CPython 3.11.11",
  "startedAt": "2025-08-03T22:49:36.281438Z",
  "program": "/home/josephL/llm-medical-bias/notebooks/Llama3_1_8B_tuning.ipynb",
  "codePath": "notebooks/Llama3_1_8B_tuning.ipynb",
  "git": {
    "remote": "https://github.com/jiosephlee/llm-medical-bias.git",
    "commit": "38f711137d46d2b448981ca9ff9799a45da63728"
  },
  "email": "jiosephlee@gmail.com",
  "root": "/home/josephL/llm-medical-bias/notebooks",
  "host": "ShenLab",
  "executable": "/home/josephL/miniconda3/envs/unsloth/bin/python",
  "codePathLocal": "Llama3_1_8B_tuning.ipynb",
  "cpu_count": 16,
  "cpu_count_logical": 32,
  "gpu": "NVIDIA GeForce RTX 3090",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "2014574526464",
      "used": "928152043520"
    }
  },
  "memory": {
    "total": "67338960896"
  },
  "cpu": {
    "count": 16,
    "countLogical": 32
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "12.5"
}