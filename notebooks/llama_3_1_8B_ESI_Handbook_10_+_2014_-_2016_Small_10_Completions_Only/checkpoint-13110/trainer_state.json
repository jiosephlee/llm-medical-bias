{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 13110,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01906941266209001,
      "grad_norm": 0.0,
      "learning_rate": 0.0001996947729874094,
      "loss": 0.0,
      "step": 25
    },
    {
      "epoch": 0.03813882532418002,
      "grad_norm": 0.0,
      "learning_rate": 0.00019931323922167113,
      "loss": 0.0,
      "step": 50
    },
    {
      "epoch": 0.057208237986270026,
      "grad_norm": 0.0,
      "learning_rate": 0.00019893170545593286,
      "loss": 0.0,
      "step": 75
    },
    {
      "epoch": 0.07627765064836003,
      "grad_norm": 0.0,
      "learning_rate": 0.0001985501716901946,
      "loss": 0.0,
      "step": 100
    },
    {
      "epoch": 0.09534706331045004,
      "grad_norm": 0.0,
      "learning_rate": 0.00019816863792445632,
      "loss": 0.0,
      "step": 125
    },
    {
      "epoch": 0.11441647597254005,
      "grad_norm": 0.0,
      "learning_rate": 0.00019778710415871805,
      "loss": 0.0,
      "step": 150
    },
    {
      "epoch": 0.13348588863463004,
      "grad_norm": 0.0,
      "learning_rate": 0.00019740557039297978,
      "loss": 0.0,
      "step": 175
    },
    {
      "epoch": 0.15255530129672007,
      "grad_norm": 0.0,
      "learning_rate": 0.0001970240366272415,
      "loss": 0.0,
      "step": 200
    },
    {
      "epoch": 0.17162471395881007,
      "grad_norm": 0.0,
      "learning_rate": 0.00019664250286150324,
      "loss": 0.0,
      "step": 225
    },
    {
      "epoch": 0.19069412662090007,
      "grad_norm": 0.0,
      "learning_rate": 0.000196260969095765,
      "loss": 0.0,
      "step": 250
    },
    {
      "epoch": 0.20976353928299007,
      "grad_norm": 0.0,
      "learning_rate": 0.0001958794353300267,
      "loss": 0.0,
      "step": 275
    },
    {
      "epoch": 0.2288329519450801,
      "grad_norm": 0.0,
      "learning_rate": 0.00019549790156428844,
      "loss": 0.0,
      "step": 300
    },
    {
      "epoch": 0.2479023646071701,
      "grad_norm": 0.0,
      "learning_rate": 0.0001951163677985502,
      "loss": 0.0,
      "step": 325
    },
    {
      "epoch": 0.2669717772692601,
      "grad_norm": 0.0,
      "learning_rate": 0.00019473483403281193,
      "loss": 0.0,
      "step": 350
    },
    {
      "epoch": 0.28604118993135014,
      "grad_norm": 0.0,
      "learning_rate": 0.00019435330026707363,
      "loss": 0.0,
      "step": 375
    },
    {
      "epoch": 0.30511060259344014,
      "grad_norm": 0.0,
      "learning_rate": 0.00019397176650133536,
      "loss": 0.0,
      "step": 400
    },
    {
      "epoch": 0.32418001525553014,
      "grad_norm": 0.0,
      "learning_rate": 0.00019359023273559712,
      "loss": 0.0,
      "step": 425
    },
    {
      "epoch": 0.34324942791762014,
      "grad_norm": 0.0,
      "learning_rate": 0.00019320869896985885,
      "loss": 0.0,
      "step": 450
    },
    {
      "epoch": 0.36231884057971014,
      "grad_norm": 0.0,
      "learning_rate": 0.00019282716520412055,
      "loss": 0.0,
      "step": 475
    },
    {
      "epoch": 0.38138825324180015,
      "grad_norm": 0.0,
      "learning_rate": 0.0001924456314383823,
      "loss": 0.0,
      "step": 500
    },
    {
      "epoch": 0.40045766590389015,
      "grad_norm": 0.0,
      "learning_rate": 0.00019206409767264404,
      "loss": 0.0,
      "step": 525
    },
    {
      "epoch": 0.41952707856598015,
      "grad_norm": 0.0,
      "learning_rate": 0.00019168256390690577,
      "loss": 0.0,
      "step": 550
    },
    {
      "epoch": 0.43859649122807015,
      "grad_norm": 0.0,
      "learning_rate": 0.00019130103014116748,
      "loss": 0.0,
      "step": 575
    },
    {
      "epoch": 0.4576659038901602,
      "grad_norm": 0.0,
      "learning_rate": 0.00019091949637542924,
      "loss": 0.0,
      "step": 600
    },
    {
      "epoch": 0.4767353165522502,
      "grad_norm": 0.0,
      "learning_rate": 0.00019053796260969097,
      "loss": 0.0,
      "step": 625
    },
    {
      "epoch": 0.4958047292143402,
      "grad_norm": 0.0,
      "learning_rate": 0.0001901564288439527,
      "loss": 0.0,
      "step": 650
    },
    {
      "epoch": 0.5148741418764302,
      "grad_norm": 0.0,
      "learning_rate": 0.00018977489507821443,
      "loss": 0.0,
      "step": 675
    },
    {
      "epoch": 0.5339435545385202,
      "grad_norm": 0.0,
      "learning_rate": 0.00018939336131247616,
      "loss": 0.0,
      "step": 700
    },
    {
      "epoch": 0.5530129672006102,
      "grad_norm": 0.0,
      "learning_rate": 0.0001890118275467379,
      "loss": 0.0,
      "step": 725
    },
    {
      "epoch": 0.5720823798627003,
      "grad_norm": 0.0,
      "learning_rate": 0.00018863029378099962,
      "loss": 0.0,
      "step": 750
    },
    {
      "epoch": 0.5911517925247902,
      "grad_norm": 0.0,
      "learning_rate": 0.00018824876001526135,
      "loss": 0.0,
      "step": 775
    },
    {
      "epoch": 0.6102212051868803,
      "grad_norm": 0.0,
      "learning_rate": 0.00018786722624952309,
      "loss": 0.0,
      "step": 800
    },
    {
      "epoch": 0.6292906178489702,
      "grad_norm": 0.0,
      "learning_rate": 0.00018748569248378482,
      "loss": 0.0,
      "step": 825
    },
    {
      "epoch": 0.6483600305110603,
      "grad_norm": 0.0,
      "learning_rate": 0.00018710415871804658,
      "loss": 0.0,
      "step": 850
    },
    {
      "epoch": 0.6674294431731502,
      "grad_norm": 0.0,
      "learning_rate": 0.00018672262495230828,
      "loss": 0.0,
      "step": 875
    },
    {
      "epoch": 0.6864988558352403,
      "grad_norm": 0.0,
      "learning_rate": 0.00018634109118657,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 0.7055682684973302,
      "grad_norm": 0.0,
      "learning_rate": 0.00018595955742083174,
      "loss": 0.0,
      "step": 925
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 0.0,
      "learning_rate": 0.0001855780236550935,
      "loss": 0.0,
      "step": 950
    },
    {
      "epoch": 0.7437070938215103,
      "grad_norm": 0.0,
      "learning_rate": 0.0001851964898893552,
      "loss": 0.0,
      "step": 975
    },
    {
      "epoch": 0.7627765064836003,
      "grad_norm": 0.0,
      "learning_rate": 0.00018481495612361693,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 0.7818459191456903,
      "grad_norm": 0.0,
      "learning_rate": 0.0001844334223578787,
      "loss": 0.0,
      "step": 1025
    },
    {
      "epoch": 0.8009153318077803,
      "grad_norm": 0.0,
      "learning_rate": 0.00018405188859214042,
      "loss": 0.0,
      "step": 1050
    },
    {
      "epoch": 0.8199847444698704,
      "grad_norm": 0.0,
      "learning_rate": 0.00018367035482640213,
      "loss": 0.0,
      "step": 1075
    },
    {
      "epoch": 0.8390541571319603,
      "grad_norm": 0.0,
      "learning_rate": 0.0001832888210606639,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 0.8581235697940504,
      "grad_norm": 0.0,
      "learning_rate": 0.00018290728729492562,
      "loss": 0.0,
      "step": 1125
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 0.0,
      "learning_rate": 0.00018252575352918735,
      "loss": 0.0,
      "step": 1150
    },
    {
      "epoch": 0.8962623951182304,
      "grad_norm": 0.0,
      "learning_rate": 0.00018214421976344905,
      "loss": 0.0,
      "step": 1175
    },
    {
      "epoch": 0.9153318077803204,
      "grad_norm": 0.0,
      "learning_rate": 0.0001817626859977108,
      "loss": 0.0,
      "step": 1200
    },
    {
      "epoch": 0.9344012204424104,
      "grad_norm": 0.0,
      "learning_rate": 0.00018138115223197254,
      "loss": 0.0,
      "step": 1225
    },
    {
      "epoch": 0.9534706331045004,
      "grad_norm": 0.0,
      "learning_rate": 0.00018099961846623427,
      "loss": 0.0,
      "step": 1250
    },
    {
      "epoch": 0.9725400457665904,
      "grad_norm": 0.0,
      "learning_rate": 0.000180618084700496,
      "loss": 0.0,
      "step": 1275
    },
    {
      "epoch": 0.9916094584286804,
      "grad_norm": 0.0,
      "learning_rate": 0.00018023655093475774,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 1.0106788710907704,
      "grad_norm": 0.0,
      "learning_rate": 0.00017985501716901947,
      "loss": 0.0,
      "step": 1325
    },
    {
      "epoch": 1.0297482837528604,
      "grad_norm": 0.0,
      "learning_rate": 0.0001794734834032812,
      "loss": 0.0,
      "step": 1350
    },
    {
      "epoch": 1.0488176964149505,
      "grad_norm": 0.0,
      "learning_rate": 0.00017909194963754293,
      "loss": 0.0,
      "step": 1375
    },
    {
      "epoch": 1.0678871090770405,
      "grad_norm": 0.0,
      "learning_rate": 0.00017871041587180466,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 0.0,
      "learning_rate": 0.0001783288821060664,
      "loss": 0.0,
      "step": 1425
    },
    {
      "epoch": 1.1060259344012204,
      "grad_norm": 0.0,
      "learning_rate": 0.00017794734834032812,
      "loss": 0.0,
      "step": 1450
    },
    {
      "epoch": 1.1250953470633105,
      "grad_norm": 0.0,
      "learning_rate": 0.00017756581457458985,
      "loss": 0.0,
      "step": 1475
    },
    {
      "epoch": 1.1441647597254005,
      "grad_norm": 0.0,
      "learning_rate": 0.00017718428080885158,
      "loss": 0.0,
      "step": 1500
    },
    {
      "epoch": 1.1632341723874904,
      "grad_norm": 0.0,
      "learning_rate": 0.00017680274704311332,
      "loss": 0.0,
      "step": 1525
    },
    {
      "epoch": 1.1823035850495804,
      "grad_norm": 0.0,
      "learning_rate": 0.00017642121327737507,
      "loss": 0.0,
      "step": 1550
    },
    {
      "epoch": 1.2013729977116705,
      "grad_norm": 0.0,
      "learning_rate": 0.00017603967951163678,
      "loss": 0.0,
      "step": 1575
    },
    {
      "epoch": 1.2204424103737606,
      "grad_norm": 0.0,
      "learning_rate": 0.0001756581457458985,
      "loss": 0.0,
      "step": 1600
    },
    {
      "epoch": 1.2395118230358504,
      "grad_norm": 0.0,
      "learning_rate": 0.00017527661198016027,
      "loss": 0.0,
      "step": 1625
    },
    {
      "epoch": 1.2585812356979404,
      "grad_norm": 0.0,
      "learning_rate": 0.000174895078214422,
      "loss": 0.0,
      "step": 1650
    },
    {
      "epoch": 1.2776506483600305,
      "grad_norm": 0.0,
      "learning_rate": 0.0001745135444486837,
      "loss": 0.0,
      "step": 1675
    },
    {
      "epoch": 1.2967200610221206,
      "grad_norm": 0.0,
      "learning_rate": 0.00017413201068294543,
      "loss": 0.0,
      "step": 1700
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.0,
      "learning_rate": 0.0001737504769172072,
      "loss": 0.0,
      "step": 1725
    },
    {
      "epoch": 1.3348588863463005,
      "grad_norm": 0.0,
      "learning_rate": 0.00017336894315146892,
      "loss": 0.0,
      "step": 1750
    },
    {
      "epoch": 1.3539282990083905,
      "grad_norm": 0.0,
      "learning_rate": 0.00017298740938573063,
      "loss": 0.0,
      "step": 1775
    },
    {
      "epoch": 1.3729977116704806,
      "grad_norm": 0.0,
      "learning_rate": 0.00017260587561999238,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 1.3920671243325706,
      "grad_norm": 0.0,
      "learning_rate": 0.00017222434185425412,
      "loss": 0.0,
      "step": 1825
    },
    {
      "epoch": 1.4111365369946607,
      "grad_norm": 0.0,
      "learning_rate": 0.00017184280808851585,
      "loss": 0.0,
      "step": 1850
    },
    {
      "epoch": 1.4302059496567505,
      "grad_norm": 0.0,
      "learning_rate": 0.00017146127432277758,
      "loss": 0.0,
      "step": 1875
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 0.0,
      "learning_rate": 0.0001710797405570393,
      "loss": 0.0,
      "step": 1900
    },
    {
      "epoch": 1.4683447749809306,
      "grad_norm": 0.0,
      "learning_rate": 0.00017069820679130104,
      "loss": 0.0,
      "step": 1925
    },
    {
      "epoch": 1.4874141876430205,
      "grad_norm": 0.0,
      "learning_rate": 0.00017031667302556277,
      "loss": 0.0,
      "step": 1950
    },
    {
      "epoch": 1.5064836003051107,
      "grad_norm": 0.0,
      "learning_rate": 0.0001699351392598245,
      "loss": 0.0,
      "step": 1975
    },
    {
      "epoch": 1.5255530129672006,
      "grad_norm": 0.0,
      "learning_rate": 0.00016955360549408623,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 1.5446224256292906,
      "grad_norm": 0.0,
      "learning_rate": 0.00016917207172834796,
      "loss": 0.0,
      "step": 2025
    },
    {
      "epoch": 1.5636918382913807,
      "grad_norm": 0.0,
      "learning_rate": 0.0001687905379626097,
      "loss": 0.0,
      "step": 2050
    },
    {
      "epoch": 1.5827612509534705,
      "grad_norm": 0.0,
      "learning_rate": 0.00016840900419687143,
      "loss": 0.0,
      "step": 2075
    },
    {
      "epoch": 1.6018306636155606,
      "grad_norm": 0.0,
      "learning_rate": 0.00016802747043113316,
      "loss": 0.0,
      "step": 2100
    },
    {
      "epoch": 1.6209000762776506,
      "grad_norm": 0.0,
      "learning_rate": 0.0001676459366653949,
      "loss": 0.0,
      "step": 2125
    },
    {
      "epoch": 1.6399694889397407,
      "grad_norm": 0.0,
      "learning_rate": 0.00016726440289965665,
      "loss": 0.0,
      "step": 2150
    },
    {
      "epoch": 1.6590389016018308,
      "grad_norm": 0.0,
      "learning_rate": 0.00016688286913391835,
      "loss": 0.0,
      "step": 2175
    },
    {
      "epoch": 1.6781083142639206,
      "grad_norm": 0.0,
      "learning_rate": 0.00016650133536818008,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 1.6971777269260107,
      "grad_norm": 0.0,
      "learning_rate": 0.0001661198016024418,
      "loss": 0.0,
      "step": 2225
    },
    {
      "epoch": 1.7162471395881007,
      "grad_norm": 0.0,
      "learning_rate": 0.00016573826783670357,
      "loss": 0.0,
      "step": 2250
    },
    {
      "epoch": 1.7353165522501905,
      "grad_norm": 0.0,
      "learning_rate": 0.00016535673407096528,
      "loss": 0.0,
      "step": 2275
    },
    {
      "epoch": 1.7543859649122808,
      "grad_norm": 0.0,
      "learning_rate": 0.000164975200305227,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 1.7734553775743707,
      "grad_norm": 0.0,
      "learning_rate": 0.00016459366653948877,
      "loss": 0.0,
      "step": 2325
    },
    {
      "epoch": 1.7925247902364607,
      "grad_norm": 0.0,
      "learning_rate": 0.0001642121327737505,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 1.8115942028985508,
      "grad_norm": 0.0,
      "learning_rate": 0.0001638305990080122,
      "loss": 0.0,
      "step": 2375
    },
    {
      "epoch": 1.8306636155606406,
      "grad_norm": 0.0,
      "learning_rate": 0.00016344906524227396,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 1.849733028222731,
      "grad_norm": 0.0,
      "learning_rate": 0.0001630675314765357,
      "loss": 0.0,
      "step": 2425
    },
    {
      "epoch": 1.8688024408848207,
      "grad_norm": 0.0,
      "learning_rate": 0.00016268599771079742,
      "loss": 0.0,
      "step": 2450
    },
    {
      "epoch": 1.8878718535469108,
      "grad_norm": 0.0,
      "learning_rate": 0.00016230446394505912,
      "loss": 0.0,
      "step": 2475
    },
    {
      "epoch": 1.9069412662090008,
      "grad_norm": 0.0,
      "learning_rate": 0.00016192293017932088,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 1.9260106788710907,
      "grad_norm": 0.0,
      "learning_rate": 0.00016154139641358261,
      "loss": 0.0,
      "step": 2525
    },
    {
      "epoch": 1.9450800915331807,
      "grad_norm": 0.0,
      "learning_rate": 0.00016115986264784435,
      "loss": 0.0,
      "step": 2550
    },
    {
      "epoch": 1.9641495041952708,
      "grad_norm": 0.0,
      "learning_rate": 0.00016077832888210608,
      "loss": 0.0,
      "step": 2575
    },
    {
      "epoch": 1.9832189168573608,
      "grad_norm": 0.0,
      "learning_rate": 0.0001603967951163678,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 2.002288329519451,
      "grad_norm": 0.0,
      "learning_rate": 0.00016001526135062954,
      "loss": 0.0,
      "step": 2625
    },
    {
      "epoch": 2.0213577421815407,
      "grad_norm": 0.0,
      "learning_rate": 0.00015963372758489127,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 2.040427154843631,
      "grad_norm": 0.0,
      "learning_rate": 0.000159252193819153,
      "loss": 0.0,
      "step": 2675
    },
    {
      "epoch": 2.059496567505721,
      "grad_norm": 0.0,
      "learning_rate": 0.00015887066005341473,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 2.0785659801678107,
      "grad_norm": 0.0,
      "learning_rate": 0.00015848912628767646,
      "loss": 0.0,
      "step": 2725
    },
    {
      "epoch": 2.097635392829901,
      "grad_norm": 0.0,
      "learning_rate": 0.00015810759252193822,
      "loss": 0.0,
      "step": 2750
    },
    {
      "epoch": 2.116704805491991,
      "grad_norm": 0.0,
      "learning_rate": 0.00015772605875619993,
      "loss": 0.0,
      "step": 2775
    },
    {
      "epoch": 2.135774218154081,
      "grad_norm": 0.0,
      "learning_rate": 0.00015734452499046166,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 2.154843630816171,
      "grad_norm": 0.0,
      "learning_rate": 0.0001569629912247234,
      "loss": 0.0,
      "step": 2825
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.0,
      "learning_rate": 0.00015658145745898515,
      "loss": 0.0,
      "step": 2850
    },
    {
      "epoch": 2.192982456140351,
      "grad_norm": 0.0,
      "learning_rate": 0.00015619992369324685,
      "loss": 0.0,
      "step": 2875
    },
    {
      "epoch": 2.212051868802441,
      "grad_norm": 0.0,
      "learning_rate": 0.00015581838992750858,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 2.2311212814645307,
      "grad_norm": 0.0,
      "learning_rate": 0.00015543685616177034,
      "loss": 0.0,
      "step": 2925
    },
    {
      "epoch": 2.250190694126621,
      "grad_norm": 0.0,
      "learning_rate": 0.00015505532239603207,
      "loss": 0.0,
      "step": 2950
    },
    {
      "epoch": 2.269260106788711,
      "grad_norm": 0.0,
      "learning_rate": 0.00015467378863029377,
      "loss": 0.0,
      "step": 2975
    },
    {
      "epoch": 2.288329519450801,
      "grad_norm": 0.0,
      "learning_rate": 0.00015429225486455553,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 2.307398932112891,
      "grad_norm": 0.0,
      "learning_rate": 0.00015391072109881726,
      "loss": 0.0,
      "step": 3025
    },
    {
      "epoch": 2.3264683447749808,
      "grad_norm": 0.0,
      "learning_rate": 0.000153529187333079,
      "loss": 0.0,
      "step": 3050
    },
    {
      "epoch": 2.345537757437071,
      "grad_norm": 0.0,
      "learning_rate": 0.0001531476535673407,
      "loss": 0.0,
      "step": 3075
    },
    {
      "epoch": 2.364607170099161,
      "grad_norm": 0.0,
      "learning_rate": 0.00015276611980160246,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 2.383676582761251,
      "grad_norm": 0.0,
      "learning_rate": 0.0001523845860358642,
      "loss": 0.0,
      "step": 3125
    },
    {
      "epoch": 2.402745995423341,
      "grad_norm": 0.0,
      "learning_rate": 0.00015200305227012592,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 2.421815408085431,
      "grad_norm": 0.0,
      "learning_rate": 0.00015162151850438765,
      "loss": 0.0,
      "step": 3175
    },
    {
      "epoch": 2.440884820747521,
      "grad_norm": 0.0,
      "learning_rate": 0.00015123998473864938,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 2.459954233409611,
      "grad_norm": 0.0,
      "learning_rate": 0.0001508584509729111,
      "loss": 0.0,
      "step": 3225
    },
    {
      "epoch": 2.479023646071701,
      "grad_norm": 0.0,
      "learning_rate": 0.00015047691720717284,
      "loss": 0.0,
      "step": 3250
    },
    {
      "epoch": 2.498093058733791,
      "grad_norm": 0.0,
      "learning_rate": 0.00015009538344143457,
      "loss": 0.0,
      "step": 3275
    },
    {
      "epoch": 2.517162471395881,
      "grad_norm": 0.0,
      "learning_rate": 0.0001497138496756963,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 2.536231884057971,
      "grad_norm": 0.0,
      "learning_rate": 0.00014933231590995804,
      "loss": 0.0,
      "step": 3325
    },
    {
      "epoch": 2.555301296720061,
      "grad_norm": 0.0,
      "learning_rate": 0.00014895078214421977,
      "loss": 0.0,
      "step": 3350
    },
    {
      "epoch": 2.5743707093821513,
      "grad_norm": 0.0,
      "learning_rate": 0.0001485692483784815,
      "loss": 0.0,
      "step": 3375
    },
    {
      "epoch": 2.593440122044241,
      "grad_norm": 0.0,
      "learning_rate": 0.00014818771461274323,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 2.612509534706331,
      "grad_norm": 0.0,
      "learning_rate": 0.00014780618084700496,
      "loss": 0.0,
      "step": 3425
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 0.0,
      "learning_rate": 0.00014742464708126672,
      "loss": 0.0,
      "step": 3450
    },
    {
      "epoch": 2.650648360030511,
      "grad_norm": 0.0,
      "learning_rate": 0.00014704311331552842,
      "loss": 0.0,
      "step": 3475
    },
    {
      "epoch": 2.669717772692601,
      "grad_norm": 0.0,
      "learning_rate": 0.00014666157954979015,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 2.688787185354691,
      "grad_norm": 0.0,
      "learning_rate": 0.0001462800457840519,
      "loss": 0.0,
      "step": 3525
    },
    {
      "epoch": 2.707856598016781,
      "grad_norm": 0.0,
      "learning_rate": 0.00014589851201831364,
      "loss": 0.0,
      "step": 3550
    },
    {
      "epoch": 2.726926010678871,
      "grad_norm": 0.0,
      "learning_rate": 0.00014551697825257535,
      "loss": 0.0,
      "step": 3575
    },
    {
      "epoch": 2.745995423340961,
      "grad_norm": 0.0,
      "learning_rate": 0.00014513544448683708,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 2.765064836003051,
      "grad_norm": 0.0,
      "learning_rate": 0.00014475391072109884,
      "loss": 0.0,
      "step": 3625
    },
    {
      "epoch": 2.7841342486651413,
      "grad_norm": 0.0,
      "learning_rate": 0.00014437237695536057,
      "loss": 0.0,
      "step": 3650
    },
    {
      "epoch": 2.803203661327231,
      "grad_norm": 0.0,
      "learning_rate": 0.00014399084318962227,
      "loss": 0.0,
      "step": 3675
    },
    {
      "epoch": 2.8222730739893214,
      "grad_norm": 0.0,
      "learning_rate": 0.00014360930942388403,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 2.841342486651411,
      "grad_norm": 0.0,
      "learning_rate": 0.00014322777565814576,
      "loss": 0.0,
      "step": 3725
    },
    {
      "epoch": 2.860411899313501,
      "grad_norm": 0.0,
      "learning_rate": 0.0001428462418924075,
      "loss": 0.0,
      "step": 3750
    },
    {
      "epoch": 2.8794813119755913,
      "grad_norm": 0.0,
      "learning_rate": 0.00014246470812666922,
      "loss": 0.0,
      "step": 3775
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 0.0,
      "learning_rate": 0.00014208317436093095,
      "loss": 0.0,
      "step": 3800
    },
    {
      "epoch": 2.917620137299771,
      "grad_norm": 0.0,
      "learning_rate": 0.00014170164059519269,
      "loss": 0.0,
      "step": 3825
    },
    {
      "epoch": 2.9366895499618613,
      "grad_norm": 0.0,
      "learning_rate": 0.00014132010682945442,
      "loss": 0.0,
      "step": 3850
    },
    {
      "epoch": 2.955758962623951,
      "grad_norm": 0.0,
      "learning_rate": 0.00014093857306371615,
      "loss": 0.0,
      "step": 3875
    },
    {
      "epoch": 2.974828375286041,
      "grad_norm": 0.0,
      "learning_rate": 0.00014055703929797788,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 2.993897787948131,
      "grad_norm": 0.0,
      "learning_rate": 0.0001401755055322396,
      "loss": 0.0,
      "step": 3925
    },
    {
      "epoch": 3.012967200610221,
      "grad_norm": 0.0,
      "learning_rate": 0.00013979397176650134,
      "loss": 0.0,
      "step": 3950
    },
    {
      "epoch": 3.0320366132723113,
      "grad_norm": 0.0,
      "learning_rate": 0.00013941243800076307,
      "loss": 0.0,
      "step": 3975
    },
    {
      "epoch": 3.051106025934401,
      "grad_norm": 0.0,
      "learning_rate": 0.0001390309042350248,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 3.0701754385964914,
      "grad_norm": 0.0,
      "learning_rate": 0.00013864937046928653,
      "loss": 0.0,
      "step": 4025
    },
    {
      "epoch": 3.0892448512585813,
      "grad_norm": 0.0,
      "learning_rate": 0.0001382678367035483,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 3.108314263920671,
      "grad_norm": 0.0,
      "learning_rate": 0.00013788630293781,
      "loss": 0.0,
      "step": 4075
    },
    {
      "epoch": 3.1273836765827614,
      "grad_norm": 0.0,
      "learning_rate": 0.00013750476917207173,
      "loss": 0.0,
      "step": 4100
    },
    {
      "epoch": 3.1464530892448512,
      "grad_norm": 0.0,
      "learning_rate": 0.00013712323540633346,
      "loss": 0.0,
      "step": 4125
    },
    {
      "epoch": 3.165522501906941,
      "grad_norm": 0.0,
      "learning_rate": 0.00013674170164059522,
      "loss": 0.0,
      "step": 4150
    },
    {
      "epoch": 3.1845919145690313,
      "grad_norm": 0.0,
      "learning_rate": 0.00013636016787485692,
      "loss": 0.0,
      "step": 4175
    },
    {
      "epoch": 3.203661327231121,
      "grad_norm": 0.0,
      "learning_rate": 0.00013597863410911865,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 3.2227307398932115,
      "grad_norm": 0.0,
      "learning_rate": 0.0001355971003433804,
      "loss": 0.0,
      "step": 4225
    },
    {
      "epoch": 3.2418001525553013,
      "grad_norm": 0.0,
      "learning_rate": 0.00013521556657764214,
      "loss": 0.0,
      "step": 4250
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 0.0,
      "learning_rate": 0.00013483403281190385,
      "loss": 0.0,
      "step": 4275
    },
    {
      "epoch": 3.2799389778794814,
      "grad_norm": 0.0,
      "learning_rate": 0.0001344524990461656,
      "loss": 0.0,
      "step": 4300
    },
    {
      "epoch": 3.2990083905415712,
      "grad_norm": 0.0,
      "learning_rate": 0.00013407096528042734,
      "loss": 0.0,
      "step": 4325
    },
    {
      "epoch": 3.3180778032036615,
      "grad_norm": 0.0,
      "learning_rate": 0.00013368943151468907,
      "loss": 0.0,
      "step": 4350
    },
    {
      "epoch": 3.3371472158657514,
      "grad_norm": 0.0,
      "learning_rate": 0.00013330789774895077,
      "loss": 0.0,
      "step": 4375
    },
    {
      "epoch": 3.356216628527841,
      "grad_norm": 0.0,
      "learning_rate": 0.00013292636398321253,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 3.3752860411899315,
      "grad_norm": 0.0,
      "learning_rate": 0.00013254483021747426,
      "loss": 0.0,
      "step": 4425
    },
    {
      "epoch": 3.3943554538520213,
      "grad_norm": 0.0,
      "learning_rate": 0.00013216329645173596,
      "loss": 0.0,
      "step": 4450
    },
    {
      "epoch": 3.413424866514111,
      "grad_norm": 0.0,
      "learning_rate": 0.00013178176268599772,
      "loss": 0.0,
      "step": 4475
    },
    {
      "epoch": 3.4324942791762014,
      "grad_norm": 0.0,
      "learning_rate": 0.00013140022892025945,
      "loss": 0.0,
      "step": 4500
    },
    {
      "epoch": 3.4515636918382913,
      "grad_norm": 0.0,
      "learning_rate": 0.00013101869515452118,
      "loss": 0.0,
      "step": 4525
    },
    {
      "epoch": 3.4706331045003815,
      "grad_norm": 0.0,
      "learning_rate": 0.00013063716138878292,
      "loss": 0.0,
      "step": 4550
    },
    {
      "epoch": 3.4897025171624714,
      "grad_norm": 0.0,
      "learning_rate": 0.00013025562762304465,
      "loss": 0.0,
      "step": 4575
    },
    {
      "epoch": 3.5087719298245617,
      "grad_norm": 0.0,
      "learning_rate": 0.00012987409385730638,
      "loss": 0.0,
      "step": 4600
    },
    {
      "epoch": 3.5278413424866515,
      "grad_norm": 0.0,
      "learning_rate": 0.0001294925600915681,
      "loss": 0.0,
      "step": 4625
    },
    {
      "epoch": 3.5469107551487413,
      "grad_norm": 0.0,
      "learning_rate": 0.00012911102632582984,
      "loss": 0.0,
      "step": 4650
    },
    {
      "epoch": 3.5659801678108316,
      "grad_norm": 0.0,
      "learning_rate": 0.00012872949256009157,
      "loss": 0.0,
      "step": 4675
    },
    {
      "epoch": 3.5850495804729214,
      "grad_norm": 0.0,
      "learning_rate": 0.0001283479587943533,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 3.6041189931350113,
      "grad_norm": 0.0,
      "learning_rate": 0.00012796642502861503,
      "loss": 0.0,
      "step": 4725
    },
    {
      "epoch": 3.6231884057971016,
      "grad_norm": 0.0,
      "learning_rate": 0.00012758489126287676,
      "loss": 0.0,
      "step": 4750
    },
    {
      "epoch": 3.6422578184591914,
      "grad_norm": 0.0,
      "learning_rate": 0.0001272033574971385,
      "loss": 0.0,
      "step": 4775
    },
    {
      "epoch": 3.6613272311212812,
      "grad_norm": 0.0,
      "learning_rate": 0.00012682182373140023,
      "loss": 0.0,
      "step": 4800
    },
    {
      "epoch": 3.6803966437833715,
      "grad_norm": 0.0,
      "learning_rate": 0.00012644028996566198,
      "loss": 0.0,
      "step": 4825
    },
    {
      "epoch": 3.6994660564454613,
      "grad_norm": 0.0,
      "learning_rate": 0.0001260587561999237,
      "loss": 0.0,
      "step": 4850
    },
    {
      "epoch": 3.7185354691075516,
      "grad_norm": 0.0,
      "learning_rate": 0.00012567722243418542,
      "loss": 0.0,
      "step": 4875
    },
    {
      "epoch": 3.7376048817696415,
      "grad_norm": 0.0,
      "learning_rate": 0.00012529568866844715,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 3.7566742944317317,
      "grad_norm": 0.0,
      "learning_rate": 0.0001249141549027089,
      "loss": 0.0,
      "step": 4925
    },
    {
      "epoch": 3.7757437070938216,
      "grad_norm": 0.0,
      "learning_rate": 0.0001245326211369706,
      "loss": 0.0,
      "step": 4950
    },
    {
      "epoch": 3.7948131197559114,
      "grad_norm": 0.0,
      "learning_rate": 0.00012415108737123234,
      "loss": 0.0,
      "step": 4975
    },
    {
      "epoch": 3.8138825324180017,
      "grad_norm": 0.0,
      "learning_rate": 0.0001237695536054941,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 3.8329519450800915,
      "grad_norm": 0.0,
      "learning_rate": 0.00012338801983975583,
      "loss": 0.0,
      "step": 5025
    },
    {
      "epoch": 3.8520213577421814,
      "grad_norm": 0.0,
      "learning_rate": 0.00012300648607401754,
      "loss": 0.0,
      "step": 5050
    },
    {
      "epoch": 3.8710907704042716,
      "grad_norm": 0.0,
      "learning_rate": 0.0001226249523082793,
      "loss": 0.0,
      "step": 5075
    },
    {
      "epoch": 3.8901601830663615,
      "grad_norm": 0.0,
      "learning_rate": 0.00012224341854254103,
      "loss": 0.0,
      "step": 5100
    },
    {
      "epoch": 3.9092295957284513,
      "grad_norm": 0.0,
      "learning_rate": 0.00012186188477680276,
      "loss": 0.0,
      "step": 5125
    },
    {
      "epoch": 3.9282990083905416,
      "grad_norm": 0.0,
      "learning_rate": 0.00012148035101106448,
      "loss": 0.0,
      "step": 5150
    },
    {
      "epoch": 3.9473684210526314,
      "grad_norm": 0.0,
      "learning_rate": 0.0001210988172453262,
      "loss": 0.0,
      "step": 5175
    },
    {
      "epoch": 3.9664378337147217,
      "grad_norm": 0.0,
      "learning_rate": 0.00012071728347958795,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 3.9855072463768115,
      "grad_norm": 0.0,
      "learning_rate": 0.00012033574971384968,
      "loss": 0.0,
      "step": 5225
    },
    {
      "epoch": 4.004576659038902,
      "grad_norm": 0.0,
      "learning_rate": 0.0001199542159481114,
      "loss": 0.0,
      "step": 5250
    },
    {
      "epoch": 4.023646071700991,
      "grad_norm": 0.0,
      "learning_rate": 0.00011957268218237314,
      "loss": 0.0,
      "step": 5275
    },
    {
      "epoch": 4.0427154843630815,
      "grad_norm": 0.0,
      "learning_rate": 0.00011919114841663488,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 4.061784897025172,
      "grad_norm": 0.0,
      "learning_rate": 0.00011880961465089662,
      "loss": 0.0,
      "step": 5325
    },
    {
      "epoch": 4.080854309687262,
      "grad_norm": 0.0,
      "learning_rate": 0.00011842808088515834,
      "loss": 0.0,
      "step": 5350
    },
    {
      "epoch": 4.099923722349351,
      "grad_norm": 0.0,
      "learning_rate": 0.00011804654711942007,
      "loss": 0.0,
      "step": 5375
    },
    {
      "epoch": 4.118993135011442,
      "grad_norm": 0.0,
      "learning_rate": 0.00011766501335368181,
      "loss": 0.0,
      "step": 5400
    },
    {
      "epoch": 4.138062547673532,
      "grad_norm": 0.0,
      "learning_rate": 0.00011728347958794354,
      "loss": 0.0,
      "step": 5425
    },
    {
      "epoch": 4.157131960335621,
      "grad_norm": 0.0,
      "learning_rate": 0.00011690194582220526,
      "loss": 0.0,
      "step": 5450
    },
    {
      "epoch": 4.176201372997712,
      "grad_norm": 0.0,
      "learning_rate": 0.000116520412056467,
      "loss": 0.0,
      "step": 5475
    },
    {
      "epoch": 4.195270785659802,
      "grad_norm": 0.0,
      "learning_rate": 0.00011613887829072874,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 4.214340198321891,
      "grad_norm": 0.0,
      "learning_rate": 0.00011575734452499047,
      "loss": 0.0,
      "step": 5525
    },
    {
      "epoch": 4.233409610983982,
      "grad_norm": 0.0,
      "learning_rate": 0.00011537581075925219,
      "loss": 0.0,
      "step": 5550
    },
    {
      "epoch": 4.252479023646072,
      "grad_norm": 0.0,
      "learning_rate": 0.00011499427699351393,
      "loss": 0.0,
      "step": 5575
    },
    {
      "epoch": 4.271548436308162,
      "grad_norm": 0.0,
      "learning_rate": 0.00011461274322777566,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 4.290617848970252,
      "grad_norm": 0.0,
      "learning_rate": 0.00011423120946203741,
      "loss": 0.0,
      "step": 5625
    },
    {
      "epoch": 4.309687261632342,
      "grad_norm": 0.0,
      "learning_rate": 0.00011384967569629912,
      "loss": 0.0,
      "step": 5650
    },
    {
      "epoch": 4.328756674294432,
      "grad_norm": 0.0,
      "learning_rate": 0.00011346814193056086,
      "loss": 0.0,
      "step": 5675
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.0,
      "learning_rate": 0.0001130866081648226,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 4.366895499618612,
      "grad_norm": 0.0,
      "learning_rate": 0.00011270507439908433,
      "loss": 0.0,
      "step": 5725
    },
    {
      "epoch": 4.385964912280702,
      "grad_norm": 0.0,
      "learning_rate": 0.00011232354063334605,
      "loss": 0.0,
      "step": 5750
    },
    {
      "epoch": 4.4050343249427915,
      "grad_norm": 0.0,
      "learning_rate": 0.00011194200686760778,
      "loss": 0.0,
      "step": 5775
    },
    {
      "epoch": 4.424103737604882,
      "grad_norm": 0.0,
      "learning_rate": 0.00011156047310186953,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 4.443173150266972,
      "grad_norm": 0.0,
      "learning_rate": 0.00011117893933613126,
      "loss": 0.0,
      "step": 5825
    },
    {
      "epoch": 4.462242562929061,
      "grad_norm": 0.0,
      "learning_rate": 0.00011079740557039297,
      "loss": 0.0,
      "step": 5850
    },
    {
      "epoch": 4.481311975591152,
      "grad_norm": 0.0,
      "learning_rate": 0.00011041587180465472,
      "loss": 0.0,
      "step": 5875
    },
    {
      "epoch": 4.500381388253242,
      "grad_norm": 0.0,
      "learning_rate": 0.00011003433803891645,
      "loss": 0.0,
      "step": 5900
    },
    {
      "epoch": 4.519450800915331,
      "grad_norm": 0.0,
      "learning_rate": 0.0001096528042731782,
      "loss": 0.0,
      "step": 5925
    },
    {
      "epoch": 4.538520213577422,
      "grad_norm": 0.0,
      "learning_rate": 0.0001092712705074399,
      "loss": 0.0,
      "step": 5950
    },
    {
      "epoch": 4.557589626239512,
      "grad_norm": 0.0,
      "learning_rate": 0.00010888973674170164,
      "loss": 0.0,
      "step": 5975
    },
    {
      "epoch": 4.576659038901602,
      "grad_norm": 0.0,
      "learning_rate": 0.00010850820297596337,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 4.595728451563692,
      "grad_norm": 0.0,
      "learning_rate": 0.00010812666921022512,
      "loss": 0.0,
      "step": 6025
    },
    {
      "epoch": 4.614797864225782,
      "grad_norm": 0.0,
      "learning_rate": 0.00010774513544448684,
      "loss": 0.0,
      "step": 6050
    },
    {
      "epoch": 4.633867276887872,
      "grad_norm": 0.0,
      "learning_rate": 0.00010736360167874857,
      "loss": 0.0,
      "step": 6075
    },
    {
      "epoch": 4.6529366895499615,
      "grad_norm": 0.0,
      "learning_rate": 0.00010698206791301031,
      "loss": 0.0,
      "step": 6100
    },
    {
      "epoch": 4.672006102212052,
      "grad_norm": 0.0,
      "learning_rate": 0.00010660053414727204,
      "loss": 0.0,
      "step": 6125
    },
    {
      "epoch": 4.691075514874142,
      "grad_norm": 0.0,
      "learning_rate": 0.00010621900038153376,
      "loss": 0.0,
      "step": 6150
    },
    {
      "epoch": 4.710144927536232,
      "grad_norm": 0.0,
      "learning_rate": 0.0001058374666157955,
      "loss": 0.0,
      "step": 6175
    },
    {
      "epoch": 4.729214340198322,
      "grad_norm": 0.0,
      "learning_rate": 0.00010545593285005724,
      "loss": 0.0,
      "step": 6200
    },
    {
      "epoch": 4.748283752860412,
      "grad_norm": 0.0,
      "learning_rate": 0.00010507439908431898,
      "loss": 0.0,
      "step": 6225
    },
    {
      "epoch": 4.767353165522502,
      "grad_norm": 0.0,
      "learning_rate": 0.00010469286531858069,
      "loss": 0.0,
      "step": 6250
    },
    {
      "epoch": 4.786422578184592,
      "grad_norm": 0.0,
      "learning_rate": 0.00010431133155284243,
      "loss": 0.0,
      "step": 6275
    },
    {
      "epoch": 4.805491990846682,
      "grad_norm": 0.0,
      "learning_rate": 0.00010392979778710416,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 4.824561403508772,
      "grad_norm": 0.0,
      "learning_rate": 0.0001035482640213659,
      "loss": 0.0,
      "step": 6325
    },
    {
      "epoch": 4.843630816170862,
      "grad_norm": 0.0,
      "learning_rate": 0.00010316673025562762,
      "loss": 0.0,
      "step": 6350
    },
    {
      "epoch": 4.862700228832952,
      "grad_norm": 0.0,
      "learning_rate": 0.00010278519648988935,
      "loss": 0.0,
      "step": 6375
    },
    {
      "epoch": 4.881769641495042,
      "grad_norm": 0.0,
      "learning_rate": 0.0001024036627241511,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 4.900839054157132,
      "grad_norm": 0.0,
      "learning_rate": 0.00010202212895841283,
      "loss": 0.0,
      "step": 6425
    },
    {
      "epoch": 4.919908466819222,
      "grad_norm": 0.0,
      "learning_rate": 0.00010164059519267455,
      "loss": 0.0,
      "step": 6450
    },
    {
      "epoch": 4.938977879481312,
      "grad_norm": 0.0,
      "learning_rate": 0.00010125906142693629,
      "loss": 0.0,
      "step": 6475
    },
    {
      "epoch": 4.958047292143402,
      "grad_norm": 0.0,
      "learning_rate": 0.00010087752766119802,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 4.977116704805492,
      "grad_norm": 0.0,
      "learning_rate": 0.00010049599389545977,
      "loss": 0.0,
      "step": 6525
    },
    {
      "epoch": 4.996186117467582,
      "grad_norm": 0.0,
      "learning_rate": 0.00010011446012972147,
      "loss": 0.0,
      "step": 6550
    },
    {
      "epoch": 5.015255530129672,
      "grad_norm": 0.0,
      "learning_rate": 9.973292636398322e-05,
      "loss": 0.0,
      "step": 6575
    },
    {
      "epoch": 5.034324942791762,
      "grad_norm": 0.0,
      "learning_rate": 9.935139259824495e-05,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 5.053394355453852,
      "grad_norm": 0.0,
      "learning_rate": 9.896985883250668e-05,
      "loss": 0.0,
      "step": 6625
    },
    {
      "epoch": 5.072463768115942,
      "grad_norm": 0.0,
      "learning_rate": 9.858832506676841e-05,
      "loss": 0.0,
      "step": 6650
    },
    {
      "epoch": 5.091533180778032,
      "grad_norm": 0.0,
      "learning_rate": 9.820679130103014e-05,
      "loss": 0.0,
      "step": 6675
    },
    {
      "epoch": 5.110602593440122,
      "grad_norm": 0.0,
      "learning_rate": 9.782525753529189e-05,
      "loss": 0.0,
      "step": 6700
    },
    {
      "epoch": 5.129672006102212,
      "grad_norm": 0.0,
      "learning_rate": 9.74437237695536e-05,
      "loss": 0.0,
      "step": 6725
    },
    {
      "epoch": 5.148741418764302,
      "grad_norm": 0.0,
      "learning_rate": 9.706219000381535e-05,
      "loss": 0.0,
      "step": 6750
    },
    {
      "epoch": 5.167810831426392,
      "grad_norm": 0.0,
      "learning_rate": 9.668065623807707e-05,
      "loss": 0.0,
      "step": 6775
    },
    {
      "epoch": 5.186880244088482,
      "grad_norm": 0.0,
      "learning_rate": 9.629912247233881e-05,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 5.2059496567505725,
      "grad_norm": 0.0,
      "learning_rate": 9.591758870660054e-05,
      "loss": 0.0,
      "step": 6825
    },
    {
      "epoch": 5.225019069412662,
      "grad_norm": 0.0,
      "learning_rate": 9.553605494086227e-05,
      "loss": 0.0,
      "step": 6850
    },
    {
      "epoch": 5.244088482074752,
      "grad_norm": 0.0,
      "learning_rate": 9.5154521175124e-05,
      "loss": 0.0,
      "step": 6875
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 0.0,
      "learning_rate": 9.477298740938573e-05,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 5.282227307398932,
      "grad_norm": 0.0,
      "learning_rate": 9.439145364364747e-05,
      "loss": 0.0,
      "step": 6925
    },
    {
      "epoch": 5.301296720061022,
      "grad_norm": 0.0,
      "learning_rate": 9.40099198779092e-05,
      "loss": 0.0,
      "step": 6950
    },
    {
      "epoch": 5.320366132723112,
      "grad_norm": 0.0,
      "learning_rate": 9.362838611217093e-05,
      "loss": 0.0,
      "step": 6975
    },
    {
      "epoch": 5.339435545385202,
      "grad_norm": 0.0,
      "learning_rate": 9.324685234643267e-05,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 5.358504958047292,
      "grad_norm": 0.0,
      "learning_rate": 9.286531858069439e-05,
      "loss": 0.0,
      "step": 7025
    },
    {
      "epoch": 5.377574370709382,
      "grad_norm": 0.0,
      "learning_rate": 9.248378481495613e-05,
      "loss": 0.0,
      "step": 7050
    },
    {
      "epoch": 5.396643783371472,
      "grad_norm": 0.0,
      "learning_rate": 9.210225104921785e-05,
      "loss": 0.0,
      "step": 7075
    },
    {
      "epoch": 5.415713196033562,
      "grad_norm": 0.0,
      "learning_rate": 9.17207172834796e-05,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 5.434782608695652,
      "grad_norm": 0.0,
      "learning_rate": 9.133918351774133e-05,
      "loss": 0.0,
      "step": 7125
    },
    {
      "epoch": 5.453852021357742,
      "grad_norm": 0.0,
      "learning_rate": 9.095764975200306e-05,
      "loss": 0.0,
      "step": 7150
    },
    {
      "epoch": 5.472921434019832,
      "grad_norm": 0.0,
      "learning_rate": 9.057611598626479e-05,
      "loss": 0.0,
      "step": 7175
    },
    {
      "epoch": 5.491990846681922,
      "grad_norm": 0.0,
      "learning_rate": 9.019458222052652e-05,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 5.511060259344013,
      "grad_norm": 0.0,
      "learning_rate": 8.981304845478825e-05,
      "loss": 0.0,
      "step": 7225
    },
    {
      "epoch": 5.530129672006102,
      "grad_norm": 0.0,
      "learning_rate": 8.943151468904998e-05,
      "loss": 0.0,
      "step": 7250
    },
    {
      "epoch": 5.549199084668192,
      "grad_norm": 0.0,
      "learning_rate": 8.904998092331171e-05,
      "loss": 0.0,
      "step": 7275
    },
    {
      "epoch": 5.5682684973302825,
      "grad_norm": 0.0,
      "learning_rate": 8.866844715757346e-05,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 5.587337909992372,
      "grad_norm": 0.0,
      "learning_rate": 8.828691339183518e-05,
      "loss": 0.0,
      "step": 7325
    },
    {
      "epoch": 5.606407322654462,
      "grad_norm": 0.0,
      "learning_rate": 8.790537962609692e-05,
      "loss": 0.0,
      "step": 7350
    },
    {
      "epoch": 5.6254767353165525,
      "grad_norm": 0.0,
      "learning_rate": 8.752384586035864e-05,
      "loss": 0.0,
      "step": 7375
    },
    {
      "epoch": 5.644546147978643,
      "grad_norm": 0.0,
      "learning_rate": 8.714231209462038e-05,
      "loss": 0.0,
      "step": 7400
    },
    {
      "epoch": 5.663615560640732,
      "grad_norm": 0.0,
      "learning_rate": 8.676077832888211e-05,
      "loss": 0.0,
      "step": 7425
    },
    {
      "epoch": 5.682684973302822,
      "grad_norm": 0.0,
      "learning_rate": 8.637924456314385e-05,
      "loss": 0.0,
      "step": 7450
    },
    {
      "epoch": 5.701754385964913,
      "grad_norm": 0.0,
      "learning_rate": 8.599771079740558e-05,
      "loss": 0.0,
      "step": 7475
    },
    {
      "epoch": 5.720823798627002,
      "grad_norm": 0.0,
      "learning_rate": 8.561617703166731e-05,
      "loss": 0.0,
      "step": 7500
    },
    {
      "epoch": 5.739893211289092,
      "grad_norm": 0.0,
      "learning_rate": 8.523464326592904e-05,
      "loss": 0.0,
      "step": 7525
    },
    {
      "epoch": 5.758962623951183,
      "grad_norm": 0.0,
      "learning_rate": 8.485310950019077e-05,
      "loss": 0.0,
      "step": 7550
    },
    {
      "epoch": 5.778032036613272,
      "grad_norm": 0.0,
      "learning_rate": 8.44715757344525e-05,
      "loss": 0.0,
      "step": 7575
    },
    {
      "epoch": 5.797101449275362,
      "grad_norm": 0.0,
      "learning_rate": 8.409004196871423e-05,
      "loss": 0.0,
      "step": 7600
    },
    {
      "epoch": 5.816170861937453,
      "grad_norm": 0.0,
      "learning_rate": 8.370850820297596e-05,
      "loss": 0.0,
      "step": 7625
    },
    {
      "epoch": 5.835240274599542,
      "grad_norm": 0.0,
      "learning_rate": 8.332697443723771e-05,
      "loss": 0.0,
      "step": 7650
    },
    {
      "epoch": 5.854309687261632,
      "grad_norm": 0.0,
      "learning_rate": 8.294544067149943e-05,
      "loss": 0.0,
      "step": 7675
    },
    {
      "epoch": 5.8733790999237225,
      "grad_norm": 0.0,
      "learning_rate": 8.256390690576117e-05,
      "loss": 0.0,
      "step": 7700
    },
    {
      "epoch": 5.892448512585812,
      "grad_norm": 0.0,
      "learning_rate": 8.218237314002289e-05,
      "loss": 0.0,
      "step": 7725
    },
    {
      "epoch": 5.911517925247902,
      "grad_norm": 0.0,
      "learning_rate": 8.180083937428463e-05,
      "loss": 0.0,
      "step": 7750
    },
    {
      "epoch": 5.9305873379099925,
      "grad_norm": 0.0,
      "learning_rate": 8.141930560854636e-05,
      "loss": 0.0,
      "step": 7775
    },
    {
      "epoch": 5.949656750572083,
      "grad_norm": 0.0,
      "learning_rate": 8.10377718428081e-05,
      "loss": 0.0,
      "step": 7800
    },
    {
      "epoch": 5.968726163234172,
      "grad_norm": 0.0,
      "learning_rate": 8.065623807706983e-05,
      "loss": 0.0,
      "step": 7825
    },
    {
      "epoch": 5.987795575896262,
      "grad_norm": 0.0,
      "learning_rate": 8.027470431133156e-05,
      "loss": 0.0,
      "step": 7850
    },
    {
      "epoch": 6.006864988558353,
      "grad_norm": 0.0,
      "learning_rate": 7.989317054559329e-05,
      "loss": 0.0,
      "step": 7875
    },
    {
      "epoch": 6.025934401220442,
      "grad_norm": 0.0,
      "learning_rate": 7.951163677985502e-05,
      "loss": 0.0,
      "step": 7900
    },
    {
      "epoch": 6.045003813882532,
      "grad_norm": 0.0,
      "learning_rate": 7.913010301411675e-05,
      "loss": 0.0,
      "step": 7925
    },
    {
      "epoch": 6.064073226544623,
      "grad_norm": 0.0,
      "learning_rate": 7.87485692483785e-05,
      "loss": 0.0,
      "step": 7950
    },
    {
      "epoch": 6.083142639206712,
      "grad_norm": 0.0,
      "learning_rate": 7.836703548264021e-05,
      "loss": 0.0,
      "step": 7975
    },
    {
      "epoch": 6.102212051868802,
      "grad_norm": 0.0,
      "learning_rate": 7.798550171690196e-05,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 6.121281464530893,
      "grad_norm": 0.0,
      "learning_rate": 7.760396795116368e-05,
      "loss": 0.0,
      "step": 8025
    },
    {
      "epoch": 6.140350877192983,
      "grad_norm": 0.0,
      "learning_rate": 7.722243418542542e-05,
      "loss": 0.0,
      "step": 8050
    },
    {
      "epoch": 6.159420289855072,
      "grad_norm": 0.0,
      "learning_rate": 7.684090041968715e-05,
      "loss": 0.0,
      "step": 8075
    },
    {
      "epoch": 6.178489702517163,
      "grad_norm": 0.0,
      "learning_rate": 7.645936665394888e-05,
      "loss": 0.0,
      "step": 8100
    },
    {
      "epoch": 6.197559115179253,
      "grad_norm": 0.0,
      "learning_rate": 7.607783288821061e-05,
      "loss": 0.0,
      "step": 8125
    },
    {
      "epoch": 6.216628527841342,
      "grad_norm": 0.0,
      "learning_rate": 7.569629912247234e-05,
      "loss": 0.0,
      "step": 8150
    },
    {
      "epoch": 6.2356979405034325,
      "grad_norm": 0.0,
      "learning_rate": 7.531476535673408e-05,
      "loss": 0.0,
      "step": 8175
    },
    {
      "epoch": 6.254767353165523,
      "grad_norm": 0.0,
      "learning_rate": 7.49332315909958e-05,
      "loss": 0.0,
      "step": 8200
    },
    {
      "epoch": 6.273836765827612,
      "grad_norm": 0.0,
      "learning_rate": 7.455169782525754e-05,
      "loss": 0.0,
      "step": 8225
    },
    {
      "epoch": 6.2929061784897025,
      "grad_norm": 0.0,
      "learning_rate": 7.417016405951928e-05,
      "loss": 0.0,
      "step": 8250
    },
    {
      "epoch": 6.311975591151793,
      "grad_norm": 0.0,
      "learning_rate": 7.3788630293781e-05,
      "loss": 0.0,
      "step": 8275
    },
    {
      "epoch": 6.331045003813882,
      "grad_norm": 0.0,
      "learning_rate": 7.340709652804274e-05,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 6.350114416475972,
      "grad_norm": 0.0,
      "learning_rate": 7.302556276230446e-05,
      "loss": 0.0,
      "step": 8325
    },
    {
      "epoch": 6.369183829138063,
      "grad_norm": 0.0,
      "learning_rate": 7.26440289965662e-05,
      "loss": 0.0,
      "step": 8350
    },
    {
      "epoch": 6.388253241800153,
      "grad_norm": 0.0,
      "learning_rate": 7.226249523082794e-05,
      "loss": 0.0,
      "step": 8375
    },
    {
      "epoch": 6.407322654462242,
      "grad_norm": 0.0,
      "learning_rate": 7.188096146508967e-05,
      "loss": 0.0,
      "step": 8400
    },
    {
      "epoch": 6.426392067124333,
      "grad_norm": 0.0,
      "learning_rate": 7.14994276993514e-05,
      "loss": 0.0,
      "step": 8425
    },
    {
      "epoch": 6.445461479786423,
      "grad_norm": 0.0,
      "learning_rate": 7.111789393361313e-05,
      "loss": 0.0,
      "step": 8450
    },
    {
      "epoch": 6.464530892448512,
      "grad_norm": 0.0,
      "learning_rate": 7.073636016787486e-05,
      "loss": 0.0,
      "step": 8475
    },
    {
      "epoch": 6.483600305110603,
      "grad_norm": 0.0,
      "learning_rate": 7.03548264021366e-05,
      "loss": 0.0,
      "step": 8500
    },
    {
      "epoch": 6.502669717772693,
      "grad_norm": 0.0,
      "learning_rate": 6.997329263639832e-05,
      "loss": 0.0,
      "step": 8525
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.0,
      "learning_rate": 6.959175887066006e-05,
      "loss": 0.0,
      "step": 8550
    },
    {
      "epoch": 6.5408085430968725,
      "grad_norm": 0.0,
      "learning_rate": 6.921022510492179e-05,
      "loss": 0.0,
      "step": 8575
    },
    {
      "epoch": 6.559877955758963,
      "grad_norm": 0.0,
      "learning_rate": 6.882869133918353e-05,
      "loss": 0.0,
      "step": 8600
    },
    {
      "epoch": 6.578947368421053,
      "grad_norm": 0.0,
      "learning_rate": 6.844715757344525e-05,
      "loss": 0.0,
      "step": 8625
    },
    {
      "epoch": 6.5980167810831425,
      "grad_norm": 0.0,
      "learning_rate": 6.8065623807707e-05,
      "loss": 0.0,
      "step": 8650
    },
    {
      "epoch": 6.617086193745233,
      "grad_norm": 0.0,
      "learning_rate": 6.768409004196871e-05,
      "loss": 0.0,
      "step": 8675
    },
    {
      "epoch": 6.636155606407323,
      "grad_norm": 0.0,
      "learning_rate": 6.730255627623046e-05,
      "loss": 0.0,
      "step": 8700
    },
    {
      "epoch": 6.655225019069412,
      "grad_norm": 0.0,
      "learning_rate": 6.692102251049219e-05,
      "loss": 0.0,
      "step": 8725
    },
    {
      "epoch": 6.674294431731503,
      "grad_norm": 0.0,
      "learning_rate": 6.65394887447539e-05,
      "loss": 0.0,
      "step": 8750
    },
    {
      "epoch": 6.693363844393593,
      "grad_norm": 0.0,
      "learning_rate": 6.615795497901565e-05,
      "loss": 0.0,
      "step": 8775
    },
    {
      "epoch": 6.712433257055682,
      "grad_norm": 0.0,
      "learning_rate": 6.577642121327737e-05,
      "loss": 0.0,
      "step": 8800
    },
    {
      "epoch": 6.731502669717773,
      "grad_norm": 0.0,
      "learning_rate": 6.539488744753911e-05,
      "loss": 0.0,
      "step": 8825
    },
    {
      "epoch": 6.750572082379863,
      "grad_norm": 0.0,
      "learning_rate": 6.501335368180084e-05,
      "loss": 0.0,
      "step": 8850
    },
    {
      "epoch": 6.769641495041952,
      "grad_norm": 0.0,
      "learning_rate": 6.463181991606257e-05,
      "loss": 0.0,
      "step": 8875
    },
    {
      "epoch": 6.788710907704043,
      "grad_norm": 0.0,
      "learning_rate": 6.42502861503243e-05,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 6.807780320366133,
      "grad_norm": 0.0,
      "learning_rate": 6.386875238458604e-05,
      "loss": 0.0,
      "step": 8925
    },
    {
      "epoch": 6.826849733028222,
      "grad_norm": 0.0,
      "learning_rate": 6.348721861884777e-05,
      "loss": 0.0,
      "step": 8950
    },
    {
      "epoch": 6.845919145690313,
      "grad_norm": 0.0,
      "learning_rate": 6.31056848531095e-05,
      "loss": 0.0,
      "step": 8975
    },
    {
      "epoch": 6.864988558352403,
      "grad_norm": 0.0,
      "learning_rate": 6.272415108737123e-05,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 6.884057971014493,
      "grad_norm": 0.0,
      "learning_rate": 6.234261732163297e-05,
      "loss": 0.0,
      "step": 9025
    },
    {
      "epoch": 6.9031273836765825,
      "grad_norm": 0.0,
      "learning_rate": 6.196108355589469e-05,
      "loss": 0.0,
      "step": 9050
    },
    {
      "epoch": 6.922196796338673,
      "grad_norm": 0.0,
      "learning_rate": 6.157954979015644e-05,
      "loss": 0.0,
      "step": 9075
    },
    {
      "epoch": 6.941266209000763,
      "grad_norm": 0.0,
      "learning_rate": 6.119801602441815e-05,
      "loss": 0.0,
      "step": 9100
    },
    {
      "epoch": 6.9603356216628525,
      "grad_norm": 0.0,
      "learning_rate": 6.08164822586799e-05,
      "loss": 0.0,
      "step": 9125
    },
    {
      "epoch": 6.979405034324943,
      "grad_norm": 0.0,
      "learning_rate": 6.043494849294162e-05,
      "loss": 0.0,
      "step": 9150
    },
    {
      "epoch": 6.998474446987033,
      "grad_norm": 0.0,
      "learning_rate": 6.005341472720336e-05,
      "loss": 0.0,
      "step": 9175
    },
    {
      "epoch": 7.017543859649122,
      "grad_norm": 0.0,
      "learning_rate": 5.9671880961465085e-05,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 7.036613272311213,
      "grad_norm": 0.0,
      "learning_rate": 5.929034719572682e-05,
      "loss": 0.0,
      "step": 9225
    },
    {
      "epoch": 7.055682684973303,
      "grad_norm": 0.0,
      "learning_rate": 5.8908813429988554e-05,
      "loss": 0.0,
      "step": 9250
    },
    {
      "epoch": 7.074752097635393,
      "grad_norm": 0.0,
      "learning_rate": 5.852727966425029e-05,
      "loss": 0.0,
      "step": 9275
    },
    {
      "epoch": 7.093821510297483,
      "grad_norm": 0.0,
      "learning_rate": 5.8145745898512016e-05,
      "loss": 0.0,
      "step": 9300
    },
    {
      "epoch": 7.112890922959573,
      "grad_norm": 0.0,
      "learning_rate": 5.7764212132773754e-05,
      "loss": 0.0,
      "step": 9325
    },
    {
      "epoch": 7.131960335621663,
      "grad_norm": 0.0,
      "learning_rate": 5.738267836703548e-05,
      "loss": 0.0,
      "step": 9350
    },
    {
      "epoch": 7.151029748283753,
      "grad_norm": 0.0,
      "learning_rate": 5.7001144601297216e-05,
      "loss": 0.0,
      "step": 9375
    },
    {
      "epoch": 7.170099160945843,
      "grad_norm": 0.0,
      "learning_rate": 5.661961083555895e-05,
      "loss": 0.0,
      "step": 9400
    },
    {
      "epoch": 7.189168573607933,
      "grad_norm": 0.0,
      "learning_rate": 5.6238077069820685e-05,
      "loss": 0.0,
      "step": 9425
    },
    {
      "epoch": 7.2082379862700225,
      "grad_norm": 0.0,
      "learning_rate": 5.585654330408241e-05,
      "loss": 0.0,
      "step": 9450
    },
    {
      "epoch": 7.227307398932113,
      "grad_norm": 0.0,
      "learning_rate": 5.547500953834415e-05,
      "loss": 0.0,
      "step": 9475
    },
    {
      "epoch": 7.246376811594203,
      "grad_norm": 0.0,
      "learning_rate": 5.509347577260587e-05,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 7.2654462242562925,
      "grad_norm": 0.0,
      "learning_rate": 5.471194200686761e-05,
      "loss": 0.0,
      "step": 9525
    },
    {
      "epoch": 7.284515636918383,
      "grad_norm": 0.0,
      "learning_rate": 5.433040824112934e-05,
      "loss": 0.0,
      "step": 9550
    },
    {
      "epoch": 7.303585049580473,
      "grad_norm": 0.0,
      "learning_rate": 5.394887447539108e-05,
      "loss": 0.0,
      "step": 9575
    },
    {
      "epoch": 7.322654462242563,
      "grad_norm": 0.0,
      "learning_rate": 5.35673407096528e-05,
      "loss": 0.0,
      "step": 9600
    },
    {
      "epoch": 7.341723874904653,
      "grad_norm": 0.0,
      "learning_rate": 5.318580694391454e-05,
      "loss": 0.0,
      "step": 9625
    },
    {
      "epoch": 7.360793287566743,
      "grad_norm": 0.0,
      "learning_rate": 5.2804273178176265e-05,
      "loss": 0.0,
      "step": 9650
    },
    {
      "epoch": 7.379862700228833,
      "grad_norm": 0.0,
      "learning_rate": 5.2422739412438e-05,
      "loss": 0.0,
      "step": 9675
    },
    {
      "epoch": 7.398932112890923,
      "grad_norm": 0.0,
      "learning_rate": 5.2041205646699734e-05,
      "loss": 0.0,
      "step": 9700
    },
    {
      "epoch": 7.418001525553013,
      "grad_norm": 0.0,
      "learning_rate": 5.165967188096147e-05,
      "loss": 0.0,
      "step": 9725
    },
    {
      "epoch": 7.437070938215103,
      "grad_norm": 0.0,
      "learning_rate": 5.1278138115223196e-05,
      "loss": 0.0,
      "step": 9750
    },
    {
      "epoch": 7.456140350877193,
      "grad_norm": 0.0,
      "learning_rate": 5.0896604349484934e-05,
      "loss": 0.0,
      "step": 9775
    },
    {
      "epoch": 7.475209763539283,
      "grad_norm": 0.0,
      "learning_rate": 5.051507058374666e-05,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 7.494279176201373,
      "grad_norm": 0.0,
      "learning_rate": 5.0133536818008397e-05,
      "loss": 0.0,
      "step": 9825
    },
    {
      "epoch": 7.5133485888634635,
      "grad_norm": 0.0,
      "learning_rate": 4.975200305227013e-05,
      "loss": 0.0,
      "step": 9850
    },
    {
      "epoch": 7.532418001525553,
      "grad_norm": 0.0,
      "learning_rate": 4.937046928653186e-05,
      "loss": 0.0,
      "step": 9875
    },
    {
      "epoch": 7.551487414187643,
      "grad_norm": 0.0,
      "learning_rate": 4.89889355207936e-05,
      "loss": 0.0,
      "step": 9900
    },
    {
      "epoch": 7.570556826849733,
      "grad_norm": 0.0,
      "learning_rate": 4.860740175505533e-05,
      "loss": 0.0,
      "step": 9925
    },
    {
      "epoch": 7.589626239511823,
      "grad_norm": 0.0,
      "learning_rate": 4.822586798931706e-05,
      "loss": 0.0,
      "step": 9950
    },
    {
      "epoch": 7.608695652173913,
      "grad_norm": 0.0,
      "learning_rate": 4.784433422357879e-05,
      "loss": 0.0,
      "step": 9975
    },
    {
      "epoch": 7.627765064836003,
      "grad_norm": 0.0,
      "learning_rate": 4.746280045784052e-05,
      "loss": 0.0,
      "step": 10000
    },
    {
      "epoch": 7.646834477498093,
      "grad_norm": 0.0,
      "learning_rate": 4.708126669210225e-05,
      "loss": 0.0,
      "step": 10025
    },
    {
      "epoch": 7.665903890160183,
      "grad_norm": 0.0,
      "learning_rate": 4.669973292636399e-05,
      "loss": 0.0,
      "step": 10050
    },
    {
      "epoch": 7.684973302822273,
      "grad_norm": 0.0,
      "learning_rate": 4.631819916062572e-05,
      "loss": 0.0,
      "step": 10075
    },
    {
      "epoch": 7.704042715484363,
      "grad_norm": 0.0,
      "learning_rate": 4.593666539488745e-05,
      "loss": 0.0,
      "step": 10100
    },
    {
      "epoch": 7.723112128146453,
      "grad_norm": 0.0,
      "learning_rate": 4.5555131629149183e-05,
      "loss": 0.0,
      "step": 10125
    },
    {
      "epoch": 7.742181540808543,
      "grad_norm": 0.0,
      "learning_rate": 4.5173597863410915e-05,
      "loss": 0.0,
      "step": 10150
    },
    {
      "epoch": 7.761250953470633,
      "grad_norm": 0.0,
      "learning_rate": 4.4792064097672646e-05,
      "loss": 0.0,
      "step": 10175
    },
    {
      "epoch": 7.780320366132723,
      "grad_norm": 0.0,
      "learning_rate": 4.4410530331934383e-05,
      "loss": 0.0,
      "step": 10200
    },
    {
      "epoch": 7.799389778794813,
      "grad_norm": 0.0,
      "learning_rate": 4.4028996566196115e-05,
      "loss": 0.0,
      "step": 10225
    },
    {
      "epoch": 7.8184591914569035,
      "grad_norm": 0.0,
      "learning_rate": 4.3647462800457846e-05,
      "loss": 0.0,
      "step": 10250
    },
    {
      "epoch": 7.837528604118993,
      "grad_norm": 0.0,
      "learning_rate": 4.326592903471958e-05,
      "loss": 0.0,
      "step": 10275
    },
    {
      "epoch": 7.856598016781083,
      "grad_norm": 0.0,
      "learning_rate": 4.288439526898131e-05,
      "loss": 0.0,
      "step": 10300
    },
    {
      "epoch": 7.875667429443173,
      "grad_norm": 0.0,
      "learning_rate": 4.250286150324304e-05,
      "loss": 0.0,
      "step": 10325
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 0.0,
      "learning_rate": 4.212132773750477e-05,
      "loss": 0.0,
      "step": 10350
    },
    {
      "epoch": 7.913806254767353,
      "grad_norm": 0.0,
      "learning_rate": 4.173979397176651e-05,
      "loss": 0.0,
      "step": 10375
    },
    {
      "epoch": 7.932875667429443,
      "grad_norm": 0.0,
      "learning_rate": 4.135826020602824e-05,
      "loss": 0.0,
      "step": 10400
    },
    {
      "epoch": 7.951945080091534,
      "grad_norm": 0.0,
      "learning_rate": 4.097672644028997e-05,
      "loss": 0.0,
      "step": 10425
    },
    {
      "epoch": 7.971014492753623,
      "grad_norm": 0.0,
      "learning_rate": 4.05951926745517e-05,
      "loss": 0.0,
      "step": 10450
    },
    {
      "epoch": 7.990083905415713,
      "grad_norm": 0.0,
      "learning_rate": 4.021365890881343e-05,
      "loss": 0.0,
      "step": 10475
    },
    {
      "epoch": 8.009153318077804,
      "grad_norm": 0.0,
      "learning_rate": 3.9832125143075164e-05,
      "loss": 0.0,
      "step": 10500
    },
    {
      "epoch": 8.028222730739893,
      "grad_norm": 0.0,
      "learning_rate": 3.94505913773369e-05,
      "loss": 0.0,
      "step": 10525
    },
    {
      "epoch": 8.047292143401982,
      "grad_norm": 0.0,
      "learning_rate": 3.906905761159863e-05,
      "loss": 0.0,
      "step": 10550
    },
    {
      "epoch": 8.066361556064074,
      "grad_norm": 0.0,
      "learning_rate": 3.8687523845860364e-05,
      "loss": 0.0,
      "step": 10575
    },
    {
      "epoch": 8.085430968726163,
      "grad_norm": 0.0,
      "learning_rate": 3.8305990080122095e-05,
      "loss": 0.0,
      "step": 10600
    },
    {
      "epoch": 8.104500381388252,
      "grad_norm": 0.0,
      "learning_rate": 3.7924456314383826e-05,
      "loss": 0.0,
      "step": 10625
    },
    {
      "epoch": 8.123569794050344,
      "grad_norm": 0.0,
      "learning_rate": 3.754292254864556e-05,
      "loss": 0.0,
      "step": 10650
    },
    {
      "epoch": 8.142639206712433,
      "grad_norm": 0.0,
      "learning_rate": 3.716138878290729e-05,
      "loss": 0.0,
      "step": 10675
    },
    {
      "epoch": 8.161708619374524,
      "grad_norm": 0.0,
      "learning_rate": 3.6779855017169026e-05,
      "loss": 0.0,
      "step": 10700
    },
    {
      "epoch": 8.180778032036613,
      "grad_norm": 0.0,
      "learning_rate": 3.639832125143076e-05,
      "loss": 0.0,
      "step": 10725
    },
    {
      "epoch": 8.199847444698703,
      "grad_norm": 0.0,
      "learning_rate": 3.601678748569249e-05,
      "loss": 0.0,
      "step": 10750
    },
    {
      "epoch": 8.218916857360794,
      "grad_norm": 0.0,
      "learning_rate": 3.563525371995422e-05,
      "loss": 0.0,
      "step": 10775
    },
    {
      "epoch": 8.237986270022883,
      "grad_norm": 0.0,
      "learning_rate": 3.525371995421595e-05,
      "loss": 0.0,
      "step": 10800
    },
    {
      "epoch": 8.257055682684973,
      "grad_norm": 0.0,
      "learning_rate": 3.487218618847768e-05,
      "loss": 0.0,
      "step": 10825
    },
    {
      "epoch": 8.276125095347064,
      "grad_norm": 0.0,
      "learning_rate": 3.449065242273942e-05,
      "loss": 0.0,
      "step": 10850
    },
    {
      "epoch": 8.295194508009153,
      "grad_norm": 0.0,
      "learning_rate": 3.410911865700115e-05,
      "loss": 0.0,
      "step": 10875
    },
    {
      "epoch": 8.314263920671243,
      "grad_norm": 0.0,
      "learning_rate": 3.372758489126288e-05,
      "loss": 0.0,
      "step": 10900
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.0,
      "learning_rate": 3.334605112552461e-05,
      "loss": 0.0,
      "step": 10925
    },
    {
      "epoch": 8.352402745995423,
      "grad_norm": 0.0,
      "learning_rate": 3.296451735978634e-05,
      "loss": 0.0,
      "step": 10950
    },
    {
      "epoch": 8.371472158657513,
      "grad_norm": 0.0,
      "learning_rate": 3.2582983594048075e-05,
      "loss": 0.0,
      "step": 10975
    },
    {
      "epoch": 8.390541571319604,
      "grad_norm": 0.0,
      "learning_rate": 3.2201449828309806e-05,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 8.409610983981693,
      "grad_norm": 0.0,
      "learning_rate": 3.181991606257154e-05,
      "loss": 0.0,
      "step": 11025
    },
    {
      "epoch": 8.428680396643783,
      "grad_norm": 0.0,
      "learning_rate": 3.143838229683327e-05,
      "loss": 0.0,
      "step": 11050
    },
    {
      "epoch": 8.447749809305874,
      "grad_norm": 0.0,
      "learning_rate": 3.1056848531095e-05,
      "loss": 0.0,
      "step": 11075
    },
    {
      "epoch": 8.466819221967963,
      "grad_norm": 0.0,
      "learning_rate": 3.067531476535673e-05,
      "loss": 0.0,
      "step": 11100
    },
    {
      "epoch": 8.485888634630053,
      "grad_norm": 0.0,
      "learning_rate": 3.0293780999618465e-05,
      "loss": 0.0,
      "step": 11125
    },
    {
      "epoch": 8.504958047292144,
      "grad_norm": 0.0,
      "learning_rate": 2.9912247233880196e-05,
      "loss": 0.0,
      "step": 11150
    },
    {
      "epoch": 8.524027459954233,
      "grad_norm": 0.0,
      "learning_rate": 2.953071346814193e-05,
      "loss": 0.0,
      "step": 11175
    },
    {
      "epoch": 8.543096872616324,
      "grad_norm": 0.0,
      "learning_rate": 2.9149179702403662e-05,
      "loss": 0.0,
      "step": 11200
    },
    {
      "epoch": 8.562166285278414,
      "grad_norm": 0.0,
      "learning_rate": 2.8767645936665393e-05,
      "loss": 0.0,
      "step": 11225
    },
    {
      "epoch": 8.581235697940503,
      "grad_norm": 0.0,
      "learning_rate": 2.8386112170927127e-05,
      "loss": 0.0,
      "step": 11250
    },
    {
      "epoch": 8.600305110602594,
      "grad_norm": 0.0,
      "learning_rate": 2.800457840518886e-05,
      "loss": 0.0,
      "step": 11275
    },
    {
      "epoch": 8.619374523264684,
      "grad_norm": 0.0,
      "learning_rate": 2.762304463945059e-05,
      "loss": 0.0,
      "step": 11300
    },
    {
      "epoch": 8.638443935926773,
      "grad_norm": 0.0,
      "learning_rate": 2.7241510873712324e-05,
      "loss": 0.0,
      "step": 11325
    },
    {
      "epoch": 8.657513348588864,
      "grad_norm": 0.0,
      "learning_rate": 2.6859977107974055e-05,
      "loss": 0.0,
      "step": 11350
    },
    {
      "epoch": 8.676582761250954,
      "grad_norm": 0.0,
      "learning_rate": 2.6478443342235786e-05,
      "loss": 0.0,
      "step": 11375
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 0.0,
      "learning_rate": 2.6096909576497517e-05,
      "loss": 0.0,
      "step": 11400
    },
    {
      "epoch": 8.714721586575134,
      "grad_norm": 0.0,
      "learning_rate": 2.5715375810759252e-05,
      "loss": 0.0,
      "step": 11425
    },
    {
      "epoch": 8.733790999237224,
      "grad_norm": 0.0,
      "learning_rate": 2.5333842045020983e-05,
      "loss": 0.0,
      "step": 11450
    },
    {
      "epoch": 8.752860411899313,
      "grad_norm": 0.0,
      "learning_rate": 2.4952308279282718e-05,
      "loss": 0.0,
      "step": 11475
    },
    {
      "epoch": 8.771929824561404,
      "grad_norm": 0.0,
      "learning_rate": 2.4570774513544452e-05,
      "loss": 0.0,
      "step": 11500
    },
    {
      "epoch": 8.790999237223494,
      "grad_norm": 0.0,
      "learning_rate": 2.4189240747806183e-05,
      "loss": 0.0,
      "step": 11525
    },
    {
      "epoch": 8.810068649885583,
      "grad_norm": 0.0,
      "learning_rate": 2.3807706982067914e-05,
      "loss": 0.0,
      "step": 11550
    },
    {
      "epoch": 8.829138062547674,
      "grad_norm": 0.0,
      "learning_rate": 2.342617321632965e-05,
      "loss": 0.0,
      "step": 11575
    },
    {
      "epoch": 8.848207475209763,
      "grad_norm": 0.0,
      "learning_rate": 2.304463945059138e-05,
      "loss": 0.0,
      "step": 11600
    },
    {
      "epoch": 8.867276887871853,
      "grad_norm": 0.0,
      "learning_rate": 2.266310568485311e-05,
      "loss": 0.0,
      "step": 11625
    },
    {
      "epoch": 8.886346300533944,
      "grad_norm": 0.0,
      "learning_rate": 2.2281571919114842e-05,
      "loss": 0.0,
      "step": 11650
    },
    {
      "epoch": 8.905415713196033,
      "grad_norm": 0.0,
      "learning_rate": 2.1900038153376577e-05,
      "loss": 0.0,
      "step": 11675
    },
    {
      "epoch": 8.924485125858123,
      "grad_norm": 0.0,
      "learning_rate": 2.1518504387638308e-05,
      "loss": 0.0,
      "step": 11700
    },
    {
      "epoch": 8.943554538520214,
      "grad_norm": 0.0,
      "learning_rate": 2.113697062190004e-05,
      "loss": 0.0,
      "step": 11725
    },
    {
      "epoch": 8.962623951182303,
      "grad_norm": 0.0,
      "learning_rate": 2.0755436856161773e-05,
      "loss": 0.0,
      "step": 11750
    },
    {
      "epoch": 8.981693363844393,
      "grad_norm": 0.0,
      "learning_rate": 2.0373903090423504e-05,
      "loss": 0.0,
      "step": 11775
    },
    {
      "epoch": 9.000762776506484,
      "grad_norm": 0.0,
      "learning_rate": 1.9992369324685236e-05,
      "loss": 0.0,
      "step": 11800
    },
    {
      "epoch": 9.019832189168573,
      "grad_norm": 0.0,
      "learning_rate": 1.961083555894697e-05,
      "loss": 0.0,
      "step": 11825
    },
    {
      "epoch": 9.038901601830664,
      "grad_norm": 0.0,
      "learning_rate": 1.92293017932087e-05,
      "loss": 0.0,
      "step": 11850
    },
    {
      "epoch": 9.057971014492754,
      "grad_norm": 0.0,
      "learning_rate": 1.8847768027470432e-05,
      "loss": 0.0,
      "step": 11875
    },
    {
      "epoch": 9.077040427154843,
      "grad_norm": 0.0,
      "learning_rate": 1.8466234261732167e-05,
      "loss": 0.0,
      "step": 11900
    },
    {
      "epoch": 9.096109839816934,
      "grad_norm": 0.0,
      "learning_rate": 1.8084700495993898e-05,
      "loss": 0.0,
      "step": 11925
    },
    {
      "epoch": 9.115179252479024,
      "grad_norm": 0.0,
      "learning_rate": 1.770316673025563e-05,
      "loss": 0.0,
      "step": 11950
    },
    {
      "epoch": 9.134248665141113,
      "grad_norm": 0.0,
      "learning_rate": 1.7321632964517364e-05,
      "loss": 0.0,
      "step": 11975
    },
    {
      "epoch": 9.153318077803204,
      "grad_norm": 0.0,
      "learning_rate": 1.6940099198779095e-05,
      "loss": 0.0,
      "step": 12000
    },
    {
      "epoch": 9.172387490465294,
      "grad_norm": 0.0,
      "learning_rate": 1.6558565433040822e-05,
      "loss": 0.0,
      "step": 12025
    },
    {
      "epoch": 9.191456903127383,
      "grad_norm": 0.0,
      "learning_rate": 1.6177031667302557e-05,
      "loss": 0.0,
      "step": 12050
    },
    {
      "epoch": 9.210526315789474,
      "grad_norm": 0.0,
      "learning_rate": 1.5795497901564288e-05,
      "loss": 0.0,
      "step": 12075
    },
    {
      "epoch": 9.229595728451564,
      "grad_norm": 0.0,
      "learning_rate": 1.541396413582602e-05,
      "loss": 0.0,
      "step": 12100
    },
    {
      "epoch": 9.248665141113653,
      "grad_norm": 0.0,
      "learning_rate": 1.5032430370087752e-05,
      "loss": 0.0,
      "step": 12125
    },
    {
      "epoch": 9.267734553775744,
      "grad_norm": 0.0,
      "learning_rate": 1.4650896604349485e-05,
      "loss": 0.0,
      "step": 12150
    },
    {
      "epoch": 9.286803966437834,
      "grad_norm": 0.0,
      "learning_rate": 1.4269362838611216e-05,
      "loss": 0.0,
      "step": 12175
    },
    {
      "epoch": 9.305873379099923,
      "grad_norm": 0.0,
      "learning_rate": 1.3887829072872949e-05,
      "loss": 0.0,
      "step": 12200
    },
    {
      "epoch": 9.324942791762014,
      "grad_norm": 0.0,
      "learning_rate": 1.3506295307134681e-05,
      "loss": 0.0,
      "step": 12225
    },
    {
      "epoch": 9.344012204424104,
      "grad_norm": 0.0,
      "learning_rate": 1.3124761541396413e-05,
      "loss": 0.0,
      "step": 12250
    },
    {
      "epoch": 9.363081617086193,
      "grad_norm": 0.0,
      "learning_rate": 1.2743227775658145e-05,
      "loss": 0.0,
      "step": 12275
    },
    {
      "epoch": 9.382151029748284,
      "grad_norm": 0.0,
      "learning_rate": 1.2361694009919878e-05,
      "loss": 0.0,
      "step": 12300
    },
    {
      "epoch": 9.401220442410374,
      "grad_norm": 0.0,
      "learning_rate": 1.1980160244181611e-05,
      "loss": 0.0,
      "step": 12325
    },
    {
      "epoch": 9.420289855072463,
      "grad_norm": 0.0,
      "learning_rate": 1.1598626478443344e-05,
      "loss": 0.0,
      "step": 12350
    },
    {
      "epoch": 9.439359267734554,
      "grad_norm": 0.0,
      "learning_rate": 1.1217092712705075e-05,
      "loss": 0.0,
      "step": 12375
    },
    {
      "epoch": 9.458428680396644,
      "grad_norm": 0.0,
      "learning_rate": 1.0835558946966808e-05,
      "loss": 0.0,
      "step": 12400
    },
    {
      "epoch": 9.477498093058735,
      "grad_norm": 0.0,
      "learning_rate": 1.045402518122854e-05,
      "loss": 0.0,
      "step": 12425
    },
    {
      "epoch": 9.496567505720824,
      "grad_norm": 0.0,
      "learning_rate": 1.0072491415490272e-05,
      "loss": 0.0,
      "step": 12450
    },
    {
      "epoch": 9.515636918382913,
      "grad_norm": 0.0,
      "learning_rate": 9.690957649752004e-06,
      "loss": 0.0,
      "step": 12475
    },
    {
      "epoch": 9.534706331045005,
      "grad_norm": 0.0,
      "learning_rate": 9.309423884013735e-06,
      "loss": 0.0,
      "step": 12500
    },
    {
      "epoch": 9.553775743707094,
      "grad_norm": 0.0,
      "learning_rate": 8.927890118275468e-06,
      "loss": 0.0,
      "step": 12525
    },
    {
      "epoch": 9.572845156369183,
      "grad_norm": 0.0,
      "learning_rate": 8.546356352537201e-06,
      "loss": 0.0,
      "step": 12550
    },
    {
      "epoch": 9.591914569031275,
      "grad_norm": 0.0,
      "learning_rate": 8.164822586798932e-06,
      "loss": 0.0,
      "step": 12575
    },
    {
      "epoch": 9.610983981693364,
      "grad_norm": 0.0,
      "learning_rate": 7.783288821060663e-06,
      "loss": 0.0,
      "step": 12600
    },
    {
      "epoch": 9.630053394355453,
      "grad_norm": 0.0,
      "learning_rate": 7.401755055322396e-06,
      "loss": 0.0,
      "step": 12625
    },
    {
      "epoch": 9.649122807017545,
      "grad_norm": 0.0,
      "learning_rate": 7.020221289584128e-06,
      "loss": 0.0,
      "step": 12650
    },
    {
      "epoch": 9.668192219679634,
      "grad_norm": 0.0,
      "learning_rate": 6.63868752384586e-06,
      "loss": 0.0,
      "step": 12675
    },
    {
      "epoch": 9.687261632341723,
      "grad_norm": 0.0,
      "learning_rate": 6.257153758107592e-06,
      "loss": 0.0,
      "step": 12700
    },
    {
      "epoch": 9.706331045003814,
      "grad_norm": 0.0,
      "learning_rate": 5.875619992369325e-06,
      "loss": 0.0,
      "step": 12725
    },
    {
      "epoch": 9.725400457665904,
      "grad_norm": 0.0,
      "learning_rate": 5.494086226631058e-06,
      "loss": 0.0,
      "step": 12750
    },
    {
      "epoch": 9.744469870327993,
      "grad_norm": 0.0,
      "learning_rate": 5.1125524608927896e-06,
      "loss": 0.0,
      "step": 12775
    },
    {
      "epoch": 9.763539282990084,
      "grad_norm": 0.0,
      "learning_rate": 4.7310186951545215e-06,
      "loss": 0.0,
      "step": 12800
    },
    {
      "epoch": 9.782608695652174,
      "grad_norm": 0.0,
      "learning_rate": 4.3494849294162535e-06,
      "loss": 0.0,
      "step": 12825
    },
    {
      "epoch": 9.801678108314263,
      "grad_norm": 0.0,
      "learning_rate": 3.9679511636779854e-06,
      "loss": 0.0,
      "step": 12850
    },
    {
      "epoch": 9.820747520976354,
      "grad_norm": 0.0,
      "learning_rate": 3.5864173979397174e-06,
      "loss": 0.0,
      "step": 12875
    },
    {
      "epoch": 9.839816933638444,
      "grad_norm": 0.0,
      "learning_rate": 3.2048836322014498e-06,
      "loss": 0.0,
      "step": 12900
    },
    {
      "epoch": 9.858886346300533,
      "grad_norm": 0.0,
      "learning_rate": 2.823349866463182e-06,
      "loss": 0.0,
      "step": 12925
    },
    {
      "epoch": 9.877955758962624,
      "grad_norm": 0.0,
      "learning_rate": 2.4418161007249145e-06,
      "loss": 0.0,
      "step": 12950
    },
    {
      "epoch": 9.897025171624714,
      "grad_norm": 0.0,
      "learning_rate": 2.060282334986646e-06,
      "loss": 0.0,
      "step": 12975
    },
    {
      "epoch": 9.916094584286803,
      "grad_norm": 0.0,
      "learning_rate": 1.6787485692483785e-06,
      "loss": 0.0,
      "step": 13000
    },
    {
      "epoch": 9.935163996948894,
      "grad_norm": 0.0,
      "learning_rate": 1.2972148035101108e-06,
      "loss": 0.0,
      "step": 13025
    },
    {
      "epoch": 9.954233409610984,
      "grad_norm": 0.0,
      "learning_rate": 9.156810377718428e-07,
      "loss": 0.0,
      "step": 13050
    },
    {
      "epoch": 9.973302822273073,
      "grad_norm": 0.0,
      "learning_rate": 5.341472720335751e-07,
      "loss": 0.0,
      "step": 13075
    },
    {
      "epoch": 9.992372234935164,
      "grad_norm": 0.0,
      "learning_rate": 1.5261350629530716e-07,
      "loss": 0.0,
      "step": 13100
    }
  ],
  "logging_steps": 25,
  "max_steps": 13110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.361290920396718e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
