{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 102,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03007518796992481,
      "grad_norm": 0.23022182285785675,
      "learning_rate": 0.0,
      "loss": 2.1261,
      "step": 1
    },
    {
      "epoch": 0.06015037593984962,
      "grad_norm": 0.22903886437416077,
      "learning_rate": 3.6363636363636366e-06,
      "loss": 1.9786,
      "step": 2
    },
    {
      "epoch": 0.09022556390977443,
      "grad_norm": 0.24579204618930817,
      "learning_rate": 7.272727272727273e-06,
      "loss": 2.0974,
      "step": 3
    },
    {
      "epoch": 0.12030075187969924,
      "grad_norm": 0.24284453690052032,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 2.0506,
      "step": 4
    },
    {
      "epoch": 0.15037593984962405,
      "grad_norm": 0.2773923873901367,
      "learning_rate": 1.4545454545454546e-05,
      "loss": 2.0481,
      "step": 5
    },
    {
      "epoch": 0.18045112781954886,
      "grad_norm": 0.26509997248649597,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.9806,
      "step": 6
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 0.24832874536514282,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 2.0941,
      "step": 7
    },
    {
      "epoch": 0.24060150375939848,
      "grad_norm": 0.25370416045188904,
      "learning_rate": 2.5454545454545457e-05,
      "loss": 2.0802,
      "step": 8
    },
    {
      "epoch": 0.2706766917293233,
      "grad_norm": 0.251737117767334,
      "learning_rate": 2.9090909090909093e-05,
      "loss": 2.0916,
      "step": 9
    },
    {
      "epoch": 0.3007518796992481,
      "grad_norm": 0.2596747875213623,
      "learning_rate": 3.272727272727273e-05,
      "loss": 2.023,
      "step": 10
    },
    {
      "epoch": 0.3308270676691729,
      "grad_norm": 0.26450589299201965,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 2.0678,
      "step": 11
    },
    {
      "epoch": 0.3609022556390977,
      "grad_norm": 0.27257290482521057,
      "learning_rate": 4e-05,
      "loss": 2.046,
      "step": 12
    },
    {
      "epoch": 0.39097744360902253,
      "grad_norm": 0.25821876525878906,
      "learning_rate": 3.998808281102141e-05,
      "loss": 1.9847,
      "step": 13
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 0.2983117401599884,
      "learning_rate": 3.995234544602496e-05,
      "loss": 1.9856,
      "step": 14
    },
    {
      "epoch": 0.45112781954887216,
      "grad_norm": 0.2802351415157318,
      "learning_rate": 3.9892830493903855e-05,
      "loss": 1.9973,
      "step": 15
    },
    {
      "epoch": 0.48120300751879697,
      "grad_norm": 0.2688964605331421,
      "learning_rate": 3.980960887975127e-05,
      "loss": 2.0366,
      "step": 16
    },
    {
      "epoch": 0.5112781954887218,
      "grad_norm": 0.2545585632324219,
      "learning_rate": 3.9702779780337476e-05,
      "loss": 1.9944,
      "step": 17
    },
    {
      "epoch": 0.5413533834586466,
      "grad_norm": 0.22684906423091888,
      "learning_rate": 3.957247050591911e-05,
      "loss": 2.0173,
      "step": 18
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.21706083416938782,
      "learning_rate": 3.9418836348521045e-05,
      "loss": 1.9516,
      "step": 19
    },
    {
      "epoch": 0.6015037593984962,
      "grad_norm": 0.1832977682352066,
      "learning_rate": 3.9242060396872014e-05,
      "loss": 1.9283,
      "step": 20
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 0.17664214968681335,
      "learning_rate": 3.904235331821428e-05,
      "loss": 1.9053,
      "step": 21
    },
    {
      "epoch": 0.6616541353383458,
      "grad_norm": 0.15711386501789093,
      "learning_rate": 3.881995310724753e-05,
      "loss": 1.8947,
      "step": 22
    },
    {
      "epoch": 0.6917293233082706,
      "grad_norm": 0.15681125223636627,
      "learning_rate": 3.8575124802506046e-05,
      "loss": 1.869,
      "step": 23
    },
    {
      "epoch": 0.7218045112781954,
      "grad_norm": 0.15472131967544556,
      "learning_rate": 3.830816017050733e-05,
      "loss": 1.8736,
      "step": 24
    },
    {
      "epoch": 0.7518796992481203,
      "grad_norm": 0.15291298925876617,
      "learning_rate": 3.801937735804838e-05,
      "loss": 1.8636,
      "step": 25
    },
    {
      "epoch": 0.7819548872180451,
      "grad_norm": 0.1682579666376114,
      "learning_rate": 3.7709120513064196e-05,
      "loss": 1.7817,
      "step": 26
    },
    {
      "epoch": 0.8120300751879699,
      "grad_norm": 0.19014444947242737,
      "learning_rate": 3.7377759374500135e-05,
      "loss": 1.9049,
      "step": 27
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.17066052556037903,
      "learning_rate": 3.702568883168703e-05,
      "loss": 1.8032,
      "step": 28
    },
    {
      "epoch": 0.8721804511278195,
      "grad_norm": 0.1540166735649109,
      "learning_rate": 3.6653328453744125e-05,
      "loss": 1.8257,
      "step": 29
    },
    {
      "epoch": 0.9022556390977443,
      "grad_norm": 0.17475466430187225,
      "learning_rate": 3.626112198957065e-05,
      "loss": 1.8889,
      "step": 30
    },
    {
      "epoch": 0.9323308270676691,
      "grad_norm": 0.17635752260684967,
      "learning_rate": 3.584953683902181e-05,
      "loss": 1.8374,
      "step": 31
    },
    {
      "epoch": 0.9624060150375939,
      "grad_norm": 0.1924305558204651,
      "learning_rate": 3.541906349589959e-05,
      "loss": 1.8695,
      "step": 32
    },
    {
      "epoch": 0.9924812030075187,
      "grad_norm": 0.1786973625421524,
      "learning_rate": 3.497021496342203e-05,
      "loss": 1.8049,
      "step": 33
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2838294804096222,
      "learning_rate": 3.450352614286753e-05,
      "loss": 1.96,
      "step": 34
    },
    {
      "epoch": 1.0300751879699248,
      "grad_norm": 0.1584615260362625,
      "learning_rate": 3.401955319612299e-05,
      "loss": 1.7941,
      "step": 35
    },
    {
      "epoch": 1.0601503759398496,
      "grad_norm": 0.1582818180322647,
      "learning_rate": 3.351887288289509e-05,
      "loss": 1.7453,
      "step": 36
    },
    {
      "epoch": 1.0902255639097744,
      "grad_norm": 0.14984609186649323,
      "learning_rate": 3.300208187337489e-05,
      "loss": 1.7438,
      "step": 37
    },
    {
      "epoch": 1.1203007518796992,
      "grad_norm": 0.15612079203128815,
      "learning_rate": 3.246979603717467e-05,
      "loss": 1.8003,
      "step": 38
    },
    {
      "epoch": 1.150375939849624,
      "grad_norm": 0.15499481558799744,
      "learning_rate": 3.192264970938451e-05,
      "loss": 1.78,
      "step": 39
    },
    {
      "epoch": 1.1804511278195489,
      "grad_norm": 0.16221961379051208,
      "learning_rate": 3.136129493462312e-05,
      "loss": 1.7515,
      "step": 40
    },
    {
      "epoch": 1.2105263157894737,
      "grad_norm": 0.15227250754833221,
      "learning_rate": 3.0786400689983986e-05,
      "loss": 1.8044,
      "step": 41
    },
    {
      "epoch": 1.2406015037593985,
      "grad_norm": 0.16534534096717834,
      "learning_rate": 3.0198652087802722e-05,
      "loss": 1.7323,
      "step": 42
    },
    {
      "epoch": 1.2706766917293233,
      "grad_norm": 0.16553084552288055,
      "learning_rate": 2.959874955919573e-05,
      "loss": 1.7284,
      "step": 43
    },
    {
      "epoch": 1.300751879699248,
      "grad_norm": 0.1826937049627304,
      "learning_rate": 2.898740801934323e-05,
      "loss": 1.6864,
      "step": 44
    },
    {
      "epoch": 1.330827067669173,
      "grad_norm": 0.18002353608608246,
      "learning_rate": 2.8365356015511305e-05,
      "loss": 1.7393,
      "step": 45
    },
    {
      "epoch": 1.3609022556390977,
      "grad_norm": 0.20241424441337585,
      "learning_rate": 2.7733334858828376e-05,
      "loss": 1.734,
      "step": 46
    },
    {
      "epoch": 1.3909774436090225,
      "grad_norm": 0.1762356162071228,
      "learning_rate": 2.7092097740850712e-05,
      "loss": 1.674,
      "step": 47
    },
    {
      "epoch": 1.4210526315789473,
      "grad_norm": 0.1952267587184906,
      "learning_rate": 2.6442408835969814e-05,
      "loss": 1.719,
      "step": 48
    },
    {
      "epoch": 1.4511278195488722,
      "grad_norm": 0.18530817329883575,
      "learning_rate": 2.5785042390731358e-05,
      "loss": 1.6524,
      "step": 49
    },
    {
      "epoch": 1.481203007518797,
      "grad_norm": 0.19248923659324646,
      "learning_rate": 2.5120781801150944e-05,
      "loss": 1.6697,
      "step": 50
    },
    {
      "epoch": 1.5112781954887218,
      "grad_norm": 0.20703737437725067,
      "learning_rate": 2.445041867912629e-05,
      "loss": 1.6594,
      "step": 51
    },
    {
      "epoch": 1.5413533834586466,
      "grad_norm": 0.18801791965961456,
      "learning_rate": 2.3774751909058335e-05,
      "loss": 1.7219,
      "step": 52
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.198623925447464,
      "learning_rate": 2.3094586695805625e-05,
      "loss": 1.7295,
      "step": 53
    },
    {
      "epoch": 1.6015037593984962,
      "grad_norm": 0.18107889592647552,
      "learning_rate": 2.2410733605106462e-05,
      "loss": 1.6896,
      "step": 54
    },
    {
      "epoch": 1.631578947368421,
      "grad_norm": 0.18787027895450592,
      "learning_rate": 2.172400759761239e-05,
      "loss": 1.7117,
      "step": 55
    },
    {
      "epoch": 1.6616541353383458,
      "grad_norm": 0.20289775729179382,
      "learning_rate": 2.1035227057684193e-05,
      "loss": 1.5732,
      "step": 56
    },
    {
      "epoch": 1.6917293233082706,
      "grad_norm": 0.18473060429096222,
      "learning_rate": 2.0345212818107774e-05,
      "loss": 1.6785,
      "step": 57
    },
    {
      "epoch": 1.7218045112781954,
      "grad_norm": 0.20190390944480896,
      "learning_rate": 1.9654787181892233e-05,
      "loss": 1.6843,
      "step": 58
    },
    {
      "epoch": 1.7518796992481203,
      "grad_norm": 0.19556404650211334,
      "learning_rate": 1.896477294231581e-05,
      "loss": 1.7105,
      "step": 59
    },
    {
      "epoch": 1.781954887218045,
      "grad_norm": 0.20838913321495056,
      "learning_rate": 1.8275992402387613e-05,
      "loss": 1.5768,
      "step": 60
    },
    {
      "epoch": 1.8120300751879699,
      "grad_norm": 0.21860376000404358,
      "learning_rate": 1.758926639489354e-05,
      "loss": 1.649,
      "step": 61
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 0.19639669358730316,
      "learning_rate": 1.6905413304194375e-05,
      "loss": 1.6533,
      "step": 62
    },
    {
      "epoch": 1.8721804511278195,
      "grad_norm": 0.22578758001327515,
      "learning_rate": 1.622524809094167e-05,
      "loss": 1.6609,
      "step": 63
    },
    {
      "epoch": 1.9022556390977443,
      "grad_norm": 0.22095882892608643,
      "learning_rate": 1.5549581320873715e-05,
      "loss": 1.5872,
      "step": 64
    },
    {
      "epoch": 1.9323308270676691,
      "grad_norm": 0.21056488156318665,
      "learning_rate": 1.4879218198849059e-05,
      "loss": 1.6666,
      "step": 65
    },
    {
      "epoch": 1.962406015037594,
      "grad_norm": 0.2516539990901947,
      "learning_rate": 1.4214957609268648e-05,
      "loss": 1.7679,
      "step": 66
    },
    {
      "epoch": 1.9924812030075187,
      "grad_norm": 0.20982983708381653,
      "learning_rate": 1.3557591164030193e-05,
      "loss": 1.6951,
      "step": 67
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4214635491371155,
      "learning_rate": 1.2907902259149287e-05,
      "loss": 1.6048,
      "step": 68
    },
    {
      "epoch": 2.030075187969925,
      "grad_norm": 0.2188495248556137,
      "learning_rate": 1.2266665141171625e-05,
      "loss": 1.597,
      "step": 69
    },
    {
      "epoch": 2.0601503759398496,
      "grad_norm": 0.21715326607227325,
      "learning_rate": 1.1634643984488703e-05,
      "loss": 1.6259,
      "step": 70
    },
    {
      "epoch": 2.090225563909774,
      "grad_norm": 0.22148774564266205,
      "learning_rate": 1.1012591980656771e-05,
      "loss": 1.5174,
      "step": 71
    },
    {
      "epoch": 2.1203007518796992,
      "grad_norm": 0.23128579556941986,
      "learning_rate": 1.0401250440804279e-05,
      "loss": 1.5994,
      "step": 72
    },
    {
      "epoch": 2.1503759398496243,
      "grad_norm": 0.2258131057024002,
      "learning_rate": 9.801347912197288e-06,
      "loss": 1.5057,
      "step": 73
    },
    {
      "epoch": 2.180451127819549,
      "grad_norm": 0.21417734026908875,
      "learning_rate": 9.213599310016019e-06,
      "loss": 1.5973,
      "step": 74
    },
    {
      "epoch": 2.2105263157894735,
      "grad_norm": 0.22901999950408936,
      "learning_rate": 8.638705065376887e-06,
      "loss": 1.6527,
      "step": 75
    },
    {
      "epoch": 2.2406015037593985,
      "grad_norm": 0.2213582545518875,
      "learning_rate": 8.077350290615495e-06,
      "loss": 1.5551,
      "step": 76
    },
    {
      "epoch": 2.2706766917293235,
      "grad_norm": 0.23189190030097961,
      "learning_rate": 7.530203962825331e-06,
      "loss": 1.6313,
      "step": 77
    },
    {
      "epoch": 2.300751879699248,
      "grad_norm": 0.24296167492866516,
      "learning_rate": 6.9979181266251165e-06,
      "loss": 1.6313,
      "step": 78
    },
    {
      "epoch": 2.3308270676691727,
      "grad_norm": 0.2289172112941742,
      "learning_rate": 6.481127117104913e-06,
      "loss": 1.5241,
      "step": 79
    },
    {
      "epoch": 2.3609022556390977,
      "grad_norm": 0.22455312311649323,
      "learning_rate": 5.980446803877011e-06,
      "loss": 1.6188,
      "step": 80
    },
    {
      "epoch": 2.3909774436090228,
      "grad_norm": 0.2265426218509674,
      "learning_rate": 5.496473857132476e-06,
      "loss": 1.5837,
      "step": 81
    },
    {
      "epoch": 2.4210526315789473,
      "grad_norm": 0.2618865966796875,
      "learning_rate": 5.029785036577976e-06,
      "loss": 1.5811,
      "step": 82
    },
    {
      "epoch": 2.451127819548872,
      "grad_norm": 0.2463882714509964,
      "learning_rate": 4.580936504100408e-06,
      "loss": 1.5963,
      "step": 83
    },
    {
      "epoch": 2.481203007518797,
      "grad_norm": 0.23804545402526855,
      "learning_rate": 4.150463160978196e-06,
      "loss": 1.5137,
      "step": 84
    },
    {
      "epoch": 2.511278195488722,
      "grad_norm": 0.2481829822063446,
      "learning_rate": 3.7388780104293474e-06,
      "loss": 1.5722,
      "step": 85
    },
    {
      "epoch": 2.5413533834586466,
      "grad_norm": 0.23824141919612885,
      "learning_rate": 3.346671546255875e-06,
      "loss": 1.5849,
      "step": 86
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.2507651448249817,
      "learning_rate": 2.9743111683129777e-06,
      "loss": 1.5924,
      "step": 87
    },
    {
      "epoch": 2.601503759398496,
      "grad_norm": 0.2725398540496826,
      "learning_rate": 2.62224062549987e-06,
      "loss": 1.6476,
      "step": 88
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 0.2342754453420639,
      "learning_rate": 2.2908794869358044e-06,
      "loss": 1.6386,
      "step": 89
    },
    {
      "epoch": 2.661654135338346,
      "grad_norm": 0.25105950236320496,
      "learning_rate": 1.9806226419516195e-06,
      "loss": 1.4763,
      "step": 90
    },
    {
      "epoch": 2.6917293233082704,
      "grad_norm": 0.43505024909973145,
      "learning_rate": 1.6918398294926742e-06,
      "loss": 1.5868,
      "step": 91
    },
    {
      "epoch": 2.7218045112781954,
      "grad_norm": 0.23099352419376373,
      "learning_rate": 1.4248751974939534e-06,
      "loss": 1.5691,
      "step": 92
    },
    {
      "epoch": 2.7518796992481205,
      "grad_norm": 38.33534622192383,
      "learning_rate": 1.1800468927524733e-06,
      "loss": 1.494,
      "step": 93
    },
    {
      "epoch": 2.781954887218045,
      "grad_norm": 0.23298011720180511,
      "learning_rate": 9.576466817857177e-07,
      "loss": 1.5339,
      "step": 94
    },
    {
      "epoch": 2.8120300751879697,
      "grad_norm": 0.25964486598968506,
      "learning_rate": 7.579396031279907e-07,
      "loss": 1.5506,
      "step": 95
    },
    {
      "epoch": 2.8421052631578947,
      "grad_norm": 0.30553656816482544,
      "learning_rate": 5.811636514789598e-07,
      "loss": 1.426,
      "step": 96
    },
    {
      "epoch": 2.8721804511278197,
      "grad_norm": 0.24182404577732086,
      "learning_rate": 4.2752949408089385e-07,
      "loss": 1.6345,
      "step": 97
    },
    {
      "epoch": 2.9022556390977443,
      "grad_norm": 0.27568554878234863,
      "learning_rate": 2.9722021966252404e-07,
      "loss": 1.5707,
      "step": 98
    },
    {
      "epoch": 2.932330827067669,
      "grad_norm": 0.23939448595046997,
      "learning_rate": 1.903911202487363e-07,
      "loss": 1.5729,
      "step": 99
    },
    {
      "epoch": 2.962406015037594,
      "grad_norm": 0.23518355190753937,
      "learning_rate": 1.0716950609614751e-07,
      "loss": 1.4925,
      "step": 100
    },
    {
      "epoch": 2.992481203007519,
      "grad_norm": 0.23946303129196167,
      "learning_rate": 4.7654553975049476e-08,
      "loss": 1.6714,
      "step": 101
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.44319745898246765,
      "learning_rate": 1.1917188978591842e-08,
      "loss": 1.5097,
      "step": 102
    }
  ],
  "logging_steps": 1,
  "max_steps": 102,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.703251688213709e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
