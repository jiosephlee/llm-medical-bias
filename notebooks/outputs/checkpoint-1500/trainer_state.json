{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 7.8125,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13020833333333334,
      "grad_norm": 0.10548655688762665,
      "learning_rate": 0.000197911227154047,
      "loss": 0.4961,
      "step": 25
    },
    {
      "epoch": 0.2604166666666667,
      "grad_norm": 0.09908479452133179,
      "learning_rate": 0.00019530026109660577,
      "loss": 0.2692,
      "step": 50
    },
    {
      "epoch": 0.390625,
      "grad_norm": 0.1174030750989914,
      "learning_rate": 0.0001926892950391645,
      "loss": 0.2607,
      "step": 75
    },
    {
      "epoch": 0.5208333333333334,
      "grad_norm": 0.08160720765590668,
      "learning_rate": 0.00019007832898172323,
      "loss": 0.2565,
      "step": 100
    },
    {
      "epoch": 0.6510416666666666,
      "grad_norm": 0.0752725601196289,
      "learning_rate": 0.000187467362924282,
      "loss": 0.2543,
      "step": 125
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.08480288833379745,
      "learning_rate": 0.00018485639686684072,
      "loss": 0.2549,
      "step": 150
    },
    {
      "epoch": 0.9114583333333334,
      "grad_norm": 0.06167466938495636,
      "learning_rate": 0.00018224543080939948,
      "loss": 0.2504,
      "step": 175
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 0.06537926197052002,
      "learning_rate": 0.00017963446475195824,
      "loss": 0.2488,
      "step": 200
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.05685584619641304,
      "learning_rate": 0.00017702349869451697,
      "loss": 0.2446,
      "step": 225
    },
    {
      "epoch": 1.3020833333333333,
      "grad_norm": 0.06594143807888031,
      "learning_rate": 0.00017441253263707573,
      "loss": 0.2451,
      "step": 250
    },
    {
      "epoch": 1.4322916666666667,
      "grad_norm": 0.05614003166556358,
      "learning_rate": 0.00017180156657963446,
      "loss": 0.2442,
      "step": 275
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.061336904764175415,
      "learning_rate": 0.00016919060052219322,
      "loss": 0.2418,
      "step": 300
    },
    {
      "epoch": 1.6927083333333335,
      "grad_norm": 0.05705995857715607,
      "learning_rate": 0.00016657963446475198,
      "loss": 0.2446,
      "step": 325
    },
    {
      "epoch": 1.8229166666666665,
      "grad_norm": 0.06356099247932434,
      "learning_rate": 0.00016396866840731071,
      "loss": 0.2451,
      "step": 350
    },
    {
      "epoch": 1.953125,
      "grad_norm": 0.06254755705595016,
      "learning_rate": 0.00016135770234986947,
      "loss": 0.2427,
      "step": 375
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.058518704026937485,
      "learning_rate": 0.0001587467362924282,
      "loss": 0.2406,
      "step": 400
    },
    {
      "epoch": 2.2135416666666665,
      "grad_norm": 0.058049991726875305,
      "learning_rate": 0.00015613577023498696,
      "loss": 0.2389,
      "step": 425
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.06319591403007507,
      "learning_rate": 0.0001535248041775457,
      "loss": 0.2402,
      "step": 450
    },
    {
      "epoch": 2.4739583333333335,
      "grad_norm": 0.05280545353889465,
      "learning_rate": 0.00015091383812010446,
      "loss": 0.2399,
      "step": 475
    },
    {
      "epoch": 2.6041666666666665,
      "grad_norm": 0.048919178545475006,
      "learning_rate": 0.0001483028720626632,
      "loss": 0.239,
      "step": 500
    },
    {
      "epoch": 2.734375,
      "grad_norm": 0.05509982630610466,
      "learning_rate": 0.00014569190600522192,
      "loss": 0.2371,
      "step": 525
    },
    {
      "epoch": 2.8645833333333335,
      "grad_norm": 0.057249121367931366,
      "learning_rate": 0.00014308093994778068,
      "loss": 0.2398,
      "step": 550
    },
    {
      "epoch": 2.9947916666666665,
      "grad_norm": 0.07030019909143448,
      "learning_rate": 0.0001404699738903394,
      "loss": 0.2387,
      "step": 575
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.05492015555500984,
      "learning_rate": 0.00013785900783289817,
      "loss": 0.2344,
      "step": 600
    },
    {
      "epoch": 3.2552083333333335,
      "grad_norm": 0.05984547361731529,
      "learning_rate": 0.00013524804177545693,
      "loss": 0.2343,
      "step": 625
    },
    {
      "epoch": 3.3854166666666665,
      "grad_norm": 0.06336786597967148,
      "learning_rate": 0.00013263707571801566,
      "loss": 0.2363,
      "step": 650
    },
    {
      "epoch": 3.515625,
      "grad_norm": 0.05662776902318001,
      "learning_rate": 0.00013002610966057442,
      "loss": 0.2371,
      "step": 675
    },
    {
      "epoch": 3.6458333333333335,
      "grad_norm": 0.061762694269418716,
      "learning_rate": 0.00012741514360313315,
      "loss": 0.2355,
      "step": 700
    },
    {
      "epoch": 3.7760416666666665,
      "grad_norm": 0.05452089011669159,
      "learning_rate": 0.00012480417754569191,
      "loss": 0.2368,
      "step": 725
    },
    {
      "epoch": 3.90625,
      "grad_norm": 0.05495314672589302,
      "learning_rate": 0.00012219321148825067,
      "loss": 0.2343,
      "step": 750
    },
    {
      "epoch": 4.036458333333333,
      "grad_norm": 0.05962739139795303,
      "learning_rate": 0.0001195822454308094,
      "loss": 0.2318,
      "step": 775
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.07522223889827728,
      "learning_rate": 0.00011697127937336816,
      "loss": 0.2298,
      "step": 800
    },
    {
      "epoch": 4.296875,
      "grad_norm": 0.05715647712349892,
      "learning_rate": 0.0001143603133159269,
      "loss": 0.2292,
      "step": 825
    },
    {
      "epoch": 4.427083333333333,
      "grad_norm": 0.06200461834669113,
      "learning_rate": 0.00011174934725848564,
      "loss": 0.2319,
      "step": 850
    },
    {
      "epoch": 4.557291666666667,
      "grad_norm": 0.05687751993536949,
      "learning_rate": 0.00010913838120104439,
      "loss": 0.2336,
      "step": 875
    },
    {
      "epoch": 4.6875,
      "grad_norm": 0.054446712136268616,
      "learning_rate": 0.00010652741514360313,
      "loss": 0.2316,
      "step": 900
    },
    {
      "epoch": 4.817708333333333,
      "grad_norm": 0.06110401451587677,
      "learning_rate": 0.00010391644908616189,
      "loss": 0.232,
      "step": 925
    },
    {
      "epoch": 4.947916666666667,
      "grad_norm": 0.05521809309720993,
      "learning_rate": 0.00010130548302872063,
      "loss": 0.2319,
      "step": 950
    },
    {
      "epoch": 5.078125,
      "grad_norm": 0.06499537080526352,
      "learning_rate": 9.869451697127938e-05,
      "loss": 0.2283,
      "step": 975
    },
    {
      "epoch": 5.208333333333333,
      "grad_norm": 0.06961985677480698,
      "learning_rate": 9.608355091383813e-05,
      "loss": 0.2254,
      "step": 1000
    },
    {
      "epoch": 5.338541666666667,
      "grad_norm": 0.07051391899585724,
      "learning_rate": 9.347258485639688e-05,
      "loss": 0.2266,
      "step": 1025
    },
    {
      "epoch": 5.46875,
      "grad_norm": 0.06559498608112335,
      "learning_rate": 9.086161879895562e-05,
      "loss": 0.2253,
      "step": 1050
    },
    {
      "epoch": 5.598958333333333,
      "grad_norm": 0.06488848477602005,
      "learning_rate": 8.825065274151437e-05,
      "loss": 0.2273,
      "step": 1075
    },
    {
      "epoch": 5.729166666666667,
      "grad_norm": 0.0621490515768528,
      "learning_rate": 8.56396866840731e-05,
      "loss": 0.229,
      "step": 1100
    },
    {
      "epoch": 5.859375,
      "grad_norm": 0.06580396741628647,
      "learning_rate": 8.302872062663186e-05,
      "loss": 0.2296,
      "step": 1125
    },
    {
      "epoch": 5.989583333333333,
      "grad_norm": 0.06544827669858932,
      "learning_rate": 8.04177545691906e-05,
      "loss": 0.2278,
      "step": 1150
    },
    {
      "epoch": 6.119791666666667,
      "grad_norm": 0.07136084884405136,
      "learning_rate": 7.780678851174935e-05,
      "loss": 0.22,
      "step": 1175
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.07921894639730453,
      "learning_rate": 7.51958224543081e-05,
      "loss": 0.2202,
      "step": 1200
    },
    {
      "epoch": 6.380208333333333,
      "grad_norm": 0.06861581653356552,
      "learning_rate": 7.258485639686684e-05,
      "loss": 0.2209,
      "step": 1225
    },
    {
      "epoch": 6.510416666666667,
      "grad_norm": 0.07941436767578125,
      "learning_rate": 6.99738903394256e-05,
      "loss": 0.2211,
      "step": 1250
    },
    {
      "epoch": 6.640625,
      "grad_norm": 0.06613438576459885,
      "learning_rate": 6.736292428198435e-05,
      "loss": 0.2215,
      "step": 1275
    },
    {
      "epoch": 6.770833333333333,
      "grad_norm": 0.06863298267126083,
      "learning_rate": 6.475195822454308e-05,
      "loss": 0.2206,
      "step": 1300
    },
    {
      "epoch": 6.901041666666667,
      "grad_norm": 0.0684012919664383,
      "learning_rate": 6.214099216710182e-05,
      "loss": 0.2222,
      "step": 1325
    },
    {
      "epoch": 7.03125,
      "grad_norm": 0.07196278125047684,
      "learning_rate": 5.953002610966058e-05,
      "loss": 0.2185,
      "step": 1350
    },
    {
      "epoch": 7.161458333333333,
      "grad_norm": 0.09065065532922745,
      "learning_rate": 5.691906005221932e-05,
      "loss": 0.2124,
      "step": 1375
    },
    {
      "epoch": 7.291666666666667,
      "grad_norm": 0.09039043635129929,
      "learning_rate": 5.4308093994778075e-05,
      "loss": 0.2118,
      "step": 1400
    },
    {
      "epoch": 7.421875,
      "grad_norm": 0.08806757628917694,
      "learning_rate": 5.169712793733682e-05,
      "loss": 0.2135,
      "step": 1425
    },
    {
      "epoch": 7.552083333333333,
      "grad_norm": 0.0804767981171608,
      "learning_rate": 4.908616187989557e-05,
      "loss": 0.2123,
      "step": 1450
    },
    {
      "epoch": 7.682291666666667,
      "grad_norm": 0.08324956148862839,
      "learning_rate": 4.647519582245431e-05,
      "loss": 0.2137,
      "step": 1475
    },
    {
      "epoch": 7.8125,
      "grad_norm": 0.08601498603820801,
      "learning_rate": 4.386422976501306e-05,
      "loss": 0.2134,
      "step": 1500
    }
  ],
  "logging_steps": 25,
  "max_steps": 1920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.59181459550634e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
